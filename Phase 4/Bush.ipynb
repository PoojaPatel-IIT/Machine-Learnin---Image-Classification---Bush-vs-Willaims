{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "iH0UY2YOCO9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9b06ae9d-4fdc-428c-fa99-1afed4cfbb96"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "X = pd.read_csv(\"X.csv\", sep = ' ', header = None , dtype = float)\n",
        "X = X.values\n",
        "y= pd.read_csv(\"y_bush_vs_others.csv\" , header = None)\n",
        "y_bush = y.values.ravel()\n",
        "y= pd.read_csv(\"y_williams_vs_others.csv\" , header = None)\n",
        "y_williams = y.values.ravel()\n",
        "print(\"X Shape\",X.shape)\n",
        "print(\"# of Bush's photos\",np.sum(y_bush))\n",
        "print(\"# of Bush's photos\",np.sum(y_williams))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_reshaped=X.reshape((X.shape[0],64,64,1))\n",
        "X_reshaped.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Shape (13233, 4096)\n",
            "# of Bush's photos 530\n",
            "# of Bush's photos 52\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13233, 64, 64, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "6hyD-bD7Y2c1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "uPpyXLssCYhb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3270
        },
        "outputId": "b016d911-876a-4437-c909-83055388388f"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "modelForBush=load_model(\"initialized-model.keras\")\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_reshaped, \n",
        "             y_bush,shuffle = True ,test_size= 1./3, random_state=6099, stratify  = y_bush) # A20396099\n",
        "\n",
        "\n",
        "modelForBush.fit(X_train_b,y_train_b, epochs=90, batch_size=32, validation_data = (X_test_b, y_test_b ) )\n",
        "#90\n",
        "y_predicted_train_bush = modelForBush.predict_classes(X_train_b) \n",
        "y_predicted_test_bush = modelForBush.predict_classes(X_test_b) \n",
        "result_f1_train_bush_E70=f1_score(y_train_b, y_predicted_train_bush)\n",
        "result_f1_test_bush_E70=f1_score(y_test_b, y_predicted_test_bush)\n",
        "print(\"Bush F1 Score on Train : \",result_f1_train_bush_E70)\n",
        "print(\"Bush F1 Score on Test : \",result_f1_test_bush_E70)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8822 samples, validate on 4411 samples\n",
            "Epoch 1/90\n",
            "8822/8822 [==============================] - 7s 757us/step - loss: 0.3306 - acc: 0.9480 - val_loss: 0.1839 - val_acc: 0.9599\n",
            "Epoch 2/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.1764 - acc: 0.9600 - val_loss: 0.1571 - val_acc: 0.9599\n",
            "Epoch 3/90\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.1641 - acc: 0.9600 - val_loss: 0.1637 - val_acc: 0.9599\n",
            "Epoch 4/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.1507 - acc: 0.9600 - val_loss: 0.2907 - val_acc: 0.9599\n",
            "Epoch 5/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.1455 - acc: 0.9600 - val_loss: 0.1646 - val_acc: 0.9599\n",
            "Epoch 6/90\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.1319 - acc: 0.9600 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 7/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.1252 - acc: 0.9600 - val_loss: 0.5402 - val_acc: 0.9599\n",
            "Epoch 8/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.1184 - acc: 0.9600 - val_loss: 0.1681 - val_acc: 0.9599\n",
            "Epoch 9/90\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.1109 - acc: 0.9599 - val_loss: 0.2622 - val_acc: 0.9599\n",
            "Epoch 10/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.1090 - acc: 0.9600 - val_loss: 0.1327 - val_acc: 0.9599\n",
            "Epoch 11/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0969 - acc: 0.9600 - val_loss: 0.2602 - val_acc: 0.9599\n",
            "Epoch 12/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0966 - acc: 0.9600 - val_loss: 0.1313 - val_acc: 0.9599\n",
            "Epoch 13/90\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0807 - acc: 0.9600 - val_loss: 0.1128 - val_acc: 0.9599\n",
            "Epoch 14/90\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0721 - acc: 0.9604 - val_loss: 0.2891 - val_acc: 0.9599\n",
            "Epoch 15/90\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0610 - acc: 0.9652 - val_loss: 0.1061 - val_acc: 0.9599\n",
            "Epoch 16/90\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0597 - acc: 0.9666 - val_loss: 0.5705 - val_acc: 0.9601\n",
            "Epoch 17/90\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0503 - acc: 0.9748 - val_loss: 0.4146 - val_acc: 0.9640\n",
            "Epoch 18/90\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0517 - acc: 0.9753 - val_loss: 0.0863 - val_acc: 0.9744\n",
            "Epoch 19/90\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0460 - acc: 0.9768 - val_loss: 0.1841 - val_acc: 0.8882\n",
            "Epoch 20/90\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0434 - acc: 0.9793 - val_loss: 0.0993 - val_acc: 0.9744\n",
            "Epoch 21/90\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.0315 - acc: 0.9821 - val_loss: 0.1252 - val_acc: 0.9714\n",
            "Epoch 22/90\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0278 - acc: 0.9861 - val_loss: 0.0920 - val_acc: 0.9789\n",
            "Epoch 23/90\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0247 - acc: 0.9848 - val_loss: 0.1094 - val_acc: 0.9655\n",
            "Epoch 24/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0288 - acc: 0.9830 - val_loss: 0.4189 - val_acc: 0.8438\n",
            "Epoch 25/90\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0224 - acc: 0.9915 - val_loss: 0.2708 - val_acc: 0.9714\n",
            "Epoch 26/90\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0203 - acc: 0.9942 - val_loss: 0.1628 - val_acc: 0.9411\n",
            "Epoch 27/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0185 - acc: 0.9956 - val_loss: 0.1088 - val_acc: 0.9807\n",
            "Epoch 28/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0345 - acc: 0.9913 - val_loss: 0.3452 - val_acc: 0.9680\n",
            "Epoch 29/90\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0235 - acc: 0.9937 - val_loss: 0.1641 - val_acc: 0.9780\n",
            "Epoch 30/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0188 - acc: 0.9946 - val_loss: 0.1484 - val_acc: 0.9755\n",
            "Epoch 31/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0211 - acc: 0.9955 - val_loss: 0.1061 - val_acc: 0.9658\n",
            "Epoch 32/90\n",
            "8822/8822 [==============================] - 6s 668us/step - loss: 0.0169 - acc: 0.9961 - val_loss: 0.3160 - val_acc: 0.9692\n",
            "Epoch 33/90\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.0178 - acc: 0.9960 - val_loss: 0.2571 - val_acc: 0.9721\n",
            "Epoch 34/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0191 - acc: 0.9961 - val_loss: 0.2642 - val_acc: 0.9091\n",
            "Epoch 35/90\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0111 - acc: 0.9980 - val_loss: 0.3196 - val_acc: 0.9728\n",
            "Epoch 36/90\n",
            "8822/8822 [==============================] - 6s 675us/step - loss: 0.0090 - acc: 0.9988 - val_loss: 0.1597 - val_acc: 0.9798\n",
            "Epoch 37/90\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0150 - acc: 0.9971 - val_loss: 0.1561 - val_acc: 0.9753\n",
            "Epoch 38/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0101 - acc: 0.9974 - val_loss: 0.1712 - val_acc: 0.9821\n",
            "Epoch 39/90\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0096 - acc: 0.9990 - val_loss: 0.1072 - val_acc: 0.9791\n",
            "Epoch 40/90\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0137 - acc: 0.9975 - val_loss: 0.2134 - val_acc: 0.9773\n",
            "Epoch 41/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0193 - acc: 0.9950 - val_loss: 0.2104 - val_acc: 0.9220\n",
            "Epoch 42/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.0898 - val_acc: 0.9839\n",
            "Epoch 43/90\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.0109 - acc: 0.9974 - val_loss: 0.1920 - val_acc: 0.9796\n",
            "Epoch 44/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0161 - acc: 0.9956 - val_loss: 0.1519 - val_acc: 0.9408\n",
            "Epoch 45/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0126 - acc: 0.9959 - val_loss: 0.2551 - val_acc: 0.9782\n",
            "Epoch 46/90\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0244 - acc: 0.9946 - val_loss: 0.4237 - val_acc: 0.9626\n",
            "Epoch 47/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0289 - acc: 0.9927 - val_loss: 0.3013 - val_acc: 0.9692\n",
            "Epoch 48/90\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0125 - acc: 0.9966 - val_loss: 0.1245 - val_acc: 0.9828\n",
            "Epoch 49/90\n",
            "8822/8822 [==============================] - 6s 675us/step - loss: 0.0118 - acc: 0.9968 - val_loss: 0.1194 - val_acc: 0.9549\n",
            "Epoch 50/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0137 - acc: 0.9964 - val_loss: 0.0904 - val_acc: 0.9796\n",
            "Epoch 51/90\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.1947 - val_acc: 0.9787\n",
            "Epoch 52/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.1127 - val_acc: 0.9839\n",
            "Epoch 53/90\n",
            "8822/8822 [==============================] - 6s 668us/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.1303 - val_acc: 0.9683\n",
            "Epoch 54/90\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.0105 - acc: 0.9969 - val_loss: 0.2562 - val_acc: 0.9064\n",
            "Epoch 55/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0225 - acc: 0.9949 - val_loss: 1.2370 - val_acc: 0.5473\n",
            "Epoch 56/90\n",
            "8822/8822 [==============================] - 6s 675us/step - loss: 0.0529 - acc: 0.9831 - val_loss: 0.6345 - val_acc: 0.9599\n",
            "Epoch 57/90\n",
            "8822/8822 [==============================] - 6s 675us/step - loss: 0.0481 - acc: 0.9837 - val_loss: 0.4429 - val_acc: 0.7427\n",
            "Epoch 58/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0549 - acc: 0.9814 - val_loss: 0.0948 - val_acc: 0.9755\n",
            "Epoch 59/90\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0486 - acc: 0.9821 - val_loss: 0.5536 - val_acc: 0.7243\n",
            "Epoch 60/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0369 - acc: 0.9881 - val_loss: 0.0763 - val_acc: 0.9791\n",
            "Epoch 61/90\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0298 - acc: 0.9915 - val_loss: 0.0893 - val_acc: 0.9805\n",
            "Epoch 62/90\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0227 - acc: 0.9917 - val_loss: 0.3813 - val_acc: 0.9610\n",
            "Epoch 63/90\n",
            "8822/8822 [==============================] - 6s 675us/step - loss: 0.0132 - acc: 0.9950 - val_loss: 0.1505 - val_acc: 0.9832\n",
            "Epoch 64/90\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.0198 - acc: 0.9941 - val_loss: 0.5255 - val_acc: 0.9610\n",
            "Epoch 65/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0096 - acc: 0.9973 - val_loss: 0.0767 - val_acc: 0.9821\n",
            "Epoch 66/90\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.1669 - val_acc: 0.9803\n",
            "Epoch 67/90\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0074 - acc: 0.9980 - val_loss: 0.1081 - val_acc: 0.9787\n",
            "Epoch 68/90\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.3918 - val_acc: 0.9678\n",
            "Epoch 69/90\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0159 - acc: 0.9963 - val_loss: 0.0570 - val_acc: 0.9862\n",
            "Epoch 70/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0099 - acc: 0.9972 - val_loss: 0.3415 - val_acc: 0.9692\n",
            "Epoch 71/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0907 - val_acc: 0.9866\n",
            "Epoch 72/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0025 - acc: 0.9998 - val_loss: 0.0748 - val_acc: 0.9869\n",
            "Epoch 73/90\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.0099 - acc: 0.9976 - val_loss: 0.6382 - val_acc: 0.9599\n",
            "Epoch 74/90\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.0065 - acc: 0.9984 - val_loss: 0.0744 - val_acc: 0.9789\n",
            "Epoch 75/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0814 - val_acc: 0.9864\n",
            "Epoch 76/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.1029 - val_acc: 0.9703\n",
            "Epoch 77/90\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0114 - acc: 0.9972 - val_loss: 0.4830 - val_acc: 0.9644\n",
            "Epoch 78/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0120 - acc: 0.9972 - val_loss: 0.1007 - val_acc: 0.9780\n",
            "Epoch 79/90\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0223 - acc: 0.9942 - val_loss: 0.1035 - val_acc: 0.9828\n",
            "Epoch 80/90\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0137 - acc: 0.9955 - val_loss: 0.0992 - val_acc: 0.9658\n",
            "Epoch 81/90\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0670 - val_acc: 0.9862\n",
            "Epoch 82/90\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.0968 - val_acc: 0.9873\n",
            "Epoch 83/90\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.4192 - val_acc: 0.9664\n",
            "Epoch 84/90\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.0089 - acc: 0.9978 - val_loss: 0.0888 - val_acc: 0.9848\n",
            "Epoch 85/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0921 - val_acc: 0.9859\n",
            "Epoch 86/90\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0029 - acc: 0.9995 - val_loss: 0.1040 - val_acc: 0.9782\n",
            "Epoch 87/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.2469 - val_acc: 0.9769\n",
            "Epoch 88/90\n",
            "8822/8822 [==============================] - 6s 668us/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0808 - val_acc: 0.9880\n",
            "Epoch 89/90\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0072 - acc: 0.9986 - val_loss: 0.3543 - val_acc: 0.9705\n",
            "Epoch 90/90\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.1086 - val_acc: 0.9869\n",
            "Bush F1 Score on Train :  1.0\n",
            "Bush F1 Score on Test :  0.8176100628930818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k_y8JnTRCkNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5404
        },
        "outputId": "93d70f3f-a735-4dd8-994b-0b47b757e786"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "modelForBush=load_model(\"initialized-model.keras\")\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_reshaped, \n",
        "             y_bush,shuffle = True ,test_size= 1./3, random_state=6099, stratify  = y_bush) # A20396099\n",
        "\n",
        "\n",
        "modelForBush.fit(X_train_b,y_train_b, epochs=150, batch_size=32, validation_data = (X_test_b, y_test_b ) )\n",
        "\n",
        "y_predicted_train_bush = modelForBush.predict_classes(X_train_b) \n",
        "y_predicted_test_bush = modelForBush.predict_classes(X_test_b) \n",
        "result_f1_train_bush_E70=f1_score(y_train_b, y_predicted_train_bush)\n",
        "result_f1_test_bush_E70=f1_score(y_test_b, y_predicted_test_bush)\n",
        "print(\"Bush F1 Score on Train : \",result_f1_train_bush_E70)\n",
        "print(\"Bush F1 Score on Test : \",result_f1_test_bush_E70)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8822 samples, validate on 4411 samples\n",
            "Epoch 1/150\n",
            "8822/8822 [==============================] - 7s 814us/step - loss: 0.3011 - acc: 0.9496 - val_loss: 0.2995 - val_acc: 0.9599\n",
            "Epoch 2/150\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.1730 - acc: 0.9600 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 3/150\n",
            "8822/8822 [==============================] - 6s 695us/step - loss: 0.1649 - acc: 0.9600 - val_loss: 0.6268 - val_acc: 0.9599\n",
            "Epoch 4/150\n",
            "8822/8822 [==============================] - 6s 697us/step - loss: 0.1532 - acc: 0.9599 - val_loss: 0.2170 - val_acc: 0.9599\n",
            "Epoch 5/150\n",
            "8822/8822 [==============================] - 6s 705us/step - loss: 0.1525 - acc: 0.9600 - val_loss: 0.1905 - val_acc: 0.9599\n",
            "Epoch 6/150\n",
            "8822/8822 [==============================] - 6s 704us/step - loss: 0.1433 - acc: 0.9598 - val_loss: 0.1499 - val_acc: 0.9599\n",
            "Epoch 7/150\n",
            "8822/8822 [==============================] - 6s 704us/step - loss: 0.1357 - acc: 0.9600 - val_loss: 0.1497 - val_acc: 0.9599\n",
            "Epoch 8/150\n",
            "8822/8822 [==============================] - 6s 697us/step - loss: 0.1270 - acc: 0.9600 - val_loss: 0.1393 - val_acc: 0.9599\n",
            "Epoch 9/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.1127 - acc: 0.9599 - val_loss: 0.1351 - val_acc: 0.9599\n",
            "Epoch 10/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.1068 - acc: 0.9600 - val_loss: 0.2100 - val_acc: 0.9599\n",
            "Epoch 11/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.1023 - acc: 0.9600 - val_loss: 0.2820 - val_acc: 0.9599\n",
            "Epoch 12/150\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0989 - acc: 0.9600 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 13/150\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0971 - acc: 0.9600 - val_loss: 0.1497 - val_acc: 0.9599\n",
            "Epoch 14/150\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0866 - acc: 0.9600 - val_loss: 0.1190 - val_acc: 0.9599\n",
            "Epoch 15/150\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0763 - acc: 0.9663 - val_loss: 0.1004 - val_acc: 0.9678\n",
            "Epoch 16/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0618 - acc: 0.9702 - val_loss: 0.1754 - val_acc: 0.9637\n",
            "Epoch 17/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0604 - acc: 0.9692 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 18/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0496 - acc: 0.9728 - val_loss: 0.1210 - val_acc: 0.9494\n",
            "Epoch 19/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0463 - acc: 0.9745 - val_loss: 0.3193 - val_acc: 0.9621\n",
            "Epoch 20/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0406 - acc: 0.9754 - val_loss: 0.1412 - val_acc: 0.9621\n",
            "Epoch 21/150\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0428 - acc: 0.9735 - val_loss: 0.3560 - val_acc: 0.9630\n",
            "Epoch 22/150\n",
            "8822/8822 [==============================] - 6s 698us/step - loss: 0.0453 - acc: 0.9744 - val_loss: 0.6457 - val_acc: 0.9599\n",
            "Epoch 23/150\n",
            "8822/8822 [==============================] - 6s 694us/step - loss: 0.0330 - acc: 0.9768 - val_loss: 0.5657 - val_acc: 0.9603\n",
            "Epoch 24/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0299 - acc: 0.9917 - val_loss: 0.4746 - val_acc: 0.9640\n",
            "Epoch 25/150\n",
            "8822/8822 [==============================] - 6s 697us/step - loss: 0.0354 - acc: 0.9916 - val_loss: 0.5943 - val_acc: 0.6491\n",
            "Epoch 26/150\n",
            "8822/8822 [==============================] - 6s 701us/step - loss: 0.0415 - acc: 0.9890 - val_loss: 0.2661 - val_acc: 0.9660\n",
            "Epoch 27/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0392 - acc: 0.9907 - val_loss: 0.0770 - val_acc: 0.9753\n",
            "Epoch 28/150\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0310 - acc: 0.9933 - val_loss: 0.2447 - val_acc: 0.9708\n",
            "Epoch 29/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0292 - acc: 0.9934 - val_loss: 0.6416 - val_acc: 0.9599\n",
            "Epoch 30/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0339 - acc: 0.9921 - val_loss: 0.2253 - val_acc: 0.9748\n",
            "Epoch 31/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0256 - acc: 0.9954 - val_loss: 0.6294 - val_acc: 0.9599\n",
            "Epoch 32/150\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0215 - acc: 0.9961 - val_loss: 0.3250 - val_acc: 0.8381\n",
            "Epoch 33/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0291 - acc: 0.9951 - val_loss: 0.2895 - val_acc: 0.9608\n",
            "Epoch 34/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0237 - acc: 0.9959 - val_loss: 0.2864 - val_acc: 0.9723\n",
            "Epoch 35/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0223 - acc: 0.9952 - val_loss: 0.6351 - val_acc: 0.9599\n",
            "Epoch 36/150\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0260 - acc: 0.9952 - val_loss: 0.2387 - val_acc: 0.9150\n",
            "Epoch 37/150\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0291 - acc: 0.9944 - val_loss: 0.2620 - val_acc: 0.9710\n",
            "Epoch 38/150\n",
            "8822/8822 [==============================] - 6s 695us/step - loss: 0.0241 - acc: 0.9954 - val_loss: 0.1256 - val_acc: 0.9712\n",
            "Epoch 39/150\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0241 - acc: 0.9948 - val_loss: 0.1479 - val_acc: 0.9275\n",
            "Epoch 40/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0165 - acc: 0.9972 - val_loss: 0.6369 - val_acc: 0.9599\n",
            "Epoch 41/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0152 - acc: 0.9975 - val_loss: 0.1261 - val_acc: 0.9841\n",
            "Epoch 42/150\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0112 - acc: 0.9986 - val_loss: 0.1630 - val_acc: 0.9717\n",
            "Epoch 43/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0406 - acc: 0.9888 - val_loss: 0.1852 - val_acc: 0.9787\n",
            "Epoch 44/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0348 - acc: 0.9912 - val_loss: 0.0954 - val_acc: 0.9721\n",
            "Epoch 45/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0314 - acc: 0.9918 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 46/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0553 - acc: 0.9833 - val_loss: 0.1695 - val_acc: 0.9263\n",
            "Epoch 47/150\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0581 - acc: 0.9816 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 48/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0578 - acc: 0.9836 - val_loss: 0.4712 - val_acc: 0.7168\n",
            "Epoch 49/150\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0399 - acc: 0.9864 - val_loss: 0.1837 - val_acc: 0.9785\n",
            "Epoch 50/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0311 - acc: 0.9899 - val_loss: 0.2162 - val_acc: 0.9735\n",
            "Epoch 51/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0450 - acc: 0.9867 - val_loss: 0.0647 - val_acc: 0.9823\n",
            "Epoch 52/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0255 - acc: 0.9930 - val_loss: 0.4066 - val_acc: 0.9664\n",
            "Epoch 53/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0268 - acc: 0.9930 - val_loss: 0.0717 - val_acc: 0.9787\n",
            "Epoch 54/150\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0168 - acc: 0.9960 - val_loss: 0.3737 - val_acc: 0.9678\n",
            "Epoch 55/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0139 - acc: 0.9959 - val_loss: 0.3978 - val_acc: 0.9680\n",
            "Epoch 56/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0198 - acc: 0.9941 - val_loss: 0.1501 - val_acc: 0.9812\n",
            "Epoch 57/150\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0164 - acc: 0.9964 - val_loss: 0.1007 - val_acc: 0.9694\n",
            "Epoch 58/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0232 - acc: 0.9935 - val_loss: 0.2574 - val_acc: 0.9766\n",
            "Epoch 59/150\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0114 - acc: 0.9975 - val_loss: 0.1917 - val_acc: 0.9798\n",
            "Epoch 60/150\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0216 - acc: 0.9944 - val_loss: 0.3698 - val_acc: 0.9671\n",
            "Epoch 61/150\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0191 - acc: 0.9952 - val_loss: 0.2354 - val_acc: 0.9769\n",
            "Epoch 62/150\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0120 - acc: 0.9972 - val_loss: 0.0732 - val_acc: 0.9844\n",
            "Epoch 63/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0131 - acc: 0.9980 - val_loss: 0.3502 - val_acc: 0.8925\n",
            "Epoch 64/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0225 - acc: 0.9950 - val_loss: 0.6387 - val_acc: 0.9599\n",
            "Epoch 65/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0132 - acc: 0.9969 - val_loss: 0.3974 - val_acc: 0.9696\n",
            "Epoch 66/150\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0253 - acc: 0.9951 - val_loss: 0.5412 - val_acc: 0.9606\n",
            "Epoch 67/150\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0306 - acc: 0.9922 - val_loss: 0.1474 - val_acc: 0.9442\n",
            "Epoch 68/150\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0167 - acc: 0.9952 - val_loss: 0.1416 - val_acc: 0.9825\n",
            "Epoch 69/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0156 - acc: 0.9969 - val_loss: 0.3342 - val_acc: 0.9680\n",
            "Epoch 70/150\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0297 - acc: 0.9913 - val_loss: 0.0803 - val_acc: 0.9667\n",
            "Epoch 71/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.0720 - val_acc: 0.9882\n",
            "Epoch 72/150\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0090 - acc: 0.9976 - val_loss: 0.0569 - val_acc: 0.9875\n",
            "Epoch 73/150\n",
            "8822/8822 [==============================] - 6s 697us/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0928 - val_acc: 0.9830\n",
            "Epoch 74/150\n",
            "8822/8822 [==============================] - 6s 695us/step - loss: 0.0186 - acc: 0.9937 - val_loss: 0.6135 - val_acc: 0.9606\n",
            "Epoch 75/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0306 - acc: 0.9938 - val_loss: 0.5092 - val_acc: 0.9621\n",
            "Epoch 76/150\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0156 - acc: 0.9974 - val_loss: 0.0823 - val_acc: 0.9866\n",
            "Epoch 77/150\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0132 - acc: 0.9978 - val_loss: 0.1417 - val_acc: 0.9841\n",
            "Epoch 78/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0110 - acc: 0.9977 - val_loss: 0.0873 - val_acc: 0.9787\n",
            "Epoch 79/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0091 - acc: 0.9977 - val_loss: 0.1380 - val_acc: 0.9862\n",
            "Epoch 80/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0119 - acc: 0.9972 - val_loss: 0.2834 - val_acc: 0.8932\n",
            "Epoch 81/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0157 - acc: 0.9960 - val_loss: 0.1255 - val_acc: 0.9853\n",
            "Epoch 82/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0202 - acc: 0.9961 - val_loss: 0.1408 - val_acc: 0.9583\n",
            "Epoch 83/150\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0176 - acc: 0.9954 - val_loss: 0.3920 - val_acc: 0.9705\n",
            "Epoch 84/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0105 - acc: 0.9966 - val_loss: 0.0793 - val_acc: 0.9869\n",
            "Epoch 85/150\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0885 - val_acc: 0.9810\n",
            "Epoch 86/150\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0130 - acc: 0.9974 - val_loss: 0.1303 - val_acc: 0.9855\n",
            "Epoch 87/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0179 - acc: 0.9961 - val_loss: 0.1774 - val_acc: 0.9553\n",
            "Epoch 88/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0190 - acc: 0.9968 - val_loss: 0.1574 - val_acc: 0.9753\n",
            "Epoch 89/150\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0183 - acc: 0.9968 - val_loss: 0.1746 - val_acc: 0.9844\n",
            "Epoch 90/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0171 - acc: 0.9968 - val_loss: 0.2672 - val_acc: 0.9773\n",
            "Epoch 91/150\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0175 - acc: 0.9947 - val_loss: 0.1415 - val_acc: 0.9744\n",
            "Epoch 92/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0208 - acc: 0.9947 - val_loss: 0.1517 - val_acc: 0.9846\n",
            "Epoch 93/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0105 - acc: 0.9972 - val_loss: 0.0986 - val_acc: 0.9864\n",
            "Epoch 94/150\n",
            "8822/8822 [==============================] - 6s 700us/step - loss: 0.0132 - acc: 0.9985 - val_loss: 0.1549 - val_acc: 0.9857\n",
            "Epoch 95/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0163 - acc: 0.9966 - val_loss: 0.6166 - val_acc: 0.9599\n",
            "Epoch 96/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0206 - acc: 0.9939 - val_loss: 0.1244 - val_acc: 0.9846\n",
            "Epoch 97/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0189 - acc: 0.9963 - val_loss: 0.1244 - val_acc: 0.9878\n",
            "Epoch 98/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0175 - acc: 0.9978 - val_loss: 0.2016 - val_acc: 0.9832\n",
            "Epoch 99/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0172 - acc: 0.9978 - val_loss: 0.0983 - val_acc: 0.9848\n",
            "Epoch 100/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0131 - acc: 0.9975 - val_loss: 0.0865 - val_acc: 0.9821\n",
            "Epoch 101/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0188 - acc: 0.9938 - val_loss: 0.3137 - val_acc: 0.9764\n",
            "Epoch 102/150\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0258 - acc: 0.9922 - val_loss: 0.0748 - val_acc: 0.9866\n",
            "Epoch 103/150\n",
            "8822/8822 [==============================] - 6s 695us/step - loss: 0.0096 - acc: 0.9968 - val_loss: 0.1386 - val_acc: 0.9855\n",
            "Epoch 104/150\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0075 - acc: 0.9991 - val_loss: 0.0795 - val_acc: 0.9887\n",
            "Epoch 105/150\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0130 - acc: 0.9971 - val_loss: 0.3378 - val_acc: 0.9739\n",
            "Epoch 106/150\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0088 - acc: 0.9981 - val_loss: 0.0792 - val_acc: 0.9889\n",
            "Epoch 107/150\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0072 - acc: 0.9985 - val_loss: 0.0852 - val_acc: 0.9878\n",
            "Epoch 108/150\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.0906 - val_acc: 0.9893\n",
            "Epoch 109/150\n",
            "8822/8822 [==============================] - 6s 695us/step - loss: 0.0040 - acc: 0.9994 - val_loss: 0.0677 - val_acc: 0.9866\n",
            "Epoch 110/150\n",
            "8822/8822 [==============================] - 6s 694us/step - loss: 0.0052 - acc: 0.9990 - val_loss: 0.1167 - val_acc: 0.9878\n",
            "Epoch 111/150\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0200 - acc: 0.9956 - val_loss: 0.2428 - val_acc: 0.9812\n",
            "Epoch 112/150\n",
            "8822/8822 [==============================] - 6s 697us/step - loss: 0.0133 - acc: 0.9976 - val_loss: 0.1076 - val_acc: 0.9873\n",
            "Epoch 113/150\n",
            "8822/8822 [==============================] - 6s 695us/step - loss: 0.0082 - acc: 0.9980 - val_loss: 0.1120 - val_acc: 0.9900\n",
            "Epoch 114/150\n",
            "8822/8822 [==============================] - 6s 694us/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.1011 - val_acc: 0.9900\n",
            "Epoch 115/150\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0127 - acc: 0.9976 - val_loss: 0.0740 - val_acc: 0.9896\n",
            "Epoch 116/150\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0820 - val_acc: 0.9830\n",
            "Epoch 117/150\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0050 - acc: 0.9992 - val_loss: 0.0753 - val_acc: 0.9857\n",
            "Epoch 118/150\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0040 - acc: 0.9995 - val_loss: 0.1154 - val_acc: 0.9891\n",
            "Epoch 119/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0088 - acc: 0.9982 - val_loss: 0.2809 - val_acc: 0.9798\n",
            "Epoch 120/150\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0073 - acc: 0.9985 - val_loss: 0.0665 - val_acc: 0.9853\n",
            "Epoch 121/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0114 - acc: 0.9966 - val_loss: 0.1949 - val_acc: 0.9810\n",
            "Epoch 122/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0177 - acc: 0.9965 - val_loss: 0.1941 - val_acc: 0.9349\n",
            "Epoch 123/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0146 - acc: 0.9964 - val_loss: 0.1597 - val_acc: 0.9859\n",
            "Epoch 124/150\n",
            "8822/8822 [==============================] - 6s 696us/step - loss: 0.0078 - acc: 0.9976 - val_loss: 0.3656 - val_acc: 0.9755\n",
            "Epoch 125/150\n",
            "8822/8822 [==============================] - 6s 699us/step - loss: 0.0064 - acc: 0.9984 - val_loss: 0.0961 - val_acc: 0.9905\n",
            "Epoch 126/150\n",
            "8822/8822 [==============================] - 6s 695us/step - loss: 0.0071 - acc: 0.9991 - val_loss: 0.2178 - val_acc: 0.9830\n",
            "Epoch 127/150\n",
            "8822/8822 [==============================] - 6s 694us/step - loss: 0.0191 - acc: 0.9976 - val_loss: 0.1669 - val_acc: 0.9458\n",
            "Epoch 128/150\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0259 - acc: 0.9938 - val_loss: 0.6325 - val_acc: 0.9599\n",
            "Epoch 129/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0224 - acc: 0.9944 - val_loss: 0.1086 - val_acc: 0.9871\n",
            "Epoch 130/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0157 - acc: 0.9958 - val_loss: 0.0788 - val_acc: 0.9835\n",
            "Epoch 131/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0107 - acc: 0.9978 - val_loss: 0.0752 - val_acc: 0.9884\n",
            "Epoch 132/150\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0092 - acc: 0.9989 - val_loss: 0.0679 - val_acc: 0.9873\n",
            "Epoch 133/150\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0043 - acc: 0.9993 - val_loss: 0.0701 - val_acc: 0.9889\n",
            "Epoch 134/150\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0051 - acc: 0.9990 - val_loss: 0.0828 - val_acc: 0.9889\n",
            "Epoch 135/150\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0053 - acc: 0.9991 - val_loss: 0.1293 - val_acc: 0.9884\n",
            "Epoch 136/150\n",
            "8822/8822 [==============================] - 6s 696us/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.1078 - val_acc: 0.9893\n",
            "Epoch 137/150\n",
            "8822/8822 [==============================] - 6s 696us/step - loss: 0.0034 - acc: 0.9997 - val_loss: 0.0960 - val_acc: 0.9907\n",
            "Epoch 138/150\n",
            "8822/8822 [==============================] - 6s 695us/step - loss: 0.0038 - acc: 0.9993 - val_loss: 0.0813 - val_acc: 0.9896\n",
            "Epoch 139/150\n",
            "8822/8822 [==============================] - 6s 694us/step - loss: 0.0128 - acc: 0.9974 - val_loss: 0.0918 - val_acc: 0.9859\n",
            "Epoch 140/150\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0267 - acc: 0.9954 - val_loss: 0.1520 - val_acc: 0.9467\n",
            "Epoch 141/150\n",
            "8822/8822 [==============================] - 6s 694us/step - loss: 0.0212 - acc: 0.9934 - val_loss: 0.1633 - val_acc: 0.9859\n",
            "Epoch 142/150\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0115 - acc: 0.9964 - val_loss: 0.1063 - val_acc: 0.9887\n",
            "Epoch 143/150\n",
            "8822/8822 [==============================] - 6s 694us/step - loss: 0.0097 - acc: 0.9976 - val_loss: 0.0907 - val_acc: 0.9893\n",
            "Epoch 144/150\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0048 - acc: 0.9991 - val_loss: 0.1476 - val_acc: 0.9875\n",
            "Epoch 145/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0082 - acc: 0.9981 - val_loss: 0.1119 - val_acc: 0.9841\n",
            "Epoch 146/150\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0088 - acc: 0.9986 - val_loss: 0.1155 - val_acc: 0.9798\n",
            "Epoch 147/150\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.1340 - val_acc: 0.9880\n",
            "Epoch 148/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0141 - acc: 0.9978 - val_loss: 0.1093 - val_acc: 0.9887\n",
            "Epoch 149/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0057 - acc: 0.9986 - val_loss: 0.0994 - val_acc: 0.9884\n",
            "Epoch 150/150\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0113 - acc: 0.9975 - val_loss: 0.0980 - val_acc: 0.9893\n",
            "Bush F1 Score on Train :  0.9900990099009902\n",
            "Bush F1 Score on Test :  0.8605341246290801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CecKkWFrMdUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6135
        },
        "outputId": "0ea58eba-cf99-470f-e13d-23b1a7ccc9a0"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "modelForBush=load_model(\"initialized-model.keras\")\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_reshaped, \n",
        "             y_bush,shuffle = True ,test_size= 1./3, random_state=6099, stratify  = y_bush) # A20396099\n",
        "\n",
        "\n",
        "modelForBush.fit(X_train_b,y_train_b, epochs=170, batch_size=32, validation_data = (X_test_b, y_test_b ) )\n",
        "\n",
        "y_predicted_train_bush = modelForBush.predict_classes(X_train_b) \n",
        "y_predicted_test_bush = modelForBush.predict_classes(X_test_b) \n",
        "result_f1_train_bush_E70=f1_score(y_train_b, y_predicted_train_bush)\n",
        "result_f1_test_bush_E70=f1_score(y_test_b, y_predicted_test_bush)\n",
        "print(\"Bush F1 Score on Train : \",result_f1_train_bush_E70)\n",
        "print(\"Bush F1 Score on Test : \",result_f1_test_bush_E70)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8822 samples, validate on 4411 samples\n",
            "Epoch 1/170\n",
            "8822/8822 [==============================] - 7s 820us/step - loss: 0.3264 - acc: 0.9471 - val_loss: 0.2082 - val_acc: 0.9599\n",
            "Epoch 2/170\n",
            "8822/8822 [==============================] - 7s 756us/step - loss: 0.1736 - acc: 0.9600 - val_loss: 0.2080 - val_acc: 0.9599\n",
            "Epoch 3/170\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.1510 - acc: 0.9600 - val_loss: 0.2142 - val_acc: 0.9599\n",
            "Epoch 4/170\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.1392 - acc: 0.9600 - val_loss: 0.1535 - val_acc: 0.9599\n",
            "Epoch 5/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.1275 - acc: 0.9600 - val_loss: 0.6373 - val_acc: 0.9599\n",
            "Epoch 6/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.1126 - acc: 0.9600 - val_loss: 0.1843 - val_acc: 0.9599\n",
            "Epoch 7/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.1086 - acc: 0.9600 - val_loss: 0.2392 - val_acc: 0.9599\n",
            "Epoch 8/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0962 - acc: 0.9600 - val_loss: 0.1360 - val_acc: 0.9599\n",
            "Epoch 9/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0890 - acc: 0.9600 - val_loss: 0.1786 - val_acc: 0.9599\n",
            "Epoch 10/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0872 - acc: 0.9600 - val_loss: 0.1529 - val_acc: 0.9599\n",
            "Epoch 11/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0787 - acc: 0.9627 - val_loss: 0.4681 - val_acc: 0.7386\n",
            "Epoch 12/170\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0634 - acc: 0.9710 - val_loss: 0.8380 - val_acc: 0.6112\n",
            "Epoch 13/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0478 - acc: 0.9811 - val_loss: 0.1280 - val_acc: 0.9669\n",
            "Epoch 14/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0420 - acc: 0.9831 - val_loss: 0.1492 - val_acc: 0.9710\n",
            "Epoch 15/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0406 - acc: 0.9845 - val_loss: 0.1864 - val_acc: 0.9662\n",
            "Epoch 16/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0345 - acc: 0.9849 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 17/170\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0362 - acc: 0.9856 - val_loss: 0.4616 - val_acc: 0.9601\n",
            "Epoch 18/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0346 - acc: 0.9855 - val_loss: 0.3060 - val_acc: 0.9599\n",
            "Epoch 19/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0304 - acc: 0.9863 - val_loss: 0.1539 - val_acc: 0.9744\n",
            "Epoch 20/170\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0202 - acc: 0.9895 - val_loss: 5.6510 - val_acc: 0.2115\n",
            "Epoch 21/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0194 - acc: 0.9907 - val_loss: 0.1418 - val_acc: 0.9712\n",
            "Epoch 22/170\n",
            "8822/8822 [==============================] - 6s 675us/step - loss: 0.0147 - acc: 0.9917 - val_loss: 0.3497 - val_acc: 0.9662\n",
            "Epoch 23/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0138 - acc: 0.9907 - val_loss: 0.1129 - val_acc: 0.9778\n",
            "Epoch 24/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0223 - acc: 0.9892 - val_loss: 0.4143 - val_acc: 0.9615\n",
            "Epoch 25/170\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0264 - acc: 0.9876 - val_loss: 0.2841 - val_acc: 0.9159\n",
            "Epoch 26/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0128 - acc: 0.9906 - val_loss: 0.1571 - val_acc: 0.9703\n",
            "Epoch 27/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0124 - acc: 0.9922 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 28/170\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0119 - acc: 0.9957 - val_loss: 0.1163 - val_acc: 0.9800\n",
            "Epoch 29/170\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0157 - acc: 0.9967 - val_loss: 0.3682 - val_acc: 0.8547\n",
            "Epoch 30/170\n",
            "8822/8822 [==============================] - 6s 698us/step - loss: 0.0135 - acc: 0.9967 - val_loss: 0.4701 - val_acc: 0.8764\n",
            "Epoch 31/170\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0135 - acc: 0.9967 - val_loss: 0.2720 - val_acc: 0.9717\n",
            "Epoch 32/170\n",
            "8822/8822 [==============================] - 6s 675us/step - loss: 0.0151 - acc: 0.9972 - val_loss: 0.1752 - val_acc: 0.9356\n",
            "Epoch 33/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0145 - acc: 0.9959 - val_loss: 0.2250 - val_acc: 0.9751\n",
            "Epoch 34/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.1893 - val_acc: 0.9791\n",
            "Epoch 35/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0158 - acc: 0.9963 - val_loss: 0.2067 - val_acc: 0.9689\n",
            "Epoch 36/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.4189 - val_acc: 0.9674\n",
            "Epoch 37/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0247 - acc: 0.9964 - val_loss: 0.1156 - val_acc: 0.9737\n",
            "Epoch 38/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0141 - acc: 0.9969 - val_loss: 0.1950 - val_acc: 0.9732\n",
            "Epoch 39/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0165 - acc: 0.9956 - val_loss: 0.3162 - val_acc: 0.9658\n",
            "Epoch 40/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0150 - acc: 0.9958 - val_loss: 0.5583 - val_acc: 0.9606\n",
            "Epoch 41/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0204 - acc: 0.9959 - val_loss: 1.8187 - val_acc: 0.3902\n",
            "Epoch 42/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0129 - acc: 0.9971 - val_loss: 0.4305 - val_acc: 0.8726\n",
            "Epoch 43/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0085 - acc: 0.9985 - val_loss: 0.0870 - val_acc: 0.9805\n",
            "Epoch 44/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0084 - acc: 0.9980 - val_loss: 0.2056 - val_acc: 0.9669\n",
            "Epoch 45/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0100 - acc: 0.9980 - val_loss: 0.1232 - val_acc: 0.9596\n",
            "Epoch 46/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0101 - acc: 0.9967 - val_loss: 0.1671 - val_acc: 0.9669\n",
            "Epoch 47/170\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0091 - acc: 0.9978 - val_loss: 0.1870 - val_acc: 0.9812\n",
            "Epoch 48/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0092 - acc: 0.9982 - val_loss: 1.3855 - val_acc: 0.6250\n",
            "Epoch 49/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.1158 - val_acc: 0.9782\n",
            "Epoch 50/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0107 - acc: 0.9981 - val_loss: 0.2401 - val_acc: 0.9778\n",
            "Epoch 51/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0127 - acc: 0.9980 - val_loss: 0.2163 - val_acc: 0.9388\n",
            "Epoch 52/170\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0084 - acc: 0.9982 - val_loss: 0.1614 - val_acc: 0.9721\n",
            "Epoch 53/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0299 - acc: 0.9939 - val_loss: 0.1065 - val_acc: 0.9844\n",
            "Epoch 54/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0059 - acc: 0.9988 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 55/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0112 - acc: 0.9972 - val_loss: 0.4993 - val_acc: 0.8613\n",
            "Epoch 56/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0118 - acc: 0.9977 - val_loss: 0.6449 - val_acc: 0.9599\n",
            "Epoch 57/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.1997 - val_acc: 0.9812\n",
            "Epoch 58/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0054 - acc: 0.9994 - val_loss: 0.4270 - val_acc: 0.9678\n",
            "Epoch 59/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.1288 - val_acc: 0.9839\n",
            "Epoch 60/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0115 - acc: 0.9974 - val_loss: 0.6162 - val_acc: 0.9606\n",
            "Epoch 61/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0160 - acc: 0.9960 - val_loss: 0.6447 - val_acc: 0.9599\n",
            "Epoch 62/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0247 - acc: 0.9938 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 63/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0195 - acc: 0.9951 - val_loss: 0.5496 - val_acc: 0.9640\n",
            "Epoch 64/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.1710 - val_acc: 0.9825\n",
            "Epoch 65/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0113 - acc: 0.9974 - val_loss: 0.2047 - val_acc: 0.8993\n",
            "Epoch 66/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0065 - acc: 0.9983 - val_loss: 0.1029 - val_acc: 0.9832\n",
            "Epoch 67/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0127 - acc: 0.9969 - val_loss: 1.0387 - val_acc: 0.6640\n",
            "Epoch 68/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0100 - acc: 0.9983 - val_loss: 0.1161 - val_acc: 0.9812\n",
            "Epoch 69/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0111 - acc: 0.9969 - val_loss: 0.1392 - val_acc: 0.9839\n",
            "Epoch 70/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0093 - acc: 0.9975 - val_loss: 0.1192 - val_acc: 0.9773\n",
            "Epoch 71/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0100 - acc: 0.9978 - val_loss: 0.4177 - val_acc: 0.9692\n",
            "Epoch 72/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.1583 - val_acc: 0.9798\n",
            "Epoch 73/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0149 - acc: 0.9971 - val_loss: 0.1634 - val_acc: 0.9628\n",
            "Epoch 74/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0101 - acc: 0.9973 - val_loss: 0.1668 - val_acc: 0.9841\n",
            "Epoch 75/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.5690 - val_acc: 0.8032\n",
            "Epoch 76/170\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0106 - acc: 0.9971 - val_loss: 0.6059 - val_acc: 0.9610\n",
            "Epoch 77/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0044 - acc: 0.9982 - val_loss: 0.0972 - val_acc: 0.9844\n",
            "Epoch 78/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0087 - acc: 0.9988 - val_loss: 10.4465 - val_acc: 0.1621\n",
            "Epoch 79/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0327 - acc: 0.9914 - val_loss: 0.1344 - val_acc: 0.9728\n",
            "Epoch 80/170\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0112 - acc: 0.9963 - val_loss: 0.1169 - val_acc: 0.9499\n",
            "Epoch 81/170\n",
            "8822/8822 [==============================] - 6s 706us/step - loss: 0.0072 - acc: 0.9983 - val_loss: 0.1769 - val_acc: 0.9825\n",
            "Epoch 82/170\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0103 - acc: 0.9986 - val_loss: 0.4669 - val_acc: 0.9655\n",
            "Epoch 83/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0118 - acc: 0.9981 - val_loss: 0.1651 - val_acc: 0.9850\n",
            "Epoch 84/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.2690 - val_acc: 0.9746\n",
            "Epoch 85/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0165 - acc: 0.9969 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 86/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0111 - acc: 0.9967 - val_loss: 0.1309 - val_acc: 0.9683\n",
            "Epoch 87/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0112 - acc: 0.9975 - val_loss: 0.2740 - val_acc: 0.9748\n",
            "Epoch 88/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0046 - acc: 0.9993 - val_loss: 0.2442 - val_acc: 0.9800\n",
            "Epoch 89/170\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.1189 - val_acc: 0.9805\n",
            "Epoch 90/170\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.2020 - val_acc: 0.9810\n",
            "Epoch 91/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.1077 - val_acc: 0.9884\n",
            "Epoch 92/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0880 - val_acc: 0.9884\n",
            "Epoch 93/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0031 - acc: 0.9992 - val_loss: 0.6241 - val_acc: 0.9606\n",
            "Epoch 94/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.1320 - val_acc: 0.9875\n",
            "Epoch 95/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0088 - acc: 0.9982 - val_loss: 0.1613 - val_acc: 0.9710\n",
            "Epoch 96/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.2529 - val_acc: 0.9803\n",
            "Epoch 97/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0111 - acc: 0.9972 - val_loss: 0.2928 - val_acc: 0.9776\n",
            "Epoch 98/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.1661 - val_acc: 0.9615\n",
            "Epoch 99/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0080 - acc: 0.9978 - val_loss: 0.1511 - val_acc: 0.9721\n",
            "Epoch 100/170\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0230 - acc: 0.9942 - val_loss: 0.1155 - val_acc: 0.9771\n",
            "Epoch 101/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0098 - acc: 0.9977 - val_loss: 0.2497 - val_acc: 0.9789\n",
            "Epoch 102/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0102 - acc: 0.9977 - val_loss: 0.6456 - val_acc: 0.9599\n",
            "Epoch 103/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0137 - acc: 0.9966 - val_loss: 0.1001 - val_acc: 0.9837\n",
            "Epoch 104/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0956 - val_acc: 0.9626\n",
            "Epoch 105/170\n",
            "8822/8822 [==============================] - 6s 700us/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.1751 - val_acc: 0.9150\n",
            "Epoch 106/170\n",
            "8822/8822 [==============================] - 7s 758us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.5099 - val_acc: 0.9637\n",
            "Epoch 107/170\n",
            "8822/8822 [==============================] - 6s 695us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.1491 - val_acc: 0.9866\n",
            "Epoch 108/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.1478 - val_acc: 0.9846\n",
            "Epoch 109/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.1462 - val_acc: 0.9696\n",
            "Epoch 110/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0082 - acc: 0.9991 - val_loss: 0.1870 - val_acc: 0.9862\n",
            "Epoch 111/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0145 - acc: 0.9978 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 112/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0133 - acc: 0.9961 - val_loss: 0.1219 - val_acc: 0.9567\n",
            "Epoch 113/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.4603 - val_acc: 0.8764\n",
            "Epoch 114/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0092 - acc: 0.9985 - val_loss: 0.2254 - val_acc: 0.9814\n",
            "Epoch 115/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0825 - val_acc: 0.9780\n",
            "Epoch 116/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0015 - acc: 0.9998 - val_loss: 0.0889 - val_acc: 0.9846\n",
            "Epoch 117/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0922 - val_acc: 0.9859\n",
            "Epoch 118/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0132 - acc: 0.9981 - val_loss: 0.2898 - val_acc: 0.9773\n",
            "Epoch 119/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0131 - acc: 0.9965 - val_loss: 0.1031 - val_acc: 0.9742\n",
            "Epoch 120/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.1096 - val_acc: 0.9819\n",
            "Epoch 121/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.2283 - val_acc: 0.9830\n",
            "Epoch 122/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0081 - acc: 0.9976 - val_loss: 0.1326 - val_acc: 0.9862\n",
            "Epoch 123/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0065 - acc: 0.9975 - val_loss: 0.2725 - val_acc: 0.9052\n",
            "Epoch 124/170\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 125/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0596 - val_acc: 0.9819\n",
            "Epoch 126/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0804 - val_acc: 0.9762\n",
            "Epoch 127/170\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0046 - acc: 0.9990 - val_loss: 0.1775 - val_acc: 0.9839\n",
            "Epoch 128/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0114 - acc: 0.9966 - val_loss: 0.4838 - val_acc: 0.9633\n",
            "Epoch 129/170\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0144 - acc: 0.9977 - val_loss: 0.3731 - val_acc: 0.9708\n",
            "Epoch 130/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0194 - acc: 0.9955 - val_loss: 0.1139 - val_acc: 0.9878\n",
            "Epoch 131/170\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0026 - acc: 0.9997 - val_loss: 0.4608 - val_acc: 0.9635\n",
            "Epoch 132/170\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0903 - val_acc: 0.9789\n",
            "Epoch 133/170\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0175 - acc: 0.9963 - val_loss: 0.2530 - val_acc: 0.9791\n",
            "Epoch 134/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0197 - acc: 0.9961 - val_loss: 0.1697 - val_acc: 0.9835\n",
            "Epoch 135/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0037 - acc: 0.9984 - val_loss: 0.1256 - val_acc: 0.9866\n",
            "Epoch 136/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0041 - acc: 0.9985 - val_loss: 0.2192 - val_acc: 0.9814\n",
            "Epoch 137/170\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0038 - acc: 0.9986 - val_loss: 0.0943 - val_acc: 0.9844\n",
            "Epoch 138/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0051 - acc: 0.9988 - val_loss: 0.1345 - val_acc: 0.9871\n",
            "Epoch 139/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.1236 - val_acc: 0.9846\n",
            "Epoch 140/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0059 - acc: 0.9986 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 141/170\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.1232 - val_acc: 0.9864\n",
            "Epoch 142/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0268 - acc: 0.9939 - val_loss: 0.2340 - val_acc: 0.9735\n",
            "Epoch 143/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0536 - acc: 0.9827 - val_loss: 0.4020 - val_acc: 0.9628\n",
            "Epoch 144/170\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0080 - acc: 0.9977 - val_loss: 0.0687 - val_acc: 0.9866\n",
            "Epoch 145/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0706 - val_acc: 0.9835\n",
            "Epoch 146/170\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.1027 - val_acc: 0.9839\n",
            "Epoch 147/170\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0078 - acc: 0.9986 - val_loss: 0.0949 - val_acc: 0.9880\n",
            "Epoch 148/170\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9903\n",
            "Epoch 149/170\n",
            "8822/8822 [==============================] - 6s 710us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0784 - val_acc: 0.9875\n",
            "Epoch 150/170\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0910 - val_acc: 0.9837\n",
            "Epoch 151/170\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 7.3607e-04 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9900\n",
            "Epoch 152/170\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0141 - acc: 0.9974 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 153/170\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0401 - acc: 0.9923 - val_loss: 0.2010 - val_acc: 0.9823\n",
            "Epoch 154/170\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0375 - acc: 0.9918 - val_loss: 0.4619 - val_acc: 0.9669\n",
            "Epoch 155/170\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0213 - acc: 0.9935 - val_loss: 0.2422 - val_acc: 0.9828\n",
            "Epoch 156/170\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0191 - acc: 0.9963 - val_loss: 0.1922 - val_acc: 0.9848\n",
            "Epoch 157/170\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0279 - acc: 0.9938 - val_loss: 0.3849 - val_acc: 0.9678\n",
            "Epoch 158/170\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0093 - acc: 0.9965 - val_loss: 0.0662 - val_acc: 0.9880\n",
            "Epoch 159/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.1074 - val_acc: 0.9873\n",
            "Epoch 160/170\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0064 - acc: 0.9984 - val_loss: 0.1436 - val_acc: 0.9835\n",
            "Epoch 161/170\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0718 - val_acc: 0.9819\n",
            "Epoch 162/170\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0043 - acc: 0.9993 - val_loss: 0.0690 - val_acc: 0.9844\n",
            "Epoch 163/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0622 - val_acc: 0.9893\n",
            "Epoch 164/170\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0677 - val_acc: 0.9898\n",
            "Epoch 165/170\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0068 - acc: 0.9983 - val_loss: 0.6143 - val_acc: 0.9601\n",
            "Epoch 166/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0087 - acc: 0.9980 - val_loss: 0.2209 - val_acc: 0.9526\n",
            "Epoch 167/170\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0181 - acc: 0.9943 - val_loss: 0.4020 - val_acc: 0.9685\n",
            "Epoch 168/170\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0108 - acc: 0.9978 - val_loss: 0.0980 - val_acc: 0.9887\n",
            "Epoch 169/170\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0039 - acc: 0.9994 - val_loss: 0.0958 - val_acc: 0.9898\n",
            "Epoch 170/170\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0042 - acc: 0.9994 - val_loss: 0.0950 - val_acc: 0.9871\n",
            "Bush F1 Score on Train :  1.0\n",
            "Bush F1 Score on Test :  0.8347826086956522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xIrQliN9mTuz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5759
        },
        "outputId": "44bdab4a-c322-434c-8e92-d27eda6573db"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "modelForBush=load_model(\"initialized-model.keras\")\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_reshaped, \n",
        "             y_bush,shuffle = True ,test_size= 1./3, random_state=6099, stratify  = y_bush) # A20396099\n",
        "\n",
        "\n",
        "modelForBush.fit(X_train_b,y_train_b, epochs=160, batch_size=32, validation_data = (X_test_b, y_test_b ) )\n",
        "\n",
        "y_predicted_train_bush = modelForBush.predict_classes(X_train_b) \n",
        "y_predicted_test_bush = modelForBush.predict_classes(X_test_b) \n",
        "result_f1_train_bush_E70=f1_score(y_train_b, y_predicted_train_bush)\n",
        "result_f1_test_bush_E70=f1_score(y_test_b, y_predicted_test_bush)\n",
        "print(\"Bush F1 Score on Train : \",result_f1_train_bush_E70)\n",
        "print(\"Bush F1 Score on Test : \",result_f1_test_bush_E70)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8822 samples, validate on 4411 samples\n",
            "Epoch 1/160\n",
            "8822/8822 [==============================] - 7s 816us/step - loss: 0.2925 - acc: 0.9455 - val_loss: 0.2377 - val_acc: 0.9599\n",
            "Epoch 2/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.1757 - acc: 0.9600 - val_loss: 0.1664 - val_acc: 0.9599\n",
            "Epoch 3/160\n",
            "8822/8822 [==============================] - 6s 694us/step - loss: 0.1572 - acc: 0.9600 - val_loss: 0.4312 - val_acc: 0.9599\n",
            "Epoch 4/160\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.1478 - acc: 0.9600 - val_loss: 0.5082 - val_acc: 0.9599\n",
            "Epoch 5/160\n",
            "8822/8822 [==============================] - 6s 694us/step - loss: 0.1451 - acc: 0.9600 - val_loss: 0.1826 - val_acc: 0.9599\n",
            "Epoch 6/160\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.1292 - acc: 0.9600 - val_loss: 0.2863 - val_acc: 0.9599\n",
            "Epoch 7/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.1341 - acc: 0.9600 - val_loss: 0.4116 - val_acc: 0.9599\n",
            "Epoch 8/160\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.1155 - acc: 0.9600 - val_loss: 0.2077 - val_acc: 0.9599\n",
            "Epoch 9/160\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.1121 - acc: 0.9600 - val_loss: 0.1738 - val_acc: 0.9599\n",
            "Epoch 10/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.1004 - acc: 0.9600 - val_loss: 0.1481 - val_acc: 0.9599\n",
            "Epoch 11/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0924 - acc: 0.9600 - val_loss: 0.6265 - val_acc: 0.9599\n",
            "Epoch 12/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0872 - acc: 0.9599 - val_loss: 0.1655 - val_acc: 0.9599\n",
            "Epoch 13/160\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0819 - acc: 0.9600 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 14/160\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0751 - acc: 0.9600 - val_loss: 0.1613 - val_acc: 0.9599\n",
            "Epoch 15/160\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0669 - acc: 0.9599 - val_loss: 0.3839 - val_acc: 0.9599\n",
            "Epoch 16/160\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0661 - acc: 0.9599 - val_loss: 0.1189 - val_acc: 0.9599\n",
            "Epoch 17/160\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0629 - acc: 0.9600 - val_loss: 0.3788 - val_acc: 0.9599\n",
            "Epoch 18/160\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0690 - acc: 0.9600 - val_loss: 0.3736 - val_acc: 0.9599\n",
            "Epoch 19/160\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0533 - acc: 0.9600 - val_loss: 0.4623 - val_acc: 0.9599\n",
            "Epoch 20/160\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0456 - acc: 0.9791 - val_loss: 0.1181 - val_acc: 0.9576\n",
            "Epoch 21/160\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0423 - acc: 0.9899 - val_loss: 0.1227 - val_acc: 0.9785\n",
            "Epoch 22/160\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0422 - acc: 0.9913 - val_loss: 0.1329 - val_acc: 0.9723\n",
            "Epoch 23/160\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0375 - acc: 0.9909 - val_loss: 0.1623 - val_acc: 0.9082\n",
            "Epoch 24/160\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0351 - acc: 0.9910 - val_loss: 0.6019 - val_acc: 0.9606\n",
            "Epoch 25/160\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0287 - acc: 0.9935 - val_loss: 0.1986 - val_acc: 0.9778\n",
            "Epoch 26/160\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0383 - acc: 0.9897 - val_loss: 0.3597 - val_acc: 0.9624\n",
            "Epoch 27/160\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0299 - acc: 0.9932 - val_loss: 0.2375 - val_acc: 0.9703\n",
            "Epoch 28/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0269 - acc: 0.9938 - val_loss: 0.2433 - val_acc: 0.8452\n",
            "Epoch 29/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0235 - acc: 0.9949 - val_loss: 0.6327 - val_acc: 0.9599\n",
            "Epoch 30/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0245 - acc: 0.9956 - val_loss: 0.2972 - val_acc: 0.9712\n",
            "Epoch 31/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0224 - acc: 0.9949 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 32/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0359 - acc: 0.9915 - val_loss: 0.5268 - val_acc: 0.9603\n",
            "Epoch 33/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0475 - acc: 0.9863 - val_loss: 0.6251 - val_acc: 0.9599\n",
            "Epoch 34/160\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0340 - acc: 0.9905 - val_loss: 0.1725 - val_acc: 0.9401\n",
            "Epoch 35/160\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0512 - acc: 0.9838 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 36/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0371 - acc: 0.9907 - val_loss: 0.1441 - val_acc: 0.9522\n",
            "Epoch 37/160\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0270 - acc: 0.9939 - val_loss: 0.1599 - val_acc: 0.9803\n",
            "Epoch 38/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0276 - acc: 0.9929 - val_loss: 0.2370 - val_acc: 0.9732\n",
            "Epoch 39/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0195 - acc: 0.9961 - val_loss: 0.0931 - val_acc: 0.9780\n",
            "Epoch 40/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0170 - acc: 0.9958 - val_loss: 0.1103 - val_acc: 0.9744\n",
            "Epoch 41/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0181 - acc: 0.9958 - val_loss: 0.6414 - val_acc: 0.9599\n",
            "Epoch 42/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0160 - acc: 0.9978 - val_loss: 0.3545 - val_acc: 0.9658\n",
            "Epoch 43/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0257 - acc: 0.9946 - val_loss: 0.0949 - val_acc: 0.9685\n",
            "Epoch 44/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0131 - acc: 0.9973 - val_loss: 0.0645 - val_acc: 0.9855\n",
            "Epoch 45/160\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0130 - acc: 0.9968 - val_loss: 0.0971 - val_acc: 0.9796\n",
            "Epoch 46/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0102 - acc: 0.9978 - val_loss: 0.1648 - val_acc: 0.9358\n",
            "Epoch 47/160\n",
            "8822/8822 [==============================] - 6s 675us/step - loss: 0.0235 - acc: 0.9941 - val_loss: 0.6337 - val_acc: 0.9599\n",
            "Epoch 48/160\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0183 - acc: 0.9957 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 49/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0155 - acc: 0.9968 - val_loss: 0.7393 - val_acc: 0.6903\n",
            "Epoch 50/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0133 - acc: 0.9973 - val_loss: 0.6448 - val_acc: 0.9599\n",
            "Epoch 51/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0181 - acc: 0.9956 - val_loss: 0.5164 - val_acc: 0.7833\n",
            "Epoch 52/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0411 - acc: 0.9891 - val_loss: 0.2448 - val_acc: 0.9241\n",
            "Epoch 53/160\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0227 - acc: 0.9952 - val_loss: 0.6454 - val_acc: 0.9599\n",
            "Epoch 54/160\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0135 - acc: 0.9956 - val_loss: 0.0738 - val_acc: 0.9778\n",
            "Epoch 55/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0102 - acc: 0.9985 - val_loss: 0.1555 - val_acc: 0.9825\n",
            "Epoch 56/160\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0123 - acc: 0.9975 - val_loss: 0.1499 - val_acc: 0.9846\n",
            "Epoch 57/160\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0132 - acc: 0.9976 - val_loss: 0.1606 - val_acc: 0.9832\n",
            "Epoch 58/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0168 - acc: 0.9968 - val_loss: 0.1339 - val_acc: 0.9776\n",
            "Epoch 59/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0436 - acc: 0.9889 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 60/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0276 - acc: 0.9910 - val_loss: 0.0783 - val_acc: 0.9800\n",
            "Epoch 61/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0301 - acc: 0.9914 - val_loss: 0.1147 - val_acc: 0.9635\n",
            "Epoch 62/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0230 - acc: 0.9937 - val_loss: 0.0997 - val_acc: 0.9676\n",
            "Epoch 63/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0200 - acc: 0.9955 - val_loss: 0.0682 - val_acc: 0.9839\n",
            "Epoch 64/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0211 - acc: 0.9942 - val_loss: 0.2399 - val_acc: 0.9708\n",
            "Epoch 65/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0122 - acc: 0.9976 - val_loss: 0.1099 - val_acc: 0.9866\n",
            "Epoch 66/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0104 - acc: 0.9978 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 67/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0128 - acc: 0.9964 - val_loss: 0.5029 - val_acc: 0.8130\n",
            "Epoch 68/160\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0157 - acc: 0.9966 - val_loss: 0.4090 - val_acc: 0.9689\n",
            "Epoch 69/160\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0240 - acc: 0.9949 - val_loss: 0.0651 - val_acc: 0.9878\n",
            "Epoch 70/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0737 - val_acc: 0.9873\n",
            "Epoch 71/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0147 - acc: 0.9971 - val_loss: 0.4106 - val_acc: 0.9658\n",
            "Epoch 72/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0151 - acc: 0.9957 - val_loss: 0.0870 - val_acc: 0.9712\n",
            "Epoch 73/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.1540 - val_acc: 0.9819\n",
            "Epoch 74/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0090 - acc: 0.9982 - val_loss: 0.1729 - val_acc: 0.9798\n",
            "Epoch 75/160\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0119 - acc: 0.9973 - val_loss: 0.5604 - val_acc: 0.9615\n",
            "Epoch 76/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0200 - acc: 0.9947 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 77/160\n",
            "8822/8822 [==============================] - 6s 675us/step - loss: 0.0228 - acc: 0.9947 - val_loss: 0.6448 - val_acc: 0.9599\n",
            "Epoch 78/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0826 - val_acc: 0.9621\n",
            "Epoch 79/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0086 - acc: 0.9983 - val_loss: 0.2079 - val_acc: 0.9807\n",
            "Epoch 80/160\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0202 - acc: 0.9950 - val_loss: 0.2787 - val_acc: 0.8590\n",
            "Epoch 81/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0187 - acc: 0.9948 - val_loss: 0.6306 - val_acc: 0.9599\n",
            "Epoch 82/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0081 - acc: 0.9976 - val_loss: 0.0757 - val_acc: 0.9701\n",
            "Epoch 83/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0098 - acc: 0.9980 - val_loss: 0.7536 - val_acc: 0.6327\n",
            "Epoch 84/160\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0093 - acc: 0.9983 - val_loss: 0.0884 - val_acc: 0.9853\n",
            "Epoch 85/160\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0470 - acc: 0.9897 - val_loss: 0.5699 - val_acc: 0.9619\n",
            "Epoch 86/160\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0314 - acc: 0.9935 - val_loss: 0.3045 - val_acc: 0.9739\n",
            "Epoch 87/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0194 - acc: 0.9954 - val_loss: 0.1117 - val_acc: 0.9644\n",
            "Epoch 88/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0105 - acc: 0.9976 - val_loss: 0.0925 - val_acc: 0.9862\n",
            "Epoch 89/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0147 - acc: 0.9965 - val_loss: 1.9066 - val_acc: 0.2546\n",
            "Epoch 90/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0107 - acc: 0.9968 - val_loss: 0.6331 - val_acc: 0.9599\n",
            "Epoch 91/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0856 - val_acc: 0.9857\n",
            "Epoch 92/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0108 - acc: 0.9978 - val_loss: 0.1692 - val_acc: 0.9841\n",
            "Epoch 93/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0093 - acc: 0.9976 - val_loss: 0.0956 - val_acc: 0.9855\n",
            "Epoch 94/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0083 - acc: 0.9984 - val_loss: 0.0656 - val_acc: 0.9853\n",
            "Epoch 95/160\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0055 - acc: 0.9989 - val_loss: 0.0690 - val_acc: 0.9837\n",
            "Epoch 96/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.1108 - val_acc: 0.9873\n",
            "Epoch 97/160\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0124 - acc: 0.9968 - val_loss: 0.6313 - val_acc: 0.9599\n",
            "Epoch 98/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0089 - acc: 0.9983 - val_loss: 0.0845 - val_acc: 0.9728\n",
            "Epoch 99/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0127 - acc: 0.9973 - val_loss: 0.6167 - val_acc: 0.9610\n",
            "Epoch 100/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0219 - acc: 0.9946 - val_loss: 0.0671 - val_acc: 0.9869\n",
            "Epoch 101/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0790 - val_acc: 0.9871\n",
            "Epoch 102/160\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0068 - acc: 0.9986 - val_loss: 0.1189 - val_acc: 0.9653\n",
            "Epoch 103/160\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0107 - acc: 0.9973 - val_loss: 0.0777 - val_acc: 0.9841\n",
            "Epoch 104/160\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0095 - acc: 0.9976 - val_loss: 0.0887 - val_acc: 0.9823\n",
            "Epoch 105/160\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0225 - acc: 0.9949 - val_loss: 0.1316 - val_acc: 0.9850\n",
            "Epoch 106/160\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0310 - acc: 0.9920 - val_loss: 0.1039 - val_acc: 0.9855\n",
            "Epoch 107/160\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0226 - acc: 0.9956 - val_loss: 0.6446 - val_acc: 0.9599\n",
            "Epoch 108/160\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0255 - acc: 0.9937 - val_loss: 0.0867 - val_acc: 0.9853\n",
            "Epoch 109/160\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0155 - acc: 0.9973 - val_loss: 0.2265 - val_acc: 0.9776\n",
            "Epoch 110/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0149 - acc: 0.9972 - val_loss: 0.3445 - val_acc: 0.9719\n",
            "Epoch 111/160\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0096 - acc: 0.9984 - val_loss: 0.1997 - val_acc: 0.9286\n",
            "Epoch 112/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0261 - acc: 0.9920 - val_loss: 0.1105 - val_acc: 0.9850\n",
            "Epoch 113/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0087 - acc: 0.9977 - val_loss: 0.0816 - val_acc: 0.9869\n",
            "Epoch 114/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0135 - acc: 0.9968 - val_loss: 0.1447 - val_acc: 0.9560\n",
            "Epoch 115/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.1211 - val_acc: 0.9859\n",
            "Epoch 116/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0295 - acc: 0.9929 - val_loss: 0.2518 - val_acc: 0.9787\n",
            "Epoch 117/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0191 - acc: 0.9961 - val_loss: 0.0874 - val_acc: 0.9814\n",
            "Epoch 118/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0160 - acc: 0.9969 - val_loss: 0.1297 - val_acc: 0.9862\n",
            "Epoch 119/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0263 - acc: 0.9947 - val_loss: 0.5667 - val_acc: 0.9612\n",
            "Epoch 120/160\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0130 - acc: 0.9965 - val_loss: 0.0809 - val_acc: 0.9873\n",
            "Epoch 121/160\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0086 - acc: 0.9984 - val_loss: 0.0877 - val_acc: 0.9882\n",
            "Epoch 122/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0075 - acc: 0.9988 - val_loss: 0.0870 - val_acc: 0.9780\n",
            "Epoch 123/160\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0060 - acc: 0.9994 - val_loss: 0.0827 - val_acc: 0.9846\n",
            "Epoch 124/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0062 - acc: 0.9994 - val_loss: 0.1155 - val_acc: 0.9708\n",
            "Epoch 125/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0088 - acc: 0.9982 - val_loss: 0.0938 - val_acc: 0.9803\n",
            "Epoch 126/160\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0116 - acc: 0.9982 - val_loss: 0.1121 - val_acc: 0.9859\n",
            "Epoch 127/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0065 - acc: 0.9986 - val_loss: 0.1193 - val_acc: 0.9855\n",
            "Epoch 128/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0084 - acc: 0.9985 - val_loss: 0.1834 - val_acc: 0.9869\n",
            "Epoch 129/160\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0115 - acc: 0.9984 - val_loss: 0.3651 - val_acc: 0.9757\n",
            "Epoch 130/160\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0112 - acc: 0.9980 - val_loss: 0.1810 - val_acc: 0.9837\n",
            "Epoch 131/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0094 - acc: 0.9985 - val_loss: 0.1181 - val_acc: 0.9878\n",
            "Epoch 132/160\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0160 - acc: 0.9976 - val_loss: 0.0995 - val_acc: 0.9789\n",
            "Epoch 133/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0177 - acc: 0.9963 - val_loss: 0.3604 - val_acc: 0.8812\n",
            "Epoch 134/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0233 - acc: 0.9949 - val_loss: 0.3659 - val_acc: 0.9757\n",
            "Epoch 135/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0206 - acc: 0.9935 - val_loss: 0.1229 - val_acc: 0.9862\n",
            "Epoch 136/160\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0096 - acc: 0.9977 - val_loss: 0.1664 - val_acc: 0.9850\n",
            "Epoch 137/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0202 - acc: 0.9950 - val_loss: 0.6379 - val_acc: 0.9603\n",
            "Epoch 138/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0296 - acc: 0.9937 - val_loss: 0.1282 - val_acc: 0.9830\n",
            "Epoch 139/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0146 - acc: 0.9957 - val_loss: 0.0864 - val_acc: 0.9762\n",
            "Epoch 140/160\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0065 - acc: 0.9984 - val_loss: 0.2068 - val_acc: 0.9835\n",
            "Epoch 141/160\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0088 - acc: 0.9980 - val_loss: 0.1139 - val_acc: 0.9864\n",
            "Epoch 142/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0086 - acc: 0.9981 - val_loss: 0.1817 - val_acc: 0.9855\n",
            "Epoch 143/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0159 - acc: 0.9985 - val_loss: 0.0973 - val_acc: 0.9769\n",
            "Epoch 144/160\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.2721 - val_acc: 0.9803\n",
            "Epoch 145/160\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0090 - acc: 0.9985 - val_loss: 0.1015 - val_acc: 0.9887\n",
            "Epoch 146/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0062 - acc: 0.9985 - val_loss: 0.1170 - val_acc: 0.9875\n",
            "Epoch 147/160\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0253 - acc: 0.9958 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 148/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0169 - acc: 0.9960 - val_loss: 0.0931 - val_acc: 0.9753\n",
            "Epoch 149/160\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0855 - val_acc: 0.9803\n",
            "Epoch 150/160\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0138 - acc: 0.9974 - val_loss: 0.3584 - val_acc: 0.9746\n",
            "Epoch 151/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.1038 - val_acc: 0.9869\n",
            "Epoch 152/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0124 - acc: 0.9975 - val_loss: 0.2348 - val_acc: 0.9816\n",
            "Epoch 153/160\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0118 - acc: 0.9973 - val_loss: 0.1296 - val_acc: 0.9873\n",
            "Epoch 154/160\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.1570 - val_acc: 0.9864\n",
            "Epoch 155/160\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0064 - acc: 0.9989 - val_loss: 0.1518 - val_acc: 0.9596\n",
            "Epoch 156/160\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0098 - acc: 0.9978 - val_loss: 0.1381 - val_acc: 0.9873\n",
            "Epoch 157/160\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0076 - acc: 0.9986 - val_loss: 0.1143 - val_acc: 0.9875\n",
            "Epoch 158/160\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.1062 - val_acc: 0.9880\n",
            "Epoch 159/160\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0098 - acc: 0.9980 - val_loss: 0.1115 - val_acc: 0.9875\n",
            "Epoch 160/160\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0070 - acc: 0.9986 - val_loss: 0.1269 - val_acc: 0.9882\n",
            "Bush F1 Score on Train :  0.9770114942528736\n",
            "Bush F1 Score on Test :  0.8375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g9Rww8Eaqa0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5581
        },
        "outputId": "12551c35-c6f3-4ccc-b51d-03e8b0df4cd7"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "modelForBush=load_model(\"initialized-model.keras\")\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_reshaped, \n",
        "             y_bush,shuffle = True ,test_size= 1./3, random_state=6099, stratify  = y_bush) # A20396099\n",
        "\n",
        "\n",
        "modelForBush.fit(X_train_b,y_train_b, epochs=155, batch_size=32, validation_data = (X_test_b, y_test_b ) )\n",
        "\n",
        "y_predicted_train_bush = modelForBush.predict_classes(X_train_b) \n",
        "y_predicted_test_bush = modelForBush.predict_classes(X_test_b) \n",
        "result_f1_train_bush_E70=f1_score(y_train_b, y_predicted_train_bush)\n",
        "result_f1_test_bush_E70=f1_score(y_test_b, y_predicted_test_bush)\n",
        "print(\"Bush F1 Score on Train : \",result_f1_train_bush_E70)\n",
        "print(\"Bush F1 Score on Test : \",result_f1_test_bush_E70)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8822 samples, validate on 4411 samples\n",
            "Epoch 1/155\n",
            "8822/8822 [==============================] - 7s 808us/step - loss: 0.3068 - acc: 0.9464 - val_loss: 0.1714 - val_acc: 0.9599\n",
            "Epoch 2/155\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.1780 - acc: 0.9600 - val_loss: 0.1559 - val_acc: 0.9599\n",
            "Epoch 3/155\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.1677 - acc: 0.9600 - val_loss: 0.2189 - val_acc: 0.9599\n",
            "Epoch 4/155\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.1603 - acc: 0.9600 - val_loss: 0.2105 - val_acc: 0.9599\n",
            "Epoch 5/155\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.1511 - acc: 0.9600 - val_loss: 0.2561 - val_acc: 0.9599\n",
            "Epoch 6/155\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.1443 - acc: 0.9600 - val_loss: 0.1588 - val_acc: 0.9599\n",
            "Epoch 7/155\n",
            "8822/8822 [==============================] - 6s 667us/step - loss: 0.1369 - acc: 0.9600 - val_loss: 0.1563 - val_acc: 0.9599\n",
            "Epoch 8/155\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.1308 - acc: 0.9600 - val_loss: 0.2200 - val_acc: 0.9599\n",
            "Epoch 9/155\n",
            "8822/8822 [==============================] - 6s 665us/step - loss: 0.1192 - acc: 0.9600 - val_loss: 0.1857 - val_acc: 0.9599\n",
            "Epoch 10/155\n",
            "8822/8822 [==============================] - 6s 667us/step - loss: 0.1127 - acc: 0.9600 - val_loss: 0.3743 - val_acc: 0.9599\n",
            "Epoch 11/155\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.1045 - acc: 0.9600 - val_loss: 0.1833 - val_acc: 0.9599\n",
            "Epoch 12/155\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0929 - acc: 0.9600 - val_loss: 0.1918 - val_acc: 0.9599\n",
            "Epoch 13/155\n",
            "8822/8822 [==============================] - 6s 668us/step - loss: 0.0887 - acc: 0.9600 - val_loss: 0.1255 - val_acc: 0.9599\n",
            "Epoch 14/155\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.0959 - acc: 0.9599 - val_loss: 0.5096 - val_acc: 0.9599\n",
            "Epoch 15/155\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0796 - acc: 0.9606 - val_loss: 0.3078 - val_acc: 0.9599\n",
            "Epoch 16/155\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0708 - acc: 0.9643 - val_loss: 0.4871 - val_acc: 0.9601\n",
            "Epoch 17/155\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0599 - acc: 0.9720 - val_loss: 0.6338 - val_acc: 0.9599\n",
            "Epoch 18/155\n",
            "8822/8822 [==============================] - 6s 667us/step - loss: 0.0560 - acc: 0.9774 - val_loss: 0.1719 - val_acc: 0.9114\n",
            "Epoch 19/155\n",
            "8822/8822 [==============================] - 6s 667us/step - loss: 0.0473 - acc: 0.9805 - val_loss: 0.5721 - val_acc: 0.9599\n",
            "Epoch 20/155\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0376 - acc: 0.9853 - val_loss: 0.6427 - val_acc: 0.9599\n",
            "Epoch 21/155\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0367 - acc: 0.9855 - val_loss: 0.3907 - val_acc: 0.9601\n",
            "Epoch 22/155\n",
            "8822/8822 [==============================] - 6s 668us/step - loss: 0.0324 - acc: 0.9846 - val_loss: 0.0902 - val_acc: 0.9708\n",
            "Epoch 23/155\n",
            "8822/8822 [==============================] - 6s 669us/step - loss: 0.0321 - acc: 0.9883 - val_loss: 0.6363 - val_acc: 0.9599\n",
            "Epoch 24/155\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0333 - acc: 0.9864 - val_loss: 0.2083 - val_acc: 0.9630\n",
            "Epoch 25/155\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0346 - acc: 0.9871 - val_loss: 0.1624 - val_acc: 0.9726\n",
            "Epoch 26/155\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0283 - acc: 0.9873 - val_loss: 0.1000 - val_acc: 0.9717\n",
            "Epoch 27/155\n",
            "8822/8822 [==============================] - 6s 667us/step - loss: 0.0310 - acc: 0.9872 - val_loss: 0.1226 - val_acc: 0.9619\n",
            "Epoch 28/155\n",
            "8822/8822 [==============================] - 6s 668us/step - loss: 0.0177 - acc: 0.9906 - val_loss: 0.1828 - val_acc: 0.9628\n",
            "Epoch 29/155\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0192 - acc: 0.9909 - val_loss: 0.2846 - val_acc: 0.9637\n",
            "Epoch 30/155\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0250 - acc: 0.9901 - val_loss: 0.1398 - val_acc: 0.9628\n",
            "Epoch 31/155\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0198 - acc: 0.9900 - val_loss: 0.3339 - val_acc: 0.9610\n",
            "Epoch 32/155\n",
            "8822/8822 [==============================] - 6s 675us/step - loss: 0.0203 - acc: 0.9905 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 33/155\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0208 - acc: 0.9898 - val_loss: 0.0817 - val_acc: 0.9764\n",
            "Epoch 34/155\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0158 - acc: 0.9921 - val_loss: 0.1747 - val_acc: 0.9771\n",
            "Epoch 35/155\n",
            "8822/8822 [==============================] - 6s 676us/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.1509 - val_acc: 0.9776\n",
            "Epoch 36/155\n",
            "8822/8822 [==============================] - 6s 678us/step - loss: 0.0163 - acc: 0.9972 - val_loss: 0.1488 - val_acc: 0.9712\n",
            "Epoch 37/155\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0285 - acc: 0.9921 - val_loss: 0.3726 - val_acc: 0.9642\n",
            "Epoch 38/155\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0297 - acc: 0.9932 - val_loss: 0.0770 - val_acc: 0.9755\n",
            "Epoch 39/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0232 - acc: 0.9942 - val_loss: 0.6413 - val_acc: 0.9599\n",
            "Epoch 40/155\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0179 - acc: 0.9967 - val_loss: 0.1507 - val_acc: 0.9760\n",
            "Epoch 41/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0213 - acc: 0.9943 - val_loss: 0.2691 - val_acc: 0.9184\n",
            "Epoch 42/155\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0202 - acc: 0.9947 - val_loss: 0.1476 - val_acc: 0.9599\n",
            "Epoch 43/155\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0186 - acc: 0.9958 - val_loss: 0.2101 - val_acc: 0.9710\n",
            "Epoch 44/155\n",
            "8822/8822 [==============================] - 6s 675us/step - loss: 0.0182 - acc: 0.9964 - val_loss: 0.1343 - val_acc: 0.9751\n",
            "Epoch 45/155\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0159 - acc: 0.9966 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 46/155\n",
            "8822/8822 [==============================] - 6s 670us/step - loss: 0.0161 - acc: 0.9969 - val_loss: 0.2218 - val_acc: 0.9694\n",
            "Epoch 47/155\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0207 - acc: 0.9949 - val_loss: 0.5034 - val_acc: 0.9601\n",
            "Epoch 48/155\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0133 - acc: 0.9974 - val_loss: 0.0758 - val_acc: 0.9830\n",
            "Epoch 49/155\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0157 - acc: 0.9959 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 50/155\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0143 - acc: 0.9966 - val_loss: 0.0931 - val_acc: 0.9764\n",
            "Epoch 51/155\n",
            "8822/8822 [==============================] - 6s 681us/step - loss: 0.0085 - acc: 0.9983 - val_loss: 0.0988 - val_acc: 0.9755\n",
            "Epoch 52/155\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0143 - acc: 0.9980 - val_loss: 0.2632 - val_acc: 0.9764\n",
            "Epoch 53/155\n",
            "8822/8822 [==============================] - 6s 671us/step - loss: 0.0130 - acc: 0.9974 - val_loss: 0.6380 - val_acc: 0.9599\n",
            "Epoch 54/155\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.0182 - acc: 0.9957 - val_loss: 0.5978 - val_acc: 0.9599\n",
            "Epoch 55/155\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0110 - acc: 0.9975 - val_loss: 0.1098 - val_acc: 0.9780\n",
            "Epoch 56/155\n",
            "8822/8822 [==============================] - 6s 673us/step - loss: 0.0253 - acc: 0.9927 - val_loss: 0.1415 - val_acc: 0.9467\n",
            "Epoch 57/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0298 - acc: 0.9920 - val_loss: 0.2325 - val_acc: 0.9726\n",
            "Epoch 58/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0279 - acc: 0.9918 - val_loss: 0.3211 - val_acc: 0.9635\n",
            "Epoch 59/155\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0175 - acc: 0.9952 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 60/155\n",
            "8822/8822 [==============================] - 6s 674us/step - loss: 0.0298 - acc: 0.9908 - val_loss: 0.2203 - val_acc: 0.9669\n",
            "Epoch 61/155\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0089 - acc: 0.9969 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 62/155\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0463 - acc: 0.9847 - val_loss: 0.3135 - val_acc: 0.8341\n",
            "Epoch 63/155\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0390 - acc: 0.9870 - val_loss: 0.1026 - val_acc: 0.9701\n",
            "Epoch 64/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0285 - acc: 0.9916 - val_loss: 0.4508 - val_acc: 0.9601\n",
            "Epoch 65/155\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0243 - acc: 0.9916 - val_loss: 0.2151 - val_acc: 0.9701\n",
            "Epoch 66/155\n",
            "8822/8822 [==============================] - 6s 679us/step - loss: 0.0592 - acc: 0.9855 - val_loss: 0.1957 - val_acc: 0.9599\n",
            "Epoch 67/155\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0480 - acc: 0.9863 - val_loss: 0.2456 - val_acc: 0.9669\n",
            "Epoch 68/155\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0268 - acc: 0.9913 - val_loss: 0.0957 - val_acc: 0.9662\n",
            "Epoch 69/155\n",
            "8822/8822 [==============================] - 6s 677us/step - loss: 0.0217 - acc: 0.9944 - val_loss: 0.0837 - val_acc: 0.9773\n",
            "Epoch 70/155\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0165 - acc: 0.9957 - val_loss: 0.3108 - val_acc: 0.9615\n",
            "Epoch 71/155\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0179 - acc: 0.9951 - val_loss: 0.0727 - val_acc: 0.9773\n",
            "Epoch 72/155\n",
            "8822/8822 [==============================] - 6s 696us/step - loss: 0.0122 - acc: 0.9972 - val_loss: 0.5484 - val_acc: 0.9603\n",
            "Epoch 73/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0122 - acc: 0.9965 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 74/155\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0197 - acc: 0.9939 - val_loss: 0.1521 - val_acc: 0.9728\n",
            "Epoch 75/155\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0145 - acc: 0.9963 - val_loss: 0.6314 - val_acc: 0.9599\n",
            "Epoch 76/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0094 - acc: 0.9972 - val_loss: 0.1504 - val_acc: 0.9717\n",
            "Epoch 77/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0241 - acc: 0.9942 - val_loss: 0.2676 - val_acc: 0.9649\n",
            "Epoch 78/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0166 - acc: 0.9956 - val_loss: 0.1429 - val_acc: 0.9782\n",
            "Epoch 79/155\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0092 - acc: 0.9978 - val_loss: 0.0884 - val_acc: 0.9769\n",
            "Epoch 80/155\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0184 - acc: 0.9943 - val_loss: 0.3949 - val_acc: 0.9653\n",
            "Epoch 81/155\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0144 - acc: 0.9965 - val_loss: 0.7111 - val_acc: 0.8216\n",
            "Epoch 82/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0117 - acc: 0.9971 - val_loss: 0.4546 - val_acc: 0.9612\n",
            "Epoch 83/155\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.5016 - val_acc: 0.9637\n",
            "Epoch 84/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0203 - acc: 0.9957 - val_loss: 0.0910 - val_acc: 0.9791\n",
            "Epoch 85/155\n",
            "8822/8822 [==============================] - 6s 695us/step - loss: 0.0113 - acc: 0.9967 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 86/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0075 - acc: 0.9986 - val_loss: 0.0851 - val_acc: 0.9823\n",
            "Epoch 87/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0115 - acc: 0.9977 - val_loss: 0.1436 - val_acc: 0.9549\n",
            "Epoch 88/155\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0154 - acc: 0.9965 - val_loss: 0.6378 - val_acc: 0.9599\n",
            "Epoch 89/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0762 - val_acc: 0.9800\n",
            "Epoch 90/155\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.4678 - val_acc: 0.9637\n",
            "Epoch 91/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0120 - acc: 0.9972 - val_loss: 0.1356 - val_acc: 0.9805\n",
            "Epoch 92/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.2688 - val_acc: 0.9769\n",
            "Epoch 93/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0065 - acc: 0.9988 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 94/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0064 - acc: 0.9976 - val_loss: 0.2769 - val_acc: 0.9730\n",
            "Epoch 95/155\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0112 - acc: 0.9973 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 96/155\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0091 - acc: 0.9973 - val_loss: 0.6452 - val_acc: 0.9599\n",
            "Epoch 97/155\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0215 - acc: 0.9947 - val_loss: 0.2490 - val_acc: 0.9737\n",
            "Epoch 98/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.1419 - val_acc: 0.9789\n",
            "Epoch 99/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0160 - acc: 0.9948 - val_loss: 0.1321 - val_acc: 0.9562\n",
            "Epoch 100/155\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0123 - acc: 0.9977 - val_loss: 0.2462 - val_acc: 0.9735\n",
            "Epoch 101/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.1979 - val_acc: 0.9753\n",
            "Epoch 102/155\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0168 - acc: 0.9960 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 103/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0146 - acc: 0.9950 - val_loss: 0.2885 - val_acc: 0.9744\n",
            "Epoch 104/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 105/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0200 - acc: 0.9946 - val_loss: 0.1717 - val_acc: 0.9785\n",
            "Epoch 106/155\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0648 - val_acc: 0.9780\n",
            "Epoch 107/155\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0132 - acc: 0.9966 - val_loss: 0.1489 - val_acc: 0.9798\n",
            "Epoch 108/155\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0093 - acc: 0.9974 - val_loss: 0.5785 - val_acc: 0.9606\n",
            "Epoch 109/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.2609 - val_acc: 0.9735\n",
            "Epoch 110/155\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.3994 - val_acc: 0.9628\n",
            "Epoch 111/155\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0161 - acc: 0.9963 - val_loss: 0.5565 - val_acc: 0.9619\n",
            "Epoch 112/155\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0120 - acc: 0.9967 - val_loss: 0.1220 - val_acc: 0.9798\n",
            "Epoch 113/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.1244 - val_acc: 0.9816\n",
            "Epoch 114/155\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0089 - acc: 0.9981 - val_loss: 0.0886 - val_acc: 0.9812\n",
            "Epoch 115/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0039 - acc: 0.9992 - val_loss: 0.1154 - val_acc: 0.9832\n",
            "Epoch 116/155\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0171 - acc: 0.9961 - val_loss: 0.0914 - val_acc: 0.9821\n",
            "Epoch 117/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0114 - acc: 0.9971 - val_loss: 0.4436 - val_acc: 0.9608\n",
            "Epoch 118/155\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0990 - val_acc: 0.9746\n",
            "Epoch 119/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0056 - acc: 0.9990 - val_loss: 0.1014 - val_acc: 0.9837\n",
            "Epoch 120/155\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0045 - acc: 0.9994 - val_loss: 0.1023 - val_acc: 0.9821\n",
            "Epoch 121/155\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0061 - acc: 0.9988 - val_loss: 0.3548 - val_acc: 0.9726\n",
            "Epoch 122/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0148 - acc: 0.9959 - val_loss: 0.2134 - val_acc: 0.9778\n",
            "Epoch 123/155\n",
            "8822/8822 [==============================] - 6s 689us/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.5070 - val_acc: 0.9617\n",
            "Epoch 124/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.1631 - val_acc: 0.9782\n",
            "Epoch 125/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.3633 - val_acc: 0.9710\n",
            "Epoch 126/155\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0104 - acc: 0.9969 - val_loss: 0.1140 - val_acc: 0.9837\n",
            "Epoch 127/155\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0174 - acc: 0.9961 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 128/155\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0458 - acc: 0.9872 - val_loss: 0.4958 - val_acc: 0.9612\n",
            "Epoch 129/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0225 - acc: 0.9949 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 130/155\n",
            "8822/8822 [==============================] - 6s 680us/step - loss: 0.0257 - acc: 0.9938 - val_loss: 0.2066 - val_acc: 0.9780\n",
            "Epoch 131/155\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0143 - acc: 0.9966 - val_loss: 0.2916 - val_acc: 0.9735\n",
            "Epoch 132/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0152 - acc: 0.9954 - val_loss: 0.1685 - val_acc: 0.9787\n",
            "Epoch 133/155\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0190 - acc: 0.9952 - val_loss: 0.2197 - val_acc: 0.9692\n",
            "Epoch 134/155\n",
            "8822/8822 [==============================] - 6s 686us/step - loss: 0.0220 - acc: 0.9948 - val_loss: 0.4524 - val_acc: 0.9624\n",
            "Epoch 135/155\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0164 - acc: 0.9955 - val_loss: 0.1498 - val_acc: 0.9812\n",
            "Epoch 136/155\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0105 - acc: 0.9965 - val_loss: 0.0947 - val_acc: 0.9800\n",
            "Epoch 137/155\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0130 - acc: 0.9974 - val_loss: 0.5871 - val_acc: 0.9621\n",
            "Epoch 138/155\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0249 - acc: 0.9926 - val_loss: 0.3670 - val_acc: 0.9719\n",
            "Epoch 139/155\n",
            "8822/8822 [==============================] - 6s 682us/step - loss: 0.0142 - acc: 0.9956 - val_loss: 0.0747 - val_acc: 0.9787\n",
            "Epoch 140/155\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0083 - acc: 0.9980 - val_loss: 0.1018 - val_acc: 0.9853\n",
            "Epoch 141/155\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.1215 - val_acc: 0.9837\n",
            "Epoch 142/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.1060 - val_acc: 0.9855\n",
            "Epoch 143/155\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.3193 - val_acc: 0.9755\n",
            "Epoch 144/155\n",
            "8822/8822 [==============================] - 6s 685us/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.5025 - val_acc: 0.9635\n",
            "Epoch 145/155\n",
            "8822/8822 [==============================] - 6s 692us/step - loss: 0.0220 - acc: 0.9948 - val_loss: 0.1768 - val_acc: 0.9800\n",
            "Epoch 146/155\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0108 - acc: 0.9977 - val_loss: 0.1623 - val_acc: 0.9812\n",
            "Epoch 147/155\n",
            "8822/8822 [==============================] - 6s 687us/step - loss: 0.0165 - acc: 0.9952 - val_loss: 0.4812 - val_acc: 0.9637\n",
            "Epoch 148/155\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0088 - acc: 0.9966 - val_loss: 0.5042 - val_acc: 0.9653\n",
            "Epoch 149/155\n",
            "8822/8822 [==============================] - 6s 684us/step - loss: 0.0066 - acc: 0.9980 - val_loss: 0.0992 - val_acc: 0.9830\n",
            "Epoch 150/155\n",
            "8822/8822 [==============================] - 6s 683us/step - loss: 0.0084 - acc: 0.9976 - val_loss: 0.1476 - val_acc: 0.9794\n",
            "Epoch 151/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.1533 - val_acc: 0.9828\n",
            "Epoch 152/155\n",
            "8822/8822 [==============================] - 6s 691us/step - loss: 0.0186 - acc: 0.9968 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 153/155\n",
            "8822/8822 [==============================] - 6s 688us/step - loss: 0.0098 - acc: 0.9971 - val_loss: 0.1849 - val_acc: 0.9821\n",
            "Epoch 154/155\n",
            "8822/8822 [==============================] - 6s 690us/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.4677 - val_acc: 0.9678\n",
            "Epoch 155/155\n",
            "8822/8822 [==============================] - 6s 693us/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.2560 - val_acc: 0.9762\n",
            "Bush F1 Score on Train :  0.8354838709677419\n",
            "Bush F1 Score on Test :  0.6096654275092936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bJBSlznbwVOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5424
        },
        "outputId": "6fcf2275-27ca-450f-f916-b896862fb8f8"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "modelForBush=load_model(\"8initialized-model.keras\")\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_reshaped, \n",
        "             y_bush,shuffle = True ,test_size= 1./3, random_state=6099, stratify  = y_bush) # A20396099\n",
        "\n",
        "\n",
        "modelForBush.fit(X_train_b,y_train_b, epochs=150, batch_size=32, validation_data = (X_test_b, y_test_b ) )\n",
        "\n",
        "y_predicted_train_bush = modelForBush.predict_classes(X_train_b) \n",
        "y_predicted_test_bush = modelForBush.predict_classes(X_test_b) \n",
        "result_f1_train_bush_E70=f1_score(y_train_b, y_predicted_train_bush)\n",
        "result_f1_test_bush_E70=f1_score(y_test_b, y_predicted_test_bush)\n",
        "print(\"Bush F1 Score on Train : \",result_f1_train_bush_E70)\n",
        "print(\"Bush F1 Score on Test : \",result_f1_test_bush_E70)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8822 samples, validate on 4411 samples\n",
            "Epoch 1/150\n",
            "8822/8822 [==============================] - 8s 894us/step - loss: 0.6702 - acc: 0.8170 - val_loss: 15.3027 - val_acc: 0.0401\n",
            "Epoch 2/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.2171 - acc: 0.9474 - val_loss: 15.3027 - val_acc: 0.0401\n",
            "Epoch 3/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.1485 - acc: 0.9553 - val_loss: 0.3819 - val_acc: 0.9599\n",
            "Epoch 4/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.1077 - acc: 0.9666 - val_loss: 0.6391 - val_acc: 0.9599\n",
            "Epoch 5/150\n",
            "8822/8822 [==============================] - 6s 731us/step - loss: 0.0817 - acc: 0.9729 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 6/150\n",
            "8822/8822 [==============================] - 6s 731us/step - loss: 0.1037 - acc: 0.9663 - val_loss: 15.2988 - val_acc: 0.0401\n",
            "Epoch 7/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0718 - acc: 0.9742 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 8/150\n",
            "8822/8822 [==============================] - 6s 730us/step - loss: 0.0510 - acc: 0.9807 - val_loss: 3.9208 - val_acc: 0.1168\n",
            "Epoch 9/150\n",
            "8822/8822 [==============================] - 6s 730us/step - loss: 0.0486 - acc: 0.9828 - val_loss: 12.4339 - val_acc: 0.0401\n",
            "Epoch 10/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0406 - acc: 0.9848 - val_loss: 0.4837 - val_acc: 0.7894\n",
            "Epoch 11/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0303 - acc: 0.9901 - val_loss: 5.2438 - val_acc: 0.0868\n",
            "Epoch 12/150\n",
            "8822/8822 [==============================] - 6s 730us/step - loss: 0.0277 - acc: 0.9899 - val_loss: 1.0949 - val_acc: 0.5715\n",
            "Epoch 13/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0294 - acc: 0.9889 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 14/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0211 - acc: 0.9931 - val_loss: 0.0319 - val_acc: 0.9896\n",
            "Epoch 15/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0267 - acc: 0.9906 - val_loss: 4.4194 - val_acc: 0.1433\n",
            "Epoch 16/150\n",
            "8822/8822 [==============================] - 6s 733us/step - loss: 0.0270 - acc: 0.9900 - val_loss: 0.4238 - val_acc: 0.9603\n",
            "Epoch 17/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0207 - acc: 0.9922 - val_loss: 0.4138 - val_acc: 0.9601\n",
            "Epoch 18/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0192 - acc: 0.9926 - val_loss: 0.0268 - val_acc: 0.9916\n",
            "Epoch 19/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0193 - acc: 0.9927 - val_loss: 0.0428 - val_acc: 0.9839\n",
            "Epoch 20/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0162 - acc: 0.9938 - val_loss: 13.7970 - val_acc: 0.0404\n",
            "Epoch 21/150\n",
            "8822/8822 [==============================] - 6s 733us/step - loss: 0.0171 - acc: 0.9931 - val_loss: 0.1213 - val_acc: 0.9751\n",
            "Epoch 22/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0192 - acc: 0.9931 - val_loss: 0.2049 - val_acc: 0.9655\n",
            "Epoch 23/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0199 - acc: 0.9932 - val_loss: 0.0628 - val_acc: 0.9769\n",
            "Epoch 24/150\n",
            "8822/8822 [==============================] - 6s 733us/step - loss: 0.0260 - acc: 0.9912 - val_loss: 0.0977 - val_acc: 0.9762\n",
            "Epoch 25/150\n",
            "8822/8822 [==============================] - 6s 731us/step - loss: 0.0257 - acc: 0.9915 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 26/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0259 - acc: 0.9905 - val_loss: 14.9527 - val_acc: 0.0401\n",
            "Epoch 27/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0192 - acc: 0.9934 - val_loss: 0.6466 - val_acc: 0.9599\n",
            "Epoch 28/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0178 - acc: 0.9925 - val_loss: 0.4272 - val_acc: 0.9608\n",
            "Epoch 29/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0174 - acc: 0.9937 - val_loss: 3.5406 - val_acc: 0.2639\n",
            "Epoch 30/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0218 - acc: 0.9924 - val_loss: 1.0170 - val_acc: 0.6466\n",
            "Epoch 31/150\n",
            "8822/8822 [==============================] - 6s 735us/step - loss: 0.0169 - acc: 0.9948 - val_loss: 0.6402 - val_acc: 0.9599\n",
            "Epoch 32/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0221 - acc: 0.9926 - val_loss: 0.0772 - val_acc: 0.9810\n",
            "Epoch 33/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0202 - acc: 0.9922 - val_loss: 0.0344 - val_acc: 0.9873\n",
            "Epoch 34/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0120 - acc: 0.9959 - val_loss: 13.8068 - val_acc: 0.0415\n",
            "Epoch 35/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0091 - acc: 0.9968 - val_loss: 0.1982 - val_acc: 0.9698\n",
            "Epoch 36/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0154 - acc: 0.9951 - val_loss: 0.0777 - val_acc: 0.9721\n",
            "Epoch 37/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0126 - acc: 0.9954 - val_loss: 0.0239 - val_acc: 0.9937\n",
            "Epoch 38/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.2096 - val_acc: 0.9297\n",
            "Epoch 39/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0100 - acc: 0.9964 - val_loss: 0.0896 - val_acc: 0.9687\n",
            "Epoch 40/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0081 - acc: 0.9967 - val_loss: 0.6375 - val_acc: 0.9599\n",
            "Epoch 41/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.6656 - val_acc: 0.7815\n",
            "Epoch 42/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0122 - acc: 0.9954 - val_loss: 2.5576 - val_acc: 0.4355\n",
            "Epoch 43/150\n",
            "8822/8822 [==============================] - 6s 735us/step - loss: 0.0096 - acc: 0.9965 - val_loss: 6.5651 - val_acc: 0.1299\n",
            "Epoch 44/150\n",
            "8822/8822 [==============================] - 6s 730us/step - loss: 0.0086 - acc: 0.9967 - val_loss: 0.4103 - val_acc: 0.9619\n",
            "Epoch 45/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0385 - val_acc: 0.9912\n",
            "Epoch 46/150\n",
            "8822/8822 [==============================] - 6s 734us/step - loss: 0.0093 - acc: 0.9963 - val_loss: 0.2055 - val_acc: 0.9327\n",
            "Epoch 47/150\n",
            "8822/8822 [==============================] - 6s 730us/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0346 - val_acc: 0.9925\n",
            "Epoch 48/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0094 - acc: 0.9966 - val_loss: 0.0714 - val_acc: 0.9737\n",
            "Epoch 49/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0075 - acc: 0.9971 - val_loss: 0.0259 - val_acc: 0.9923\n",
            "Epoch 50/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0109 - acc: 0.9955 - val_loss: 1.0528 - val_acc: 0.7112\n",
            "Epoch 51/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0130 - acc: 0.9951 - val_loss: 15.3027 - val_acc: 0.0401\n",
            "Epoch 52/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0131 - acc: 0.9940 - val_loss: 0.0431 - val_acc: 0.9889\n",
            "Epoch 53/150\n",
            "8822/8822 [==============================] - 6s 730us/step - loss: 0.0104 - acc: 0.9960 - val_loss: 13.6570 - val_acc: 0.0456\n",
            "Epoch 54/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0103 - acc: 0.9959 - val_loss: 0.0243 - val_acc: 0.9934\n",
            "Epoch 55/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0076 - acc: 0.9969 - val_loss: 0.1429 - val_acc: 0.9785\n",
            "Epoch 56/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0061 - acc: 0.9980 - val_loss: 9.5957 - val_acc: 0.0864\n",
            "Epoch 57/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0082 - acc: 0.9971 - val_loss: 0.0268 - val_acc: 0.9927\n",
            "Epoch 58/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0051 - acc: 0.9981 - val_loss: 3.4572 - val_acc: 0.4224\n",
            "Epoch 59/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0089 - acc: 0.9969 - val_loss: 0.0947 - val_acc: 0.9848\n",
            "Epoch 60/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0088 - acc: 0.9974 - val_loss: 0.4210 - val_acc: 0.8907\n",
            "Epoch 61/150\n",
            "8822/8822 [==============================] - 6s 732us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.6227 - val_acc: 0.9599\n",
            "Epoch 62/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0165 - acc: 0.9939 - val_loss: 8.3817 - val_acc: 0.1276\n",
            "Epoch 63/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0127 - acc: 0.9963 - val_loss: 4.5287 - val_acc: 0.3543\n",
            "Epoch 64/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0227 - acc: 0.9932 - val_loss: 0.3543 - val_acc: 0.9642\n",
            "Epoch 65/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0123 - acc: 0.9955 - val_loss: 0.1207 - val_acc: 0.9828\n",
            "Epoch 66/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0081 - acc: 0.9969 - val_loss: 0.0389 - val_acc: 0.9882\n",
            "Epoch 67/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0063 - acc: 0.9974 - val_loss: 0.0564 - val_acc: 0.9857\n",
            "Epoch 68/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.0337 - val_acc: 0.9937\n",
            "Epoch 69/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0522 - val_acc: 0.9875\n",
            "Epoch 70/150\n",
            "8822/8822 [==============================] - 6s 731us/step - loss: 0.0046 - acc: 0.9983 - val_loss: 0.0789 - val_acc: 0.9873\n",
            "Epoch 71/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0857 - val_acc: 0.9864\n",
            "Epoch 72/150\n",
            "8822/8822 [==============================] - 6s 730us/step - loss: 0.0049 - acc: 0.9982 - val_loss: 0.0432 - val_acc: 0.9927\n",
            "Epoch 73/150\n",
            "8822/8822 [==============================] - 6s 731us/step - loss: 0.0043 - acc: 0.9982 - val_loss: 0.3377 - val_acc: 0.9671\n",
            "Epoch 74/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.5812 - val_acc: 0.9599\n",
            "Epoch 75/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0087 - acc: 0.9967 - val_loss: 0.0583 - val_acc: 0.9900\n",
            "Epoch 76/150\n",
            "8822/8822 [==============================] - 6s 723us/step - loss: 0.0092 - acc: 0.9973 - val_loss: 0.0861 - val_acc: 0.9757\n",
            "Epoch 77/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0127 - acc: 0.9956 - val_loss: 0.1861 - val_acc: 0.9456\n",
            "Epoch 78/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0106 - acc: 0.9957 - val_loss: 0.2189 - val_acc: 0.9753\n",
            "Epoch 79/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0086 - acc: 0.9967 - val_loss: 0.2007 - val_acc: 0.9739\n",
            "Epoch 80/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0073 - acc: 0.9973 - val_loss: 0.2066 - val_acc: 0.9413\n",
            "Epoch 81/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0654 - val_acc: 0.9898\n",
            "Epoch 82/150\n",
            "8822/8822 [==============================] - 6s 731us/step - loss: 0.0063 - acc: 0.9977 - val_loss: 1.8663 - val_acc: 0.6323\n",
            "Epoch 83/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0063 - acc: 0.9978 - val_loss: 0.0422 - val_acc: 0.9912\n",
            "Epoch 84/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0073 - acc: 0.9973 - val_loss: 0.0433 - val_acc: 0.9927\n",
            "Epoch 85/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0274 - val_acc: 0.9941\n",
            "Epoch 86/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0047 - acc: 0.9983 - val_loss: 0.0276 - val_acc: 0.9932\n",
            "Epoch 87/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0048 - acc: 0.9980 - val_loss: 0.2261 - val_acc: 0.9737\n",
            "Epoch 88/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0056 - acc: 0.9974 - val_loss: 0.0250 - val_acc: 0.9948\n",
            "Epoch 89/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0046 - acc: 0.9985 - val_loss: 1.0491 - val_acc: 0.7842\n",
            "Epoch 90/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0039 - acc: 0.9983 - val_loss: 0.1813 - val_acc: 0.9544\n",
            "Epoch 91/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0038 - acc: 0.9986 - val_loss: 0.0554 - val_acc: 0.9918\n",
            "Epoch 92/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0037 - acc: 0.9986 - val_loss: 0.0701 - val_acc: 0.9912\n",
            "Epoch 93/150\n",
            "8822/8822 [==============================] - 6s 723us/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0570 - val_acc: 0.9927\n",
            "Epoch 94/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0052 - acc: 0.9980 - val_loss: 0.6944 - val_acc: 0.8517\n",
            "Epoch 95/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0721 - val_acc: 0.9905\n",
            "Epoch 96/150\n",
            "8822/8822 [==============================] - 6s 731us/step - loss: 0.0090 - acc: 0.9966 - val_loss: 0.2032 - val_acc: 0.9757\n",
            "Epoch 97/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0069 - acc: 0.9975 - val_loss: 4.9856 - val_acc: 0.3684\n",
            "Epoch 98/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0083 - acc: 0.9968 - val_loss: 0.6426 - val_acc: 0.9599\n",
            "Epoch 99/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0080 - acc: 0.9972 - val_loss: 0.7914 - val_acc: 0.8352\n",
            "Epoch 100/150\n",
            "8822/8822 [==============================] - 6s 733us/step - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0380 - val_acc: 0.9914\n",
            "Epoch 101/150\n",
            "8822/8822 [==============================] - 7s 745us/step - loss: 0.0093 - acc: 0.9967 - val_loss: 0.0327 - val_acc: 0.9943\n",
            "Epoch 102/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0078 - acc: 0.9971 - val_loss: 0.0430 - val_acc: 0.9941\n",
            "Epoch 103/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.1194 - val_acc: 0.9841\n",
            "Epoch 104/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0043 - acc: 0.9980 - val_loss: 0.0925 - val_acc: 0.9812\n",
            "Epoch 105/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0069 - acc: 0.9976 - val_loss: 0.2544 - val_acc: 0.9735\n",
            "Epoch 106/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0049 - acc: 0.9982 - val_loss: 0.2899 - val_acc: 0.9728\n",
            "Epoch 107/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0706 - val_acc: 0.9848\n",
            "Epoch 108/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0397 - val_acc: 0.9918\n",
            "Epoch 109/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.2684 - val_acc: 0.9726\n",
            "Epoch 110/150\n",
            "8822/8822 [==============================] - 6s 733us/step - loss: 0.0065 - acc: 0.9976 - val_loss: 0.0374 - val_acc: 0.9941\n",
            "Epoch 111/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0425 - val_acc: 0.9923\n",
            "Epoch 112/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0476 - val_acc: 0.9925\n",
            "Epoch 113/150\n",
            "8822/8822 [==============================] - 6s 722us/step - loss: 0.0101 - acc: 0.9971 - val_loss: 0.2276 - val_acc: 0.9515\n",
            "Epoch 114/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0088 - acc: 0.9967 - val_loss: 0.0698 - val_acc: 0.9905\n",
            "Epoch 115/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0677 - val_acc: 0.9846\n",
            "Epoch 116/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0086 - acc: 0.9974 - val_loss: 0.1334 - val_acc: 0.9841\n",
            "Epoch 117/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0025 - acc: 0.9990 - val_loss: 0.6010 - val_acc: 0.9608\n",
            "Epoch 118/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0152 - acc: 0.9951 - val_loss: 0.6302 - val_acc: 0.9601\n",
            "Epoch 119/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0094 - acc: 0.9969 - val_loss: 1.0832 - val_acc: 0.8044\n",
            "Epoch 120/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0114 - acc: 0.9963 - val_loss: 0.0586 - val_acc: 0.9909\n",
            "Epoch 121/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0330 - val_acc: 0.9950\n",
            "Epoch 122/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0090 - acc: 0.9966 - val_loss: 0.5970 - val_acc: 0.9601\n",
            "Epoch 123/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0177 - acc: 0.9954 - val_loss: 0.2998 - val_acc: 0.9696\n",
            "Epoch 124/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.1093 - val_acc: 0.9880\n",
            "Epoch 125/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0112 - acc: 0.9961 - val_loss: 0.0751 - val_acc: 0.9900\n",
            "Epoch 126/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0084 - acc: 0.9976 - val_loss: 3.6752 - val_acc: 0.5019\n",
            "Epoch 127/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0534 - val_acc: 0.9882\n",
            "Epoch 128/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0400 - val_acc: 0.9946\n",
            "Epoch 129/150\n",
            "8822/8822 [==============================] - 6s 730us/step - loss: 0.0085 - acc: 0.9975 - val_loss: 0.0551 - val_acc: 0.9921\n",
            "Epoch 130/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0070 - acc: 0.9980 - val_loss: 3.2824 - val_acc: 0.5561\n",
            "Epoch 131/150\n",
            "8822/8822 [==============================] - 6s 721us/step - loss: 0.0077 - acc: 0.9978 - val_loss: 0.0473 - val_acc: 0.9884\n",
            "Epoch 132/150\n",
            "8822/8822 [==============================] - 6s 723us/step - loss: 0.0098 - acc: 0.9973 - val_loss: 0.3153 - val_acc: 0.9241\n",
            "Epoch 133/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0122 - acc: 0.9959 - val_loss: 0.3228 - val_acc: 0.9701\n",
            "Epoch 134/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.1448 - val_acc: 0.9676\n",
            "Epoch 135/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.2037 - val_acc: 0.9798\n",
            "Epoch 136/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0095 - acc: 0.9972 - val_loss: 0.1260 - val_acc: 0.9853\n",
            "Epoch 137/150\n",
            "8822/8822 [==============================] - 6s 729us/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0383 - val_acc: 0.9943\n",
            "Epoch 138/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.4358 - val_acc: 0.9107\n",
            "Epoch 139/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.2195 - val_acc: 0.9764\n",
            "Epoch 140/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0053 - acc: 0.9989 - val_loss: 0.9341 - val_acc: 0.8331\n",
            "Epoch 141/150\n",
            "8822/8822 [==============================] - 6s 723us/step - loss: 0.0046 - acc: 0.9983 - val_loss: 0.0526 - val_acc: 0.9882\n",
            "Epoch 142/150\n",
            "8822/8822 [==============================] - 6s 723us/step - loss: 0.0049 - acc: 0.9982 - val_loss: 0.0618 - val_acc: 0.9918\n",
            "Epoch 143/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0661 - val_acc: 0.9832\n",
            "Epoch 144/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.1418 - val_acc: 0.9835\n",
            "Epoch 145/150\n",
            "8822/8822 [==============================] - 6s 728us/step - loss: 0.0053 - acc: 0.9978 - val_loss: 0.9564 - val_acc: 0.8304\n",
            "Epoch 146/150\n",
            "8822/8822 [==============================] - 6s 727us/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0995 - val_acc: 0.9887\n",
            "Epoch 147/150\n",
            "8822/8822 [==============================] - 6s 725us/step - loss: 0.0091 - acc: 0.9976 - val_loss: 0.5319 - val_acc: 0.9075\n",
            "Epoch 148/150\n",
            "8822/8822 [==============================] - 6s 732us/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.1372 - val_acc: 0.9850\n",
            "Epoch 149/150\n",
            "8822/8822 [==============================] - 6s 726us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 11.3412 - val_acc: 0.1285\n",
            "Epoch 150/150\n",
            "8822/8822 [==============================] - 6s 724us/step - loss: 0.0058 - acc: 0.9975 - val_loss: 0.4936 - val_acc: 0.9637\n",
            "Bush F1 Score on Train :  0.16145833333333331\n",
            "Bush F1 Score on Test :  0.1752577319587629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ReeKK6VcFKHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5424
        },
        "outputId": "b2c925d6-52a7-4bd1-b65f-de545db6324e"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "modelForBush=load_model(\"10initialized-model.keras\")\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_reshaped, \n",
        "             y_bush,shuffle = True ,test_size= 1./3, random_state=6099, stratify  = y_bush) # A20396099\n",
        "\n",
        "\n",
        "modelForBush.fit(X_train_b,y_train_b, epochs=150, batch_size=32, validation_data = (X_test_b, y_test_b ) )\n",
        "\n",
        "y_predicted_train_bush = modelForBush.predict_classes(X_train_b) \n",
        "y_predicted_test_bush = modelForBush.predict_classes(X_test_b) \n",
        "result_f1_train_bush_E70=f1_score(y_train_b, y_predicted_train_bush)\n",
        "result_f1_test_bush_E70=f1_score(y_test_b, y_predicted_test_bush)\n",
        "print(\"Bush F1 Score on Train : \",result_f1_train_bush_E70)\n",
        "print(\"Bush F1 Score on Test : \",result_f1_test_bush_E70)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8822 samples, validate on 4411 samples\n",
            "Epoch 1/150\n",
            "8822/8822 [==============================] - 6s 672us/step - loss: 0.1789 - acc: 0.9600 - val_loss: 0.1737 - val_acc: 0.9599\n",
            "Epoch 2/150\n",
            "8822/8822 [==============================] - 5s 534us/step - loss: 0.1693 - acc: 0.9600 - val_loss: 0.1657 - val_acc: 0.9599\n",
            "Epoch 3/150\n",
            "8822/8822 [==============================] - 5s 536us/step - loss: 0.1635 - acc: 0.9600 - val_loss: 0.1482 - val_acc: 0.9599\n",
            "Epoch 4/150\n",
            "8822/8822 [==============================] - 5s 539us/step - loss: 0.1452 - acc: 0.9596 - val_loss: 0.1365 - val_acc: 0.9599\n",
            "Epoch 5/150\n",
            "8822/8822 [==============================] - 5s 537us/step - loss: 0.1234 - acc: 0.9620 - val_loss: 0.1154 - val_acc: 0.9644\n",
            "Epoch 6/150\n",
            "8822/8822 [==============================] - 5s 540us/step - loss: 0.0993 - acc: 0.9660 - val_loss: 0.0964 - val_acc: 0.9692\n",
            "Epoch 7/150\n",
            "8822/8822 [==============================] - 5s 542us/step - loss: 0.0803 - acc: 0.9715 - val_loss: 0.1045 - val_acc: 0.9653\n",
            "Epoch 8/150\n",
            "8822/8822 [==============================] - 5s 537us/step - loss: 0.0555 - acc: 0.9814 - val_loss: 0.0546 - val_acc: 0.9805\n",
            "Epoch 9/150\n",
            "8822/8822 [==============================] - 5s 539us/step - loss: 0.0423 - acc: 0.9853 - val_loss: 0.0447 - val_acc: 0.9850\n",
            "Epoch 10/150\n",
            "8822/8822 [==============================] - 5s 534us/step - loss: 0.0298 - acc: 0.9900 - val_loss: 0.0409 - val_acc: 0.9853\n",
            "Epoch 11/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 0.0229 - acc: 0.9924 - val_loss: 0.0347 - val_acc: 0.9884\n",
            "Epoch 12/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 0.0161 - acc: 0.9947 - val_loss: 0.0447 - val_acc: 0.9828\n",
            "Epoch 13/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 0.0124 - acc: 0.9965 - val_loss: 0.0387 - val_acc: 0.9855\n",
            "Epoch 14/150\n",
            "8822/8822 [==============================] - 5s 541us/step - loss: 0.0083 - acc: 0.9984 - val_loss: 0.0328 - val_acc: 0.9882\n",
            "Epoch 15/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 0.0058 - acc: 0.9989 - val_loss: 0.0371 - val_acc: 0.9882\n",
            "Epoch 16/150\n",
            "8822/8822 [==============================] - 5s 533us/step - loss: 0.0051 - acc: 0.9990 - val_loss: 0.0314 - val_acc: 0.9896\n",
            "Epoch 17/150\n",
            "8822/8822 [==============================] - 5s 534us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0335 - val_acc: 0.9882\n",
            "Epoch 18/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0329 - val_acc: 0.9891\n",
            "Epoch 19/150\n",
            "8822/8822 [==============================] - 5s 534us/step - loss: 0.0014 - acc: 0.9999 - val_loss: 0.0414 - val_acc: 0.9893\n",
            "Epoch 20/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 0.0019 - acc: 0.9999 - val_loss: 0.0318 - val_acc: 0.9900\n",
            "Epoch 21/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 7.0769e-04 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9898\n",
            "Epoch 22/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 4.9096e-04 - acc: 1.0000 - val_loss: 0.0371 - val_acc: 0.9898\n",
            "Epoch 23/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 3.9345e-04 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 0.9900\n",
            "Epoch 24/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 2.8745e-04 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 0.9907\n",
            "Epoch 25/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 2.3317e-04 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 0.9900\n",
            "Epoch 26/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.9570e-04 - acc: 1.0000 - val_loss: 0.0364 - val_acc: 0.9905\n",
            "Epoch 27/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.6038e-04 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 0.9896\n",
            "Epoch 28/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 1.2853e-04 - acc: 1.0000 - val_loss: 0.0378 - val_acc: 0.9905\n",
            "Epoch 29/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.1033e-04 - acc: 1.0000 - val_loss: 0.0473 - val_acc: 0.9898\n",
            "Epoch 30/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 9.3091e-05 - acc: 1.0000 - val_loss: 0.0476 - val_acc: 0.9898\n",
            "Epoch 31/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 7.0855e-05 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9903\n",
            "Epoch 32/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 6.3089e-05 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 0.9900\n",
            "Epoch 33/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 5.0409e-05 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 0.9900\n",
            "Epoch 34/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 4.0769e-05 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 0.9903\n",
            "Epoch 35/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 3.6929e-05 - acc: 1.0000 - val_loss: 0.0460 - val_acc: 0.9903\n",
            "Epoch 36/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 2.9121e-05 - acc: 1.0000 - val_loss: 0.0462 - val_acc: 0.9905\n",
            "Epoch 37/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 2.6346e-05 - acc: 1.0000 - val_loss: 0.0509 - val_acc: 0.9903\n",
            "Epoch 38/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 2.0593e-05 - acc: 1.0000 - val_loss: 0.0518 - val_acc: 0.9903\n",
            "Epoch 39/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.7157e-05 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 0.9905\n",
            "Epoch 40/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.6069e-05 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 0.9900\n",
            "Epoch 41/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.2105e-05 - acc: 1.0000 - val_loss: 0.0517 - val_acc: 0.9903\n",
            "Epoch 42/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 1.0030e-05 - acc: 1.0000 - val_loss: 0.0560 - val_acc: 0.9905\n",
            "Epoch 43/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 8.7393e-06 - acc: 1.0000 - val_loss: 0.0547 - val_acc: 0.9898\n",
            "Epoch 44/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 7.2334e-06 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 0.9896\n",
            "Epoch 45/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 6.4780e-06 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 0.9900\n",
            "Epoch 46/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 5.1123e-06 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9900\n",
            "Epoch 47/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 4.3492e-06 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9905\n",
            "Epoch 48/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 3.7152e-06 - acc: 1.0000 - val_loss: 0.0539 - val_acc: 0.9912\n",
            "Epoch 49/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 3.1401e-06 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 0.9909\n",
            "Epoch 50/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 2.6318e-06 - acc: 1.0000 - val_loss: 0.0575 - val_acc: 0.9903\n",
            "Epoch 51/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 2.2935e-06 - acc: 1.0000 - val_loss: 0.0597 - val_acc: 0.9903\n",
            "Epoch 52/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.9086e-06 - acc: 1.0000 - val_loss: 0.0633 - val_acc: 0.9903\n",
            "Epoch 53/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 1.8099e-06 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 0.9907\n",
            "Epoch 54/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 1.4489e-06 - acc: 1.0000 - val_loss: 0.0595 - val_acc: 0.9905\n",
            "Epoch 55/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 1.2208e-06 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 0.9905\n",
            "Epoch 56/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 1.0612e-06 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9898\n",
            "Epoch 57/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 9.0408e-07 - acc: 1.0000 - val_loss: 0.0637 - val_acc: 0.9900\n",
            "Epoch 58/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 7.9174e-07 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 0.9907\n",
            "Epoch 59/150\n",
            "8822/8822 [==============================] - 5s 533us/step - loss: 6.9601e-07 - acc: 1.0000 - val_loss: 0.0610 - val_acc: 0.9909\n",
            "Epoch 60/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 6.5151e-07 - acc: 1.0000 - val_loss: 0.0640 - val_acc: 0.9900\n",
            "Epoch 61/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 5.3478e-07 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 0.9903\n",
            "Epoch 62/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 4.6802e-07 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9903\n",
            "Epoch 63/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 3.9665e-07 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9905\n",
            "Epoch 64/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 3.5580e-07 - acc: 1.0000 - val_loss: 0.0682 - val_acc: 0.9900\n",
            "Epoch 65/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 3.3327e-07 - acc: 1.0000 - val_loss: 0.0688 - val_acc: 0.9900\n",
            "Epoch 66/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 2.8704e-07 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 0.9907\n",
            "Epoch 67/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 2.6650e-07 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 0.9905\n",
            "Epoch 68/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 2.4080e-07 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9907\n",
            "Epoch 69/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 2.1455e-07 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9905\n",
            "Epoch 70/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 2.0040e-07 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9907\n",
            "Epoch 71/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.8503e-07 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 0.9907\n",
            "Epoch 72/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 1.7437e-07 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 0.9903\n",
            "Epoch 73/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 1.5915e-07 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9905\n",
            "Epoch 74/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 1.6046e-07 - acc: 1.0000 - val_loss: 0.0720 - val_acc: 0.9903\n",
            "Epoch 75/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 1.4320e-07 - acc: 1.0000 - val_loss: 0.0707 - val_acc: 0.9907\n",
            "Epoch 76/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.3972e-07 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 0.9907\n",
            "Epoch 77/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 1.3023e-07 - acc: 1.0000 - val_loss: 0.0739 - val_acc: 0.9903\n",
            "Epoch 78/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.2743e-07 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 0.9903\n",
            "Epoch 79/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.2464e-07 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 0.9905\n",
            "Epoch 80/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 1.2068e-07 - acc: 1.0000 - val_loss: 0.0733 - val_acc: 0.9903\n",
            "Epoch 81/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 1.1631e-07 - acc: 1.0000 - val_loss: 0.0717 - val_acc: 0.9907\n",
            "Epoch 82/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 1.1384e-07 - acc: 1.0000 - val_loss: 0.0736 - val_acc: 0.9905\n",
            "Epoch 83/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.1221e-07 - acc: 1.0000 - val_loss: 0.0733 - val_acc: 0.9905\n",
            "Epoch 84/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 1.1004e-07 - acc: 1.0000 - val_loss: 0.0742 - val_acc: 0.9907\n",
            "Epoch 85/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 1.0863e-07 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 0.9905\n",
            "Epoch 86/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 1.0709e-07 - acc: 1.0000 - val_loss: 0.0748 - val_acc: 0.9907\n",
            "Epoch 87/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.0685e-07 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 0.9907\n",
            "Epoch 88/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 1.0513e-07 - acc: 1.0000 - val_loss: 0.0747 - val_acc: 0.9907\n",
            "Epoch 89/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.0434e-07 - acc: 1.0000 - val_loss: 0.0752 - val_acc: 0.9907\n",
            "Epoch 90/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 1.0396e-07 - acc: 1.0000 - val_loss: 0.0752 - val_acc: 0.9905\n",
            "Epoch 91/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 1.0328e-07 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 0.9905\n",
            "Epoch 92/150\n",
            "8822/8822 [==============================] - 5s 534us/step - loss: 1.0274e-07 - acc: 1.0000 - val_loss: 0.0755 - val_acc: 0.9907\n",
            "Epoch 93/150\n",
            "8822/8822 [==============================] - 5s 533us/step - loss: 1.0237e-07 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 0.9907\n",
            "Epoch 94/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.0214e-07 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 0.9907\n",
            "Epoch 95/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.0176e-07 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 0.9907\n",
            "Epoch 96/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.0167e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9900\n",
            "Epoch 97/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 1.0153e-07 - acc: 1.0000 - val_loss: 0.0761 - val_acc: 0.9905\n",
            "Epoch 98/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.0127e-07 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 0.9907\n",
            "Epoch 99/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 1.0121e-07 - acc: 1.0000 - val_loss: 0.0758 - val_acc: 0.9907\n",
            "Epoch 100/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.0105e-07 - acc: 1.0000 - val_loss: 0.0762 - val_acc: 0.9905\n",
            "Epoch 101/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 1.0097e-07 - acc: 1.0000 - val_loss: 0.0765 - val_acc: 0.9905\n",
            "Epoch 102/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.0096e-07 - acc: 1.0000 - val_loss: 0.0774 - val_acc: 0.9907\n",
            "Epoch 103/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.0095e-07 - acc: 1.0000 - val_loss: 0.0762 - val_acc: 0.9907\n",
            "Epoch 104/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 1.0093e-07 - acc: 1.0000 - val_loss: 0.0766 - val_acc: 0.9905\n",
            "Epoch 105/150\n",
            "8822/8822 [==============================] - 5s 532us/step - loss: 1.0088e-07 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 0.9905\n",
            "Epoch 106/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.0086e-07 - acc: 1.0000 - val_loss: 0.0773 - val_acc: 0.9907\n",
            "Epoch 107/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 1.0092e-07 - acc: 1.0000 - val_loss: 0.0758 - val_acc: 0.9907\n",
            "Epoch 108/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 1.0084e-07 - acc: 1.0000 - val_loss: 0.0772 - val_acc: 0.9905\n",
            "Epoch 109/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 1.0081e-07 - acc: 1.0000 - val_loss: 0.0774 - val_acc: 0.9905\n",
            "Epoch 110/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.0081e-07 - acc: 1.0000 - val_loss: 0.0774 - val_acc: 0.9907\n",
            "Epoch 111/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.0079e-07 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 0.9907\n",
            "Epoch 112/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.0079e-07 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 0.9907\n",
            "Epoch 113/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.0078e-07 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 0.9905\n",
            "Epoch 114/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.0078e-07 - acc: 1.0000 - val_loss: 0.0772 - val_acc: 0.9905\n",
            "Epoch 115/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 1.0079e-07 - acc: 1.0000 - val_loss: 0.0771 - val_acc: 0.9907\n",
            "Epoch 116/150\n",
            "8822/8822 [==============================] - 5s 533us/step - loss: 1.0079e-07 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 0.9907\n",
            "Epoch 117/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 1.0080e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9905\n",
            "Epoch 118/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.0079e-07 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 0.9909\n",
            "Epoch 119/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 1.0080e-07 - acc: 1.0000 - val_loss: 0.0772 - val_acc: 0.9912\n",
            "Epoch 120/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 1.0081e-07 - acc: 1.0000 - val_loss: 0.0776 - val_acc: 0.9907\n",
            "Epoch 121/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 1.0085e-07 - acc: 1.0000 - val_loss: 0.0773 - val_acc: 0.9909\n",
            "Epoch 122/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 1.0078e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 123/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 124/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 125/150\n",
            "8822/8822 [==============================] - 5s 530us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 126/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 127/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 128/150\n",
            "8822/8822 [==============================] - 5s 523us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 129/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 130/150\n",
            "8822/8822 [==============================] - 5s 523us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 131/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 132/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 133/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 134/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 135/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 136/150\n",
            "8822/8822 [==============================] - 5s 523us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 137/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 138/150\n",
            "8822/8822 [==============================] - 5s 524us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 139/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 140/150\n",
            "8822/8822 [==============================] - 5s 524us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 141/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 142/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 143/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 144/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 145/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 146/150\n",
            "8822/8822 [==============================] - 5s 523us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 147/150\n",
            "8822/8822 [==============================] - 5s 524us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 148/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 149/150\n",
            "8822/8822 [==============================] - 5s 531us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Epoch 150/150\n",
            "8822/8822 [==============================] - 5s 536us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9907\n",
            "Bush F1 Score on Train :  1.0\n",
            "Bush F1 Score on Test :  0.8776119402985074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vFcxI1g1FPC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5424
        },
        "outputId": "98b4be57-5aef-4598-8ede-5ba1ba45c30f"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "modelForBush=load_model(\"13initialized-model.keras\")\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_reshaped, \n",
        "             y_bush,shuffle = True ,test_size= 1./3, random_state=6099, stratify  = y_bush) # A20396099\n",
        "\n",
        "\n",
        "modelForBush.fit(X_train_b,y_train_b, epochs=150, batch_size=32, validation_data = (X_test_b, y_test_b ) )\n",
        "\n",
        "y_predicted_train_bush = modelForBush.predict_classes(X_train_b) \n",
        "y_predicted_test_bush = modelForBush.predict_classes(X_test_b) \n",
        "result_f1_train_bush_E70=f1_score(y_train_b, y_predicted_train_bush)\n",
        "result_f1_test_bush_E70=f1_score(y_test_b, y_predicted_test_bush)\n",
        "print(\"Bush F1 Score on Train : \",result_f1_train_bush_E70)\n",
        "print(\"Bush F1 Score on Test : \",result_f1_test_bush_E70)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8822 samples, validate on 4411 samples\n",
            "Epoch 1/150\n",
            "8822/8822 [==============================] - 7s 754us/step - loss: 0.5333 - acc: 0.7977 - val_loss: 15.2599 - val_acc: 0.0401\n",
            "Epoch 2/150\n",
            "8822/8822 [==============================] - 5s 603us/step - loss: 0.1566 - acc: 0.9569 - val_loss: 11.8546 - val_acc: 0.0401\n",
            "Epoch 3/150\n",
            "8822/8822 [==============================] - 5s 609us/step - loss: 0.1083 - acc: 0.9655 - val_loss: 1.9433 - val_acc: 0.2476\n",
            "Epoch 4/150\n",
            "8822/8822 [==============================] - 5s 614us/step - loss: 0.0803 - acc: 0.9728 - val_loss: 0.3396 - val_acc: 0.9599\n",
            "Epoch 5/150\n",
            "8822/8822 [==============================] - 5s 616us/step - loss: 0.0617 - acc: 0.9781 - val_loss: 0.3039 - val_acc: 0.9601\n",
            "Epoch 6/150\n",
            "8822/8822 [==============================] - 5s 606us/step - loss: 0.0524 - acc: 0.9802 - val_loss: 11.7755 - val_acc: 0.0404\n",
            "Epoch 7/150\n",
            "8822/8822 [==============================] - 5s 605us/step - loss: 0.0430 - acc: 0.9845 - val_loss: 0.0679 - val_acc: 0.9812\n",
            "Epoch 8/150\n",
            "8822/8822 [==============================] - 5s 606us/step - loss: 0.0403 - acc: 0.9848 - val_loss: 15.0417 - val_acc: 0.0401\n",
            "Epoch 9/150\n",
            "8822/8822 [==============================] - 5s 605us/step - loss: 0.0271 - acc: 0.9903 - val_loss: 0.6428 - val_acc: 0.9599\n",
            "Epoch 10/150\n",
            "8822/8822 [==============================] - 5s 606us/step - loss: 0.0287 - acc: 0.9898 - val_loss: 0.3489 - val_acc: 0.9610\n",
            "Epoch 11/150\n",
            "8822/8822 [==============================] - 5s 605us/step - loss: 0.0249 - acc: 0.9913 - val_loss: 0.5043 - val_acc: 0.9599\n",
            "Epoch 12/150\n",
            "8822/8822 [==============================] - 5s 605us/step - loss: 0.0215 - acc: 0.9925 - val_loss: 0.0805 - val_acc: 0.9816\n",
            "Epoch 13/150\n",
            "8822/8822 [==============================] - 5s 605us/step - loss: 0.0167 - acc: 0.9947 - val_loss: 0.6229 - val_acc: 0.7815\n",
            "Epoch 14/150\n",
            "8822/8822 [==============================] - 5s 606us/step - loss: 0.0169 - acc: 0.9935 - val_loss: 0.0520 - val_acc: 0.9835\n",
            "Epoch 15/150\n",
            "8822/8822 [==============================] - 5s 606us/step - loss: 0.0145 - acc: 0.9950 - val_loss: 0.0909 - val_acc: 0.9816\n",
            "Epoch 16/150\n",
            "8822/8822 [==============================] - 5s 608us/step - loss: 0.0103 - acc: 0.9965 - val_loss: 0.1809 - val_acc: 0.9735\n",
            "Epoch 17/150\n",
            "8822/8822 [==============================] - 5s 605us/step - loss: 0.0109 - acc: 0.9957 - val_loss: 0.0574 - val_acc: 0.9859\n",
            "Epoch 18/150\n",
            "8822/8822 [==============================] - 5s 602us/step - loss: 0.0103 - acc: 0.9959 - val_loss: 0.2729 - val_acc: 0.9077\n",
            "Epoch 19/150\n",
            "8822/8822 [==============================] - 5s 601us/step - loss: 0.0073 - acc: 0.9972 - val_loss: 0.0549 - val_acc: 0.9871\n",
            "Epoch 20/150\n",
            "8822/8822 [==============================] - 5s 604us/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.1230 - val_acc: 0.9626\n",
            "Epoch 21/150\n",
            "8822/8822 [==============================] - 5s 608us/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.7312 - val_acc: 0.7971\n",
            "Epoch 22/150\n",
            "8822/8822 [==============================] - 5s 591us/step - loss: 0.0085 - acc: 0.9969 - val_loss: 0.0672 - val_acc: 0.9791\n",
            "Epoch 23/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0089 - acc: 0.9969 - val_loss: 0.1241 - val_acc: 0.9621\n",
            "Epoch 24/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0101 - acc: 0.9972 - val_loss: 0.0835 - val_acc: 0.9744\n",
            "Epoch 25/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0086 - acc: 0.9971 - val_loss: 11.7520 - val_acc: 0.0696\n",
            "Epoch 26/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0633 - val_acc: 0.9882\n",
            "Epoch 27/150\n",
            "8822/8822 [==============================] - 5s 597us/step - loss: 0.0064 - acc: 0.9974 - val_loss: 2.2349 - val_acc: 0.5654\n",
            "Epoch 28/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0042 - acc: 0.9982 - val_loss: 0.1071 - val_acc: 0.9655\n",
            "Epoch 29/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.3070 - val_acc: 0.9676\n",
            "Epoch 30/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0039 - acc: 0.9984 - val_loss: 0.1254 - val_acc: 0.9828\n",
            "Epoch 31/150\n",
            "8822/8822 [==============================] - 5s 597us/step - loss: 0.0068 - acc: 0.9973 - val_loss: 0.0523 - val_acc: 0.9857\n",
            "Epoch 32/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0052 - acc: 0.9980 - val_loss: 0.0870 - val_acc: 0.9869\n",
            "Epoch 33/150\n",
            "8822/8822 [==============================] - 5s 591us/step - loss: 0.0044 - acc: 0.9982 - val_loss: 0.1333 - val_acc: 0.9830\n",
            "Epoch 34/150\n",
            "8822/8822 [==============================] - 5s 603us/step - loss: 0.0038 - acc: 0.9985 - val_loss: 0.4767 - val_acc: 0.9615\n",
            "Epoch 35/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.3728 - val_acc: 0.9016\n",
            "Epoch 36/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.4069 - val_acc: 0.8966\n",
            "Epoch 37/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.1117 - val_acc: 0.9669\n",
            "Epoch 38/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0029 - acc: 0.9986 - val_loss: 0.0524 - val_acc: 0.9864\n",
            "Epoch 39/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.1681 - val_acc: 0.9549\n",
            "Epoch 40/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.0864 - val_acc: 0.9866\n",
            "Epoch 41/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0040 - acc: 0.9980 - val_loss: 0.0419 - val_acc: 0.9930\n",
            "Epoch 42/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0470 - val_acc: 0.9909\n",
            "Epoch 43/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0017 - acc: 0.9992 - val_loss: 0.1443 - val_acc: 0.9816\n",
            "Epoch 44/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.2256 - val_acc: 0.9773\n",
            "Epoch 45/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0038 - acc: 0.9985 - val_loss: 0.1873 - val_acc: 0.9794\n",
            "Epoch 46/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.0514 - val_acc: 0.9925\n",
            "Epoch 47/150\n",
            "8822/8822 [==============================] - 5s 591us/step - loss: 0.0041 - acc: 0.9983 - val_loss: 0.3825 - val_acc: 0.9660\n",
            "Epoch 48/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0042 - acc: 0.9978 - val_loss: 0.0830 - val_acc: 0.9887\n",
            "Epoch 49/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0449 - val_acc: 0.9912\n",
            "Epoch 50/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0620 - val_acc: 0.9862\n",
            "Epoch 51/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0047 - acc: 0.9982 - val_loss: 0.0767 - val_acc: 0.9862\n",
            "Epoch 52/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.1348 - val_acc: 0.9703\n",
            "Epoch 53/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0036 - acc: 0.9986 - val_loss: 0.2089 - val_acc: 0.9803\n",
            "Epoch 54/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0034 - acc: 0.9985 - val_loss: 0.0552 - val_acc: 0.9921\n",
            "Epoch 55/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0034 - acc: 0.9984 - val_loss: 0.1372 - val_acc: 0.9828\n",
            "Epoch 56/150\n",
            "8822/8822 [==============================] - 5s 591us/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.4735 - val_acc: 0.9635\n",
            "Epoch 57/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0019 - acc: 0.9989 - val_loss: 0.3980 - val_acc: 0.9674\n",
            "Epoch 58/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.2930 - val_acc: 0.9340\n",
            "Epoch 59/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0039 - acc: 0.9985 - val_loss: 0.2176 - val_acc: 0.9483\n",
            "Epoch 60/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.2988 - val_acc: 0.9730\n",
            "Epoch 61/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.1742 - val_acc: 0.9825\n",
            "Epoch 62/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.4436 - val_acc: 0.9637\n",
            "Epoch 63/150\n",
            "8822/8822 [==============================] - 5s 599us/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.4520 - val_acc: 0.9050\n",
            "Epoch 64/150\n",
            "8822/8822 [==============================] - 5s 600us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0561 - val_acc: 0.9907\n",
            "Epoch 65/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0558 - val_acc: 0.9918\n",
            "Epoch 66/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.1925 - val_acc: 0.9814\n",
            "Epoch 67/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.0631 - val_acc: 0.9887\n",
            "Epoch 68/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 8.3425e-04 - acc: 0.9997 - val_loss: 0.5851 - val_acc: 0.8889\n",
            "Epoch 69/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0594 - val_acc: 0.9921\n",
            "Epoch 70/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0043 - acc: 0.9983 - val_loss: 0.1940 - val_acc: 0.9603\n",
            "Epoch 71/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0013 - acc: 0.9992 - val_loss: 0.0612 - val_acc: 0.9921\n",
            "Epoch 72/150\n",
            "8822/8822 [==============================] - 5s 590us/step - loss: 0.0059 - acc: 0.9977 - val_loss: 0.0657 - val_acc: 0.9921\n",
            "Epoch 73/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.4960 - val_acc: 0.9630\n",
            "Epoch 74/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.2016 - val_acc: 0.9796\n",
            "Epoch 75/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0061 - acc: 0.9982 - val_loss: 2.9147 - val_acc: 0.6309\n",
            "Epoch 76/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.2901 - val_acc: 0.9497\n",
            "Epoch 77/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0039 - acc: 0.9984 - val_loss: 0.0898 - val_acc: 0.9848\n",
            "Epoch 78/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0040 - acc: 0.9984 - val_loss: 0.1187 - val_acc: 0.9866\n",
            "Epoch 79/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0021 - acc: 0.9990 - val_loss: 0.0824 - val_acc: 0.9891\n",
            "Epoch 80/150\n",
            "8822/8822 [==============================] - 5s 597us/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.8118 - val_acc: 0.8662\n",
            "Epoch 81/150\n",
            "8822/8822 [==============================] - 5s 601us/step - loss: 0.0048 - acc: 0.9982 - val_loss: 0.3450 - val_acc: 0.9370\n",
            "Epoch 82/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0042 - acc: 0.9990 - val_loss: 0.1808 - val_acc: 0.9635\n",
            "Epoch 83/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0018 - acc: 0.9992 - val_loss: 0.3368 - val_acc: 0.9712\n",
            "Epoch 84/150\n",
            "8822/8822 [==============================] - 5s 600us/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0771 - val_acc: 0.9878\n",
            "Epoch 85/150\n",
            "8822/8822 [==============================] - 5s 597us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.0695 - val_acc: 0.9914\n",
            "Epoch 86/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.1045 - val_acc: 0.9798\n",
            "Epoch 87/150\n",
            "8822/8822 [==============================] - 5s 599us/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0658 - val_acc: 0.9921\n",
            "Epoch 88/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 3.6202 - val_acc: 0.5645\n",
            "Epoch 89/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0022 - acc: 0.9990 - val_loss: 0.0821 - val_acc: 0.9893\n",
            "Epoch 90/150\n",
            "8822/8822 [==============================] - 5s 598us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.1782 - val_acc: 0.9837\n",
            "Epoch 91/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.1973 - val_acc: 0.9821\n",
            "Epoch 92/150\n",
            "8822/8822 [==============================] - 5s 598us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.9380 - val_acc: 0.8472\n",
            "Epoch 93/150\n",
            "8822/8822 [==============================] - 5s 603us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0712 - val_acc: 0.9909\n",
            "Epoch 94/150\n",
            "8822/8822 [==============================] - 5s 591us/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0859 - val_acc: 0.9891\n",
            "Epoch 95/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0031 - acc: 0.9986 - val_loss: 0.0881 - val_acc: 0.9893\n",
            "Epoch 96/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0028 - acc: 0.9988 - val_loss: 0.3654 - val_acc: 0.9404\n",
            "Epoch 97/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.2510 - val_acc: 0.9796\n",
            "Epoch 98/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.1694 - val_acc: 0.9737\n",
            "Epoch 99/150\n",
            "8822/8822 [==============================] - 5s 598us/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.1288 - val_acc: 0.9857\n",
            "Epoch 100/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0893 - val_acc: 0.9893\n",
            "Epoch 101/150\n",
            "8822/8822 [==============================] - 5s 597us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.1575 - val_acc: 0.9698\n",
            "Epoch 102/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 9.0447e-04 - acc: 0.9998 - val_loss: 0.1744 - val_acc: 0.9644\n",
            "Epoch 103/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.1154 - val_acc: 0.9878\n",
            "Epoch 104/150\n",
            "8822/8822 [==============================] - 5s 598us/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.2216 - val_acc: 0.9805\n",
            "Epoch 105/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0037 - acc: 0.9992 - val_loss: 0.1025 - val_acc: 0.9884\n",
            "Epoch 106/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.2844 - val_acc: 0.9755\n",
            "Epoch 107/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.1310 - val_acc: 0.9857\n",
            "Epoch 108/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0023 - acc: 0.9988 - val_loss: 0.1924 - val_acc: 0.9667\n",
            "Epoch 109/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 2.3394 - val_acc: 0.7023\n",
            "Epoch 110/150\n",
            "8822/8822 [==============================] - 5s 597us/step - loss: 9.5764e-04 - acc: 0.9995 - val_loss: 0.2599 - val_acc: 0.9796\n",
            "Epoch 111/150\n",
            "8822/8822 [==============================] - 5s 598us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.3065 - val_acc: 0.9764\n",
            "Epoch 112/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0614 - val_acc: 0.9925\n",
            "Epoch 113/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 6.2169e-04 - acc: 0.9995 - val_loss: 0.6390 - val_acc: 0.8987\n",
            "Epoch 114/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.0908 - val_acc: 0.9905\n",
            "Epoch 115/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0023 - acc: 0.9992 - val_loss: 0.3070 - val_acc: 0.9442\n",
            "Epoch 116/150\n",
            "8822/8822 [==============================] - 5s 593us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.5346 - val_acc: 0.9628\n",
            "Epoch 117/150\n",
            "8822/8822 [==============================] - 5s 599us/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0787 - val_acc: 0.9905\n",
            "Epoch 118/150\n",
            "8822/8822 [==============================] - 5s 613us/step - loss: 4.0074e-04 - acc: 0.9998 - val_loss: 1.2571 - val_acc: 0.8293\n",
            "Epoch 119/150\n",
            "8822/8822 [==============================] - 5s 601us/step - loss: 0.0021 - acc: 0.9990 - val_loss: 0.2036 - val_acc: 0.9821\n",
            "Epoch 120/150\n",
            "8822/8822 [==============================] - 5s 595us/step - loss: 0.0015 - acc: 0.9990 - val_loss: 0.3049 - val_acc: 0.9769\n",
            "Epoch 121/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.2660 - val_acc: 0.9581\n",
            "Epoch 122/150\n",
            "8822/8822 [==============================] - 5s 599us/step - loss: 0.0012 - acc: 0.9994 - val_loss: 0.1866 - val_acc: 0.9696\n",
            "Epoch 123/150\n",
            "8822/8822 [==============================] - 5s 600us/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0710 - val_acc: 0.9914\n",
            "Epoch 124/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0019 - acc: 0.9997 - val_loss: 1.9107 - val_acc: 0.7556\n",
            "Epoch 125/150\n",
            "8822/8822 [==============================] - 5s 597us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0838 - val_acc: 0.9907\n",
            "Epoch 126/150\n",
            "8822/8822 [==============================] - 5s 591us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.1483 - val_acc: 0.9853\n",
            "Epoch 127/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0856 - val_acc: 0.9903\n",
            "Epoch 128/150\n",
            "8822/8822 [==============================] - 5s 592us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1643 - val_acc: 0.9844\n",
            "Epoch 129/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2436 - val_acc: 0.9590\n",
            "Epoch 130/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.1071 - val_acc: 0.9891\n",
            "Epoch 131/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.3993 - val_acc: 0.9687\n",
            "Epoch 132/150\n",
            "8822/8822 [==============================] - 5s 594us/step - loss: 0.0012 - acc: 0.9995 - val_loss: 0.0661 - val_acc: 0.9916\n",
            "Epoch 133/150\n",
            "8822/8822 [==============================] - 5s 599us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.1630 - val_acc: 0.9848\n",
            "Epoch 134/150\n",
            "8822/8822 [==============================] - 5s 600us/step - loss: 0.0023 - acc: 0.9992 - val_loss: 0.0708 - val_acc: 0.9914\n",
            "Epoch 135/150\n",
            "8822/8822 [==============================] - 5s 599us/step - loss: 0.0039 - acc: 0.9994 - val_loss: 0.2084 - val_acc: 0.9664\n",
            "Epoch 136/150\n",
            "8822/8822 [==============================] - 5s 603us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.1989 - val_acc: 0.9832\n",
            "Epoch 137/150\n",
            "8822/8822 [==============================] - 5s 598us/step - loss: 0.0049 - acc: 0.9990 - val_loss: 0.3622 - val_acc: 0.9717\n",
            "Epoch 138/150\n",
            "8822/8822 [==============================] - 5s 597us/step - loss: 0.0010 - acc: 0.9994 - val_loss: 0.2719 - val_acc: 0.9778\n",
            "Epoch 139/150\n",
            "8822/8822 [==============================] - 5s 598us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0757 - val_acc: 0.9914\n",
            "Epoch 140/150\n",
            "8822/8822 [==============================] - 5s 600us/step - loss: 0.0019 - acc: 0.9993 - val_loss: 0.1566 - val_acc: 0.9859\n",
            "Epoch 141/150\n",
            "8822/8822 [==============================] - 5s 597us/step - loss: 0.0019 - acc: 0.9993 - val_loss: 0.2788 - val_acc: 0.9773\n",
            "Epoch 142/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0935 - val_acc: 0.9866\n",
            "Epoch 143/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.1868 - val_acc: 0.9832\n",
            "Epoch 144/150\n",
            "8822/8822 [==============================] - 5s 601us/step - loss: 4.8283e-04 - acc: 0.9998 - val_loss: 0.1413 - val_acc: 0.9791\n",
            "Epoch 145/150\n",
            "8822/8822 [==============================] - 5s 596us/step - loss: 4.5903e-04 - acc: 0.9997 - val_loss: 0.1431 - val_acc: 0.9869\n",
            "Epoch 146/150\n",
            "8822/8822 [==============================] - 5s 599us/step - loss: 8.2714e-04 - acc: 0.9997 - val_loss: 0.1222 - val_acc: 0.9882\n",
            "Epoch 147/150\n",
            "8822/8822 [==============================] - 5s 597us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0958 - val_acc: 0.9898\n",
            "Epoch 148/150\n",
            "8822/8822 [==============================] - 5s 598us/step - loss: 0.0012 - acc: 0.9994 - val_loss: 0.0755 - val_acc: 0.9912\n",
            "Epoch 149/150\n",
            "8822/8822 [==============================] - 5s 604us/step - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0828 - val_acc: 0.9903\n",
            "Epoch 150/150\n",
            "8822/8822 [==============================] - 5s 610us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0776 - val_acc: 0.9891\n",
            "Bush F1 Score on Train :  1.0\n",
            "Bush F1 Score on Test :  0.8659217877094972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rJH_b6SQFSor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5424
        },
        "outputId": "3a3213a4-c827-421f-c084-3d6b79cebc1b"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "modelForBush=load_model(\"10initialized-model.keras\")\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_reshaped, \n",
        "             y_bush,shuffle = True ,test_size= 1./3, random_state=6099, stratify  = y_bush) # A20396099\n",
        "\n",
        "\n",
        "modelForBush.fit(X_train_b,y_train_b, epochs=150, batch_size=32, validation_data = (X_test_b, y_test_b ) )\n",
        "\n",
        "y_predicted_train_bush = modelForBush.predict_classes(X_train_b) \n",
        "y_predicted_test_bush = modelForBush.predict_classes(X_test_b) \n",
        "result_f1_train_bush_E70=f1_score(y_train_b, y_predicted_train_bush)\n",
        "result_f1_test_bush_E70=f1_score(y_test_b, y_predicted_test_bush)\n",
        "print(\"Bush F1 Score on Train : \",result_f1_train_bush_E70)\n",
        "print(\"Bush F1 Score on Test : \",result_f1_test_bush_E70)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8822 samples, validate on 4411 samples\n",
            "Epoch 1/150\n",
            "8822/8822 [==============================] - 5s 573us/step - loss: 0.1849 - acc: 0.9600 - val_loss: 0.1668 - val_acc: 0.9599\n",
            "Epoch 2/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 0.1651 - acc: 0.9600 - val_loss: 0.1578 - val_acc: 0.9599\n",
            "Epoch 3/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 0.1518 - acc: 0.9599 - val_loss: 0.1438 - val_acc: 0.9601\n",
            "Epoch 4/150\n",
            "8822/8822 [==============================] - 5s 523us/step - loss: 0.1284 - acc: 0.9607 - val_loss: 0.1100 - val_acc: 0.9633\n",
            "Epoch 5/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 0.1009 - acc: 0.9659 - val_loss: 0.0919 - val_acc: 0.9703\n",
            "Epoch 6/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 0.0762 - acc: 0.9736 - val_loss: 0.0770 - val_acc: 0.9753\n",
            "Epoch 7/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 0.0572 - acc: 0.9810 - val_loss: 0.0632 - val_acc: 0.9785\n",
            "Epoch 8/150\n",
            "8822/8822 [==============================] - 5s 517us/step - loss: 0.0478 - acc: 0.9838 - val_loss: 0.0556 - val_acc: 0.9812\n",
            "Epoch 9/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 0.0374 - acc: 0.9873 - val_loss: 0.0514 - val_acc: 0.9810\n",
            "Epoch 10/150\n",
            "8822/8822 [==============================] - 5s 516us/step - loss: 0.0319 - acc: 0.9893 - val_loss: 0.0443 - val_acc: 0.9853\n",
            "Epoch 11/150\n",
            "8822/8822 [==============================] - 5s 524us/step - loss: 0.0248 - acc: 0.9932 - val_loss: 0.0449 - val_acc: 0.9855\n",
            "Epoch 12/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 0.0193 - acc: 0.9937 - val_loss: 0.0425 - val_acc: 0.9857\n",
            "Epoch 13/150\n",
            "8822/8822 [==============================] - 5s 523us/step - loss: 0.0164 - acc: 0.9956 - val_loss: 0.0402 - val_acc: 0.9871\n",
            "Epoch 14/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 0.0128 - acc: 0.9960 - val_loss: 0.0438 - val_acc: 0.9866\n",
            "Epoch 15/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 0.0092 - acc: 0.9975 - val_loss: 0.0413 - val_acc: 0.9878\n",
            "Epoch 16/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 0.0068 - acc: 0.9985 - val_loss: 0.0386 - val_acc: 0.9866\n",
            "Epoch 17/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 0.0056 - acc: 0.9986 - val_loss: 0.0407 - val_acc: 0.9857\n",
            "Epoch 18/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 0.0030 - acc: 0.9998 - val_loss: 0.0452 - val_acc: 0.9880\n",
            "Epoch 19/150\n",
            "8822/8822 [==============================] - 5s 516us/step - loss: 0.0023 - acc: 0.9997 - val_loss: 0.0402 - val_acc: 0.9889\n",
            "Epoch 20/150\n",
            "8822/8822 [==============================] - 5s 521us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0425 - val_acc: 0.9880\n",
            "Epoch 21/150\n",
            "8822/8822 [==============================] - 5s 517us/step - loss: 9.3332e-04 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 0.9882\n",
            "Epoch 22/150\n",
            "8822/8822 [==============================] - 5s 521us/step - loss: 7.3014e-04 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9893\n",
            "Epoch 23/150\n",
            "8822/8822 [==============================] - 5s 516us/step - loss: 5.6572e-04 - acc: 1.0000 - val_loss: 0.0441 - val_acc: 0.9884\n",
            "Epoch 24/150\n",
            "8822/8822 [==============================] - 5s 521us/step - loss: 4.3664e-04 - acc: 1.0000 - val_loss: 0.0549 - val_acc: 0.9884\n",
            "Epoch 25/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 3.8352e-04 - acc: 1.0000 - val_loss: 0.0483 - val_acc: 0.9887\n",
            "Epoch 26/150\n",
            "8822/8822 [==============================] - 5s 525us/step - loss: 2.5079e-04 - acc: 1.0000 - val_loss: 0.0557 - val_acc: 0.9887\n",
            "Epoch 27/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.9807e-04 - acc: 1.0000 - val_loss: 0.0530 - val_acc: 0.9889\n",
            "Epoch 28/150\n",
            "8822/8822 [==============================] - 5s 534us/step - loss: 1.5724e-04 - acc: 1.0000 - val_loss: 0.0524 - val_acc: 0.9889\n",
            "Epoch 29/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 1.2949e-04 - acc: 1.0000 - val_loss: 0.0515 - val_acc: 0.9880\n",
            "Epoch 30/150\n",
            "8822/8822 [==============================] - 5s 526us/step - loss: 1.0315e-04 - acc: 1.0000 - val_loss: 0.0527 - val_acc: 0.9882\n",
            "Epoch 31/150\n",
            "8822/8822 [==============================] - 5s 523us/step - loss: 8.2975e-05 - acc: 1.0000 - val_loss: 0.0543 - val_acc: 0.9884\n",
            "Epoch 32/150\n",
            "8822/8822 [==============================] - 5s 521us/step - loss: 7.1601e-05 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9884\n",
            "Epoch 33/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 5.4433e-05 - acc: 1.0000 - val_loss: 0.0552 - val_acc: 0.9880\n",
            "Epoch 34/150\n",
            "8822/8822 [==============================] - 5s 524us/step - loss: 4.8527e-05 - acc: 1.0000 - val_loss: 0.0570 - val_acc: 0.9887\n",
            "Epoch 35/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 3.6307e-05 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9884\n",
            "Epoch 36/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 3.1837e-05 - acc: 1.0000 - val_loss: 0.0620 - val_acc: 0.9889\n",
            "Epoch 37/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 2.6742e-05 - acc: 1.0000 - val_loss: 0.0604 - val_acc: 0.9887\n",
            "Epoch 38/150\n",
            "8822/8822 [==============================] - 5s 523us/step - loss: 2.2436e-05 - acc: 1.0000 - val_loss: 0.0591 - val_acc: 0.9887\n",
            "Epoch 39/150\n",
            "8822/8822 [==============================] - 5s 523us/step - loss: 1.7715e-05 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9884\n",
            "Epoch 40/150\n",
            "8822/8822 [==============================] - 5s 524us/step - loss: 1.5654e-05 - acc: 1.0000 - val_loss: 0.0591 - val_acc: 0.9887\n",
            "Epoch 41/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 1.2341e-05 - acc: 1.0000 - val_loss: 0.0618 - val_acc: 0.9884\n",
            "Epoch 42/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 1.0304e-05 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9884\n",
            "Epoch 43/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 9.0014e-06 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9884\n",
            "Epoch 44/150\n",
            "8822/8822 [==============================] - 5s 523us/step - loss: 7.4774e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9891\n",
            "Epoch 45/150\n",
            "8822/8822 [==============================] - 5s 517us/step - loss: 6.4060e-06 - acc: 1.0000 - val_loss: 0.0669 - val_acc: 0.9884\n",
            "Epoch 46/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 5.3371e-06 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 0.9884\n",
            "Epoch 47/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 4.3550e-06 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 0.9887\n",
            "Epoch 48/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 3.6140e-06 - acc: 1.0000 - val_loss: 0.0688 - val_acc: 0.9884\n",
            "Epoch 49/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 3.0864e-06 - acc: 1.0000 - val_loss: 0.0714 - val_acc: 0.9884\n",
            "Epoch 50/150\n",
            "8822/8822 [==============================] - 5s 517us/step - loss: 2.6458e-06 - acc: 1.0000 - val_loss: 0.0722 - val_acc: 0.9878\n",
            "Epoch 51/150\n",
            "8822/8822 [==============================] - 5s 521us/step - loss: 2.1942e-06 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 0.9882\n",
            "Epoch 52/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 1.9340e-06 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 0.9884\n",
            "Epoch 53/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 1.6214e-06 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9884\n",
            "Epoch 54/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 1.4165e-06 - acc: 1.0000 - val_loss: 0.0741 - val_acc: 0.9880\n",
            "Epoch 55/150\n",
            "8822/8822 [==============================] - 5s 521us/step - loss: 1.2014e-06 - acc: 1.0000 - val_loss: 0.0734 - val_acc: 0.9884\n",
            "Epoch 56/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 1.0668e-06 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 0.9884\n",
            "Epoch 57/150\n",
            "8822/8822 [==============================] - 5s 528us/step - loss: 8.9730e-07 - acc: 1.0000 - val_loss: 0.0810 - val_acc: 0.9882\n",
            "Epoch 58/150\n",
            "8822/8822 [==============================] - 5s 534us/step - loss: 7.6332e-07 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9882\n",
            "Epoch 59/150\n",
            "8822/8822 [==============================] - 5s 539us/step - loss: 6.8732e-07 - acc: 1.0000 - val_loss: 0.0792 - val_acc: 0.9884\n",
            "Epoch 60/150\n",
            "8822/8822 [==============================] - 5s 512us/step - loss: 5.8068e-07 - acc: 1.0000 - val_loss: 0.0775 - val_acc: 0.9887\n",
            "Epoch 61/150\n",
            "8822/8822 [==============================] - 5s 516us/step - loss: 5.1998e-07 - acc: 1.0000 - val_loss: 0.0811 - val_acc: 0.9882\n",
            "Epoch 62/150\n",
            "8822/8822 [==============================] - 5s 516us/step - loss: 4.5213e-07 - acc: 1.0000 - val_loss: 0.0799 - val_acc: 0.9887\n",
            "Epoch 63/150\n",
            "8822/8822 [==============================] - 5s 515us/step - loss: 3.8463e-07 - acc: 1.0000 - val_loss: 0.0821 - val_acc: 0.9884\n",
            "Epoch 64/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 3.4819e-07 - acc: 1.0000 - val_loss: 0.0815 - val_acc: 0.9887\n",
            "Epoch 65/150\n",
            "8822/8822 [==============================] - 5s 513us/step - loss: 3.1691e-07 - acc: 1.0000 - val_loss: 0.0796 - val_acc: 0.9884\n",
            "Epoch 66/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 2.9358e-07 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 0.9882\n",
            "Epoch 67/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 2.5806e-07 - acc: 1.0000 - val_loss: 0.0850 - val_acc: 0.9880\n",
            "Epoch 68/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 2.2843e-07 - acc: 1.0000 - val_loss: 0.0869 - val_acc: 0.9880\n",
            "Epoch 69/150\n",
            "8822/8822 [==============================] - 5s 516us/step - loss: 2.1326e-07 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 0.9882\n",
            "Epoch 70/150\n",
            "8822/8822 [==============================] - 5s 515us/step - loss: 1.9892e-07 - acc: 1.0000 - val_loss: 0.0878 - val_acc: 0.9880\n",
            "Epoch 71/150\n",
            "8822/8822 [==============================] - 5s 515us/step - loss: 1.7951e-07 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9884\n",
            "Epoch 72/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 1.7005e-07 - acc: 1.0000 - val_loss: 0.0855 - val_acc: 0.9887\n",
            "Epoch 73/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 1.5933e-07 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 0.9880\n",
            "Epoch 74/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 1.5028e-07 - acc: 1.0000 - val_loss: 0.0906 - val_acc: 0.9882\n",
            "Epoch 75/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 1.4306e-07 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 0.9884\n",
            "Epoch 76/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 1.3618e-07 - acc: 1.0000 - val_loss: 0.0887 - val_acc: 0.9884\n",
            "Epoch 77/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 1.3092e-07 - acc: 1.0000 - val_loss: 0.0893 - val_acc: 0.9882\n",
            "Epoch 78/150\n",
            "8822/8822 [==============================] - 5s 517us/step - loss: 1.2659e-07 - acc: 1.0000 - val_loss: 0.0899 - val_acc: 0.9884\n",
            "Epoch 79/150\n",
            "8822/8822 [==============================] - 5s 516us/step - loss: 1.2283e-07 - acc: 1.0000 - val_loss: 0.0938 - val_acc: 0.9884\n",
            "Epoch 80/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 1.1913e-07 - acc: 1.0000 - val_loss: 0.0898 - val_acc: 0.9889\n",
            "Epoch 81/150\n",
            "8822/8822 [==============================] - 5s 517us/step - loss: 1.1872e-07 - acc: 1.0000 - val_loss: 0.0942 - val_acc: 0.9882\n",
            "Epoch 82/150\n",
            "8822/8822 [==============================] - 5s 517us/step - loss: 1.1319e-07 - acc: 1.0000 - val_loss: 0.0949 - val_acc: 0.9882\n",
            "Epoch 83/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 1.1273e-07 - acc: 1.0000 - val_loss: 0.0934 - val_acc: 0.9884\n",
            "Epoch 84/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 1.1042e-07 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9889\n",
            "Epoch 85/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 1.0845e-07 - acc: 1.0000 - val_loss: 0.0946 - val_acc: 0.9884\n",
            "Epoch 86/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 1.0711e-07 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 0.9882\n",
            "Epoch 87/150\n",
            "8822/8822 [==============================] - 5s 517us/step - loss: 1.0596e-07 - acc: 1.0000 - val_loss: 0.0958 - val_acc: 0.9884\n",
            "Epoch 88/150\n",
            "8822/8822 [==============================] - 5s 517us/step - loss: 1.0490e-07 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 0.9891\n",
            "Epoch 89/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 1.0431e-07 - acc: 1.0000 - val_loss: 0.0933 - val_acc: 0.9889\n",
            "Epoch 90/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 1.0365e-07 - acc: 1.0000 - val_loss: 0.0969 - val_acc: 0.9884\n",
            "Epoch 91/150\n",
            "8822/8822 [==============================] - 5s 521us/step - loss: 1.0316e-07 - acc: 1.0000 - val_loss: 0.0954 - val_acc: 0.9891\n",
            "Epoch 92/150\n",
            "8822/8822 [==============================] - 5s 522us/step - loss: 1.0260e-07 - acc: 1.0000 - val_loss: 0.0959 - val_acc: 0.9884\n",
            "Epoch 93/150\n",
            "8822/8822 [==============================] - 5s 521us/step - loss: 1.0228e-07 - acc: 1.0000 - val_loss: 0.0964 - val_acc: 0.9889\n",
            "Epoch 94/150\n",
            "8822/8822 [==============================] - 5s 523us/step - loss: 1.0187e-07 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9884\n",
            "Epoch 95/150\n",
            "8822/8822 [==============================] - 5s 529us/step - loss: 1.0178e-07 - acc: 1.0000 - val_loss: 0.0970 - val_acc: 0.9887\n",
            "Epoch 96/150\n",
            "8822/8822 [==============================] - 5s 527us/step - loss: 1.0167e-07 - acc: 1.0000 - val_loss: 0.0963 - val_acc: 0.9891\n",
            "Epoch 97/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 1.0133e-07 - acc: 1.0000 - val_loss: 0.0983 - val_acc: 0.9887\n",
            "Epoch 98/150\n",
            "8822/8822 [==============================] - 5s 517us/step - loss: 1.0124e-07 - acc: 1.0000 - val_loss: 0.0991 - val_acc: 0.9884\n",
            "Epoch 99/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 1.0108e-07 - acc: 1.0000 - val_loss: 0.0995 - val_acc: 0.9882\n",
            "Epoch 100/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 1.0100e-07 - acc: 1.0000 - val_loss: 0.0989 - val_acc: 0.9884\n",
            "Epoch 101/150\n",
            "8822/8822 [==============================] - 5s 518us/step - loss: 1.0094e-07 - acc: 1.0000 - val_loss: 0.0987 - val_acc: 0.9882\n",
            "Epoch 102/150\n",
            "8822/8822 [==============================] - 5s 524us/step - loss: 1.0096e-07 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9884\n",
            "Epoch 103/150\n",
            "8822/8822 [==============================] - 5s 515us/step - loss: 1.0093e-07 - acc: 1.0000 - val_loss: 0.0984 - val_acc: 0.9884\n",
            "Epoch 104/150\n",
            "8822/8822 [==============================] - 5s 519us/step - loss: 1.0087e-07 - acc: 1.0000 - val_loss: 0.0996 - val_acc: 0.9882\n",
            "Epoch 105/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 1.0087e-07 - acc: 1.0000 - val_loss: 0.0979 - val_acc: 0.9887\n",
            "Epoch 106/150\n",
            "8822/8822 [==============================] - 5s 524us/step - loss: 1.0081e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9884\n",
            "Epoch 107/150\n",
            "8822/8822 [==============================] - 5s 520us/step - loss: 1.0082e-07 - acc: 1.0000 - val_loss: 0.0976 - val_acc: 0.9889\n",
            "Epoch 108/150\n",
            "8822/8822 [==============================] - 4s 502us/step - loss: 1.0081e-07 - acc: 1.0000 - val_loss: 0.1009 - val_acc: 0.9884\n",
            "Epoch 109/150\n",
            "8822/8822 [==============================] - 4s 498us/step - loss: 1.0081e-07 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9884\n",
            "Epoch 110/150\n",
            "8822/8822 [==============================] - 4s 495us/step - loss: 1.0080e-07 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 0.9884\n",
            "Epoch 111/150\n",
            "8822/8822 [==============================] - 4s 499us/step - loss: 1.0079e-07 - acc: 1.0000 - val_loss: 0.0996 - val_acc: 0.9882\n",
            "Epoch 112/150\n",
            "8822/8822 [==============================] - 4s 492us/step - loss: 1.0078e-07 - acc: 1.0000 - val_loss: 0.0997 - val_acc: 0.9882\n",
            "Epoch 113/150\n",
            "8822/8822 [==============================] - 4s 498us/step - loss: 1.0078e-07 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 0.9887\n",
            "Epoch 114/150\n",
            "8822/8822 [==============================] - 4s 495us/step - loss: 1.0078e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9887\n",
            "Epoch 115/150\n",
            "8822/8822 [==============================] - 4s 495us/step - loss: 1.0078e-07 - acc: 1.0000 - val_loss: 0.1016 - val_acc: 0.9884\n",
            "Epoch 116/150\n",
            "8822/8822 [==============================] - 4s 490us/step - loss: 1.0078e-07 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9887\n",
            "Epoch 117/150\n",
            "8822/8822 [==============================] - 4s 494us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0999 - val_acc: 0.9884\n",
            "Epoch 118/150\n",
            "8822/8822 [==============================] - 4s 492us/step - loss: 1.0080e-07 - acc: 1.0000 - val_loss: 0.1001 - val_acc: 0.9884\n",
            "Epoch 119/150\n",
            "8822/8822 [==============================] - 4s 496us/step - loss: 1.0078e-07 - acc: 1.0000 - val_loss: 0.0995 - val_acc: 0.9884\n",
            "Epoch 120/150\n",
            "8822/8822 [==============================] - 4s 494us/step - loss: 1.0078e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 121/150\n",
            "8822/8822 [==============================] - 4s 493us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 122/150\n",
            "8822/8822 [==============================] - 4s 492us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 123/150\n",
            "8822/8822 [==============================] - 4s 492us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 124/150\n",
            "8822/8822 [==============================] - 4s 498us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 125/150\n",
            "8822/8822 [==============================] - 4s 495us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 126/150\n",
            "8822/8822 [==============================] - 4s 492us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 127/150\n",
            "8822/8822 [==============================] - 4s 493us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 128/150\n",
            "8822/8822 [==============================] - 4s 492us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 129/150\n",
            "8822/8822 [==============================] - 4s 496us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 130/150\n",
            "8822/8822 [==============================] - 4s 494us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 131/150\n",
            "8822/8822 [==============================] - 4s 495us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 132/150\n",
            "8822/8822 [==============================] - 4s 495us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 133/150\n",
            "8822/8822 [==============================] - 4s 494us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 134/150\n",
            "8822/8822 [==============================] - 4s 495us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 135/150\n",
            "8822/8822 [==============================] - 4s 492us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 136/150\n",
            "8822/8822 [==============================] - 4s 495us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 137/150\n",
            "8822/8822 [==============================] - 4s 498us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 138/150\n",
            "8822/8822 [==============================] - 4s 492us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 139/150\n",
            "8822/8822 [==============================] - 4s 493us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 140/150\n",
            "8822/8822 [==============================] - 4s 496us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 141/150\n",
            "8822/8822 [==============================] - 4s 499us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 142/150\n",
            "8822/8822 [==============================] - 4s 494us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 143/150\n",
            "8822/8822 [==============================] - 4s 490us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 144/150\n",
            "8822/8822 [==============================] - 4s 493us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 145/150\n",
            "8822/8822 [==============================] - 4s 495us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 146/150\n",
            "8822/8822 [==============================] - 4s 493us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 147/150\n",
            "8822/8822 [==============================] - 4s 492us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 148/150\n",
            "8822/8822 [==============================] - 4s 497us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 149/150\n",
            "8822/8822 [==============================] - 4s 493us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Epoch 150/150\n",
            "8822/8822 [==============================] - 4s 494us/step - loss: 1.0077e-07 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9882\n",
            "Bush F1 Score on Train :  1.0\n",
            "Bush F1 Score on Test :  0.8414634146341463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U6Gs5mlgsmxs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelForBush.save('bush.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ehh0EULyEMuB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bushModel = load_model('bush.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hiOB6Oe6FxeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "06ec3ee5-feee-4c42-990e-b93d8a4188fb"
      },
      "cell_type": "code",
      "source": [
        "bushModel.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 62, 62, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 12, 12, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 2305      \n",
            "=================================================================\n",
            "Total params: 58,049\n",
            "Trainable params: 58,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dxiY6AtiFy_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "ee480dfe-a25c-4489-f8b5-ca0818042b50"
      },
      "cell_type": "code",
      "source": [
        "bushModel.layers"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.convolutional.Conv2D at 0x7fe865ff4390>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7fe862504fd0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7fe8625068d0>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7fe862504dd8>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7fe8625252e8>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7fe86253dc18>,\n",
              " <keras.layers.core.Flatten at 0x7fe8630fe358>,\n",
              " <keras.layers.core.Dense at 0x7fe8624db630>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "LkB64_mvF5HH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f535ed9-40b6-4467-b93b-caed14c8ec1a"
      },
      "cell_type": "code",
      "source": [
        "bushModel.inputs"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'conv2d_19_input_5:0' shape=(?, 64, 64, 1) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "33sAjCnkF7Fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c43ebe1d-44f4-4979-82f5-143d4993e49d"
      },
      "cell_type": "code",
      "source": [
        "bushModel.outputs"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'dense_9_5/Sigmoid:0' shape=(?, 1) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "6cHW_g8oF8yD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}