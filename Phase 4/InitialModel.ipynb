{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "cqJE-zF14bnJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from zipfile import ZipFile\n",
        "zip_test = ZipFile(\"test1.zip\")\n",
        "zip_test.extractall()\n",
        "zip_test.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jYSfPPqi-bL_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zip_train = ZipFile(\"train.zip\")\n",
        "zip_train.extractall()\n",
        "zip_train.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xoL6qi7EI4X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm \n",
        "\n",
        "'''Labelling the dataset'''\n",
        "def label_img(img): \n",
        "    word_label = img.split('.')[-3] \n",
        "    # DIY One hot encoder \n",
        "    if word_label == 'cat': return 0 \n",
        "    elif word_label == 'dog': return 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xj3IpjK4EZJp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "HEuS66FSEQpL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Ny7H6sw3KBn",
        "colab_type": "code",
        "outputId": "91d61557-c7ae-41a0-9392-ac3fa7f00f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "  \n",
        "'''Creating the training data'''\n",
        "def create_train_data(): \n",
        "    # Creating an empty list where we should the store the training data \n",
        "    # after a little preprocessing of the data \n",
        "    training_data = [] \n",
        "  \n",
        "    # tqdm is only used for interactive loading \n",
        "    # loading the training data \n",
        "    for img in tqdm(os.listdir(\"train\")): \n",
        "  \n",
        "        # labeling the images \n",
        "        label = label_img(img) \n",
        "  \n",
        "        path = os.path.join(\"train\", img) \n",
        "#         print(path)\n",
        "        # loading the image from the path and then converting them into \n",
        "        # greyscale for easier covnet prob \n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n",
        "  \n",
        "        # resizing the image for processing them in the covnet \n",
        "        img = cv2.resize(img, (64, 64)) \n",
        "  \n",
        "        # final step-forming the training data list with numpy array of the images \n",
        "        training_data.append([np.array(img), np.array(label)]) \n",
        "  \n",
        "    # shuffling of the training data to preserve the random state of our data \n",
        "    shuffle(training_data) \n",
        "  \n",
        "    # saving our trained data for further uses if required \n",
        "    np.save('train_data.npy', training_data) \n",
        "    return training_data \n",
        "  \n",
        "\n",
        "'''Running the training and the testing in the dataset for our model'''\n",
        "train_data = create_train_data() \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-423bcbceb87a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m'''Running the training and the testing in the dataset for our model'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-423bcbceb87a>\u001b[0m in \u001b[0;36mcreate_train_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# tqdm is only used for interactive loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# loading the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# labeling the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "P7F3PtDd3KPk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data = np.load('train_data.npy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06D_jCy2KWgQ",
        "colab_type": "code",
        "outputId": "0905ab99-d277-4510-aa94-3456d646cfab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train = data[:-500]\n",
        "test = data[-500:]\n",
        "train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "9kVUy03NKmBS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = np.array([i[0] for i in train]).reshape(-1,64,64,1)\n",
        "X_test= np.array([i[0] for i in test]).reshape(-1,64,64,1)\n",
        "y_train = np.array([i[1] for i in train])\n",
        "y_test = np.array([i[1] for i in test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSLkYVFoL0eV",
        "colab_type": "code",
        "outputId": "6856110d-a99a-48d8-c845-d8993372e199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24500,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "h_4a3T_xOusJ",
        "colab_type": "code",
        "outputId": "be8a1160-245a-4fdf-b805-c248b76bcdb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2516
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train, epochs=70, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_predicted_train_catDog = model.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/70\n",
            "24500/24500 [==============================] - 11s 467us/step - loss: 0.7995 - acc: 0.5260 - val_loss: 0.6861 - val_acc: 0.5300\n",
            "Epoch 2/70\n",
            "24500/24500 [==============================] - 11s 446us/step - loss: 0.6864 - acc: 0.5525 - val_loss: 0.6575 - val_acc: 0.6360\n",
            "Epoch 3/70\n",
            "24500/24500 [==============================] - 10s 426us/step - loss: 0.6236 - acc: 0.6552 - val_loss: 0.5521 - val_acc: 0.7440\n",
            "Epoch 4/70\n",
            "24500/24500 [==============================] - 10s 424us/step - loss: 0.5565 - acc: 0.7219 - val_loss: 0.5379 - val_acc: 0.7280\n",
            "Epoch 5/70\n",
            "24500/24500 [==============================] - 10s 424us/step - loss: 0.5193 - acc: 0.7466 - val_loss: 0.4592 - val_acc: 0.7700\n",
            "Epoch 6/70\n",
            "24500/24500 [==============================] - 10s 425us/step - loss: 0.4796 - acc: 0.7758 - val_loss: 0.4165 - val_acc: 0.8020\n",
            "Epoch 7/70\n",
            "24500/24500 [==============================] - 10s 422us/step - loss: 0.4562 - acc: 0.7885 - val_loss: 0.3988 - val_acc: 0.8180\n",
            "Epoch 8/70\n",
            "24500/24500 [==============================] - 10s 422us/step - loss: 0.4321 - acc: 0.8015 - val_loss: 0.3870 - val_acc: 0.8320\n",
            "Epoch 9/70\n",
            "24500/24500 [==============================] - 11s 430us/step - loss: 0.4071 - acc: 0.8162 - val_loss: 0.3540 - val_acc: 0.8520\n",
            "Epoch 10/70\n",
            "24500/24500 [==============================] - 10s 425us/step - loss: 0.3889 - acc: 0.8261 - val_loss: 0.3837 - val_acc: 0.8200\n",
            "Epoch 11/70\n",
            "24500/24500 [==============================] - 10s 428us/step - loss: 0.3652 - acc: 0.8384 - val_loss: 0.4640 - val_acc: 0.7900\n",
            "Epoch 12/70\n",
            "24500/24500 [==============================] - 10s 428us/step - loss: 0.3585 - acc: 0.8419 - val_loss: 0.3135 - val_acc: 0.8540\n",
            "Epoch 13/70\n",
            "24500/24500 [==============================] - 11s 431us/step - loss: 0.3410 - acc: 0.8513 - val_loss: 0.3969 - val_acc: 0.8200\n",
            "Epoch 14/70\n",
            "24500/24500 [==============================] - 11s 433us/step - loss: 0.3292 - acc: 0.8579 - val_loss: 0.3254 - val_acc: 0.8600\n",
            "Epoch 15/70\n",
            "24500/24500 [==============================] - 10s 424us/step - loss: 0.3140 - acc: 0.8673 - val_loss: 0.3686 - val_acc: 0.8520\n",
            "Epoch 16/70\n",
            "24500/24500 [==============================] - 10s 420us/step - loss: 0.3069 - acc: 0.8711 - val_loss: 0.3337 - val_acc: 0.8540\n",
            "Epoch 17/70\n",
            "24500/24500 [==============================] - 10s 421us/step - loss: 0.2959 - acc: 0.8722 - val_loss: 0.3839 - val_acc: 0.8400\n",
            "Epoch 18/70\n",
            "24500/24500 [==============================] - 10s 423us/step - loss: 0.2915 - acc: 0.8769 - val_loss: 0.3392 - val_acc: 0.8560\n",
            "Epoch 19/70\n",
            "24500/24500 [==============================] - 11s 434us/step - loss: 0.2753 - acc: 0.8860 - val_loss: 0.3185 - val_acc: 0.8660\n",
            "Epoch 20/70\n",
            "24500/24500 [==============================] - 11s 435us/step - loss: 0.2740 - acc: 0.8851 - val_loss: 0.3287 - val_acc: 0.8600\n",
            "Epoch 21/70\n",
            "24500/24500 [==============================] - 11s 432us/step - loss: 0.2669 - acc: 0.8877 - val_loss: 0.4003 - val_acc: 0.8460\n",
            "Epoch 22/70\n",
            "24500/24500 [==============================] - 10s 427us/step - loss: 0.2552 - acc: 0.8931 - val_loss: 0.3284 - val_acc: 0.8700\n",
            "Epoch 23/70\n",
            "24500/24500 [==============================] - 10s 428us/step - loss: 0.2495 - acc: 0.9001 - val_loss: 0.3578 - val_acc: 0.8540\n",
            "Epoch 24/70\n",
            "24500/24500 [==============================] - 10s 428us/step - loss: 0.2387 - acc: 0.9013 - val_loss: 0.3548 - val_acc: 0.8480\n",
            "Epoch 25/70\n",
            "24500/24500 [==============================] - 11s 430us/step - loss: 0.2370 - acc: 0.9028 - val_loss: 0.3874 - val_acc: 0.8620\n",
            "Epoch 26/70\n",
            "24500/24500 [==============================] - 11s 429us/step - loss: 0.2323 - acc: 0.9056 - val_loss: 0.3739 - val_acc: 0.8660\n",
            "Epoch 27/70\n",
            "24500/24500 [==============================] - 10s 428us/step - loss: 0.2317 - acc: 0.9048 - val_loss: 0.4609 - val_acc: 0.8380\n",
            "Epoch 28/70\n",
            "24500/24500 [==============================] - 10s 426us/step - loss: 0.2239 - acc: 0.9091 - val_loss: 0.3754 - val_acc: 0.8420\n",
            "Epoch 29/70\n",
            "24500/24500 [==============================] - 10s 427us/step - loss: 0.2208 - acc: 0.9099 - val_loss: 0.3707 - val_acc: 0.8480\n",
            "Epoch 30/70\n",
            "24500/24500 [==============================] - 10s 428us/step - loss: 0.2162 - acc: 0.9131 - val_loss: 0.5311 - val_acc: 0.8300\n",
            "Epoch 31/70\n",
            "24500/24500 [==============================] - 10s 427us/step - loss: 0.2099 - acc: 0.9149 - val_loss: 0.4302 - val_acc: 0.8540\n",
            "Epoch 32/70\n",
            "24500/24500 [==============================] - 11s 429us/step - loss: 0.2048 - acc: 0.9183 - val_loss: 0.4657 - val_acc: 0.8560\n",
            "Epoch 33/70\n",
            "24500/24500 [==============================] - 11s 429us/step - loss: 0.2099 - acc: 0.9173 - val_loss: 0.4111 - val_acc: 0.8660\n",
            "Epoch 34/70\n",
            "24500/24500 [==============================] - 11s 430us/step - loss: 0.2063 - acc: 0.9181 - val_loss: 0.4212 - val_acc: 0.8560\n",
            "Epoch 35/70\n",
            "24500/24500 [==============================] - 11s 429us/step - loss: 0.1981 - acc: 0.9229 - val_loss: 0.4828 - val_acc: 0.8420\n",
            "Epoch 36/70\n",
            "24500/24500 [==============================] - 11s 432us/step - loss: 0.1986 - acc: 0.9213 - val_loss: 0.6218 - val_acc: 0.8360\n",
            "Epoch 37/70\n",
            "24500/24500 [==============================] - 10s 429us/step - loss: 0.1929 - acc: 0.9255 - val_loss: 0.4837 - val_acc: 0.8400\n",
            "Epoch 38/70\n",
            "24500/24500 [==============================] - 10s 428us/step - loss: 0.1925 - acc: 0.9237 - val_loss: 0.4396 - val_acc: 0.8620\n",
            "Epoch 39/70\n",
            "24500/24500 [==============================] - 11s 429us/step - loss: 0.1870 - acc: 0.9278 - val_loss: 0.5327 - val_acc: 0.8520\n",
            "Epoch 40/70\n",
            "24500/24500 [==============================] - 11s 430us/step - loss: 0.1938 - acc: 0.9251 - val_loss: 0.4395 - val_acc: 0.8740\n",
            "Epoch 41/70\n",
            "24500/24500 [==============================] - 11s 429us/step - loss: 0.1821 - acc: 0.9287 - val_loss: 0.4336 - val_acc: 0.8740\n",
            "Epoch 42/70\n",
            "24500/24500 [==============================] - 10s 428us/step - loss: 0.1841 - acc: 0.9300 - val_loss: 0.5165 - val_acc: 0.8560\n",
            "Epoch 43/70\n",
            "24500/24500 [==============================] - 11s 431us/step - loss: 0.1813 - acc: 0.9300 - val_loss: 0.5312 - val_acc: 0.8560\n",
            "Epoch 44/70\n",
            "24500/24500 [==============================] - 11s 432us/step - loss: 0.1794 - acc: 0.9342 - val_loss: 0.5202 - val_acc: 0.8640\n",
            "Epoch 45/70\n",
            "24500/24500 [==============================] - 11s 433us/step - loss: 0.1791 - acc: 0.9345 - val_loss: 0.5442 - val_acc: 0.8300\n",
            "Epoch 46/70\n",
            "24500/24500 [==============================] - 10s 428us/step - loss: 0.1767 - acc: 0.9339 - val_loss: 0.6129 - val_acc: 0.8360\n",
            "Epoch 47/70\n",
            "24500/24500 [==============================] - 11s 433us/step - loss: 0.1802 - acc: 0.9323 - val_loss: 0.5707 - val_acc: 0.8440\n",
            "Epoch 48/70\n",
            "24500/24500 [==============================] - 11s 433us/step - loss: 0.1771 - acc: 0.9341 - val_loss: 0.4861 - val_acc: 0.8640\n",
            "Epoch 49/70\n",
            "24500/24500 [==============================] - 11s 433us/step - loss: 0.1780 - acc: 0.9334 - val_loss: 0.5106 - val_acc: 0.8580\n",
            "Epoch 50/70\n",
            "24500/24500 [==============================] - 11s 431us/step - loss: 0.1797 - acc: 0.9341 - val_loss: 0.5883 - val_acc: 0.8560\n",
            "Epoch 51/70\n",
            "24500/24500 [==============================] - 11s 429us/step - loss: 0.1699 - acc: 0.9376 - val_loss: 0.5901 - val_acc: 0.8620\n",
            "Epoch 52/70\n",
            "24500/24500 [==============================] - 11s 432us/step - loss: 0.1690 - acc: 0.9386 - val_loss: 0.6649 - val_acc: 0.8560\n",
            "Epoch 53/70\n",
            "24500/24500 [==============================] - 11s 431us/step - loss: 0.1738 - acc: 0.9369 - val_loss: 0.6684 - val_acc: 0.8280\n",
            "Epoch 54/70\n",
            "24500/24500 [==============================] - 11s 430us/step - loss: 0.1758 - acc: 0.9363 - val_loss: 0.6067 - val_acc: 0.8400\n",
            "Epoch 55/70\n",
            "24500/24500 [==============================] - 11s 431us/step - loss: 0.1684 - acc: 0.9387 - val_loss: 0.5948 - val_acc: 0.8260\n",
            "Epoch 56/70\n",
            "24500/24500 [==============================] - 11s 430us/step - loss: 0.1717 - acc: 0.9392 - val_loss: 0.6052 - val_acc: 0.8560\n",
            "Epoch 57/70\n",
            "24500/24500 [==============================] - 10s 428us/step - loss: 0.1623 - acc: 0.9413 - val_loss: 0.6033 - val_acc: 0.8340\n",
            "Epoch 58/70\n",
            "24500/24500 [==============================] - 11s 430us/step - loss: 0.1696 - acc: 0.9383 - val_loss: 0.6957 - val_acc: 0.8460\n",
            "Epoch 59/70\n",
            "24500/24500 [==============================] - 11s 429us/step - loss: 0.1672 - acc: 0.9393 - val_loss: 0.6031 - val_acc: 0.8600\n",
            "Epoch 60/70\n",
            "24500/24500 [==============================] - 11s 430us/step - loss: 0.1668 - acc: 0.9399 - val_loss: 0.6266 - val_acc: 0.8520\n",
            "Epoch 61/70\n",
            "24500/24500 [==============================] - 11s 429us/step - loss: 0.1700 - acc: 0.9393 - val_loss: 0.5720 - val_acc: 0.8600\n",
            "Epoch 62/70\n",
            "24500/24500 [==============================] - 11s 429us/step - loss: 0.1669 - acc: 0.9393 - val_loss: 0.5913 - val_acc: 0.8540\n",
            "Epoch 63/70\n",
            "24500/24500 [==============================] - 11s 433us/step - loss: 0.1619 - acc: 0.9434 - val_loss: 0.6192 - val_acc: 0.8380\n",
            "Epoch 64/70\n",
            "24500/24500 [==============================] - 10s 427us/step - loss: 0.1632 - acc: 0.9427 - val_loss: 0.5100 - val_acc: 0.8780\n",
            "Epoch 65/70\n",
            "24500/24500 [==============================] - 11s 430us/step - loss: 0.1652 - acc: 0.9421 - val_loss: 0.7124 - val_acc: 0.8380\n",
            "Epoch 66/70\n",
            "24500/24500 [==============================] - 10s 419us/step - loss: 0.1659 - acc: 0.9424 - val_loss: 0.5654 - val_acc: 0.8600\n",
            "Epoch 67/70\n",
            "24500/24500 [==============================] - 10s 419us/step - loss: 0.1579 - acc: 0.9460 - val_loss: 0.6643 - val_acc: 0.8580\n",
            "Epoch 68/70\n",
            "24500/24500 [==============================] - 10s 418us/step - loss: 0.1591 - acc: 0.9440 - val_loss: 0.5446 - val_acc: 0.8480\n",
            "Epoch 69/70\n",
            "24500/24500 [==============================] - 10s 428us/step - loss: 0.1623 - acc: 0.9427 - val_loss: 0.6821 - val_acc: 0.8380\n",
            "Epoch 70/70\n",
            "24500/24500 [==============================] - 10s 426us/step - loss: 0.1582 - acc: 0.9461 - val_loss: 0.9230 - val_acc: 0.8160\n",
            " F1 Score on Train :  0.9253407413838007\n",
            " F1 Score on Test :  0.7850467289719627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X0MKTGzfoAmY",
        "colab_type": "code",
        "outputId": "44e0cbed-3c96-4371-aa33-da3cff98f7ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.save('initialized-model.keras')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_71 (Conv2D)           (None, 62, 62, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_65 (MaxPooling (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_72 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_66 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_73 (Conv2D)           (None, 12, 12, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_67 (MaxPooling (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 4, 4, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_68 (MaxPooling (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 37,569\n",
            "Trainable params: 37,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Rn4tHBLowo1",
        "colab_type": "code",
        "outputId": "c805c715-6c35-4f28-a301-302305b70ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1823
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train, epochs=50, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_predicted_train_catDog = model.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.7521 - acc: 0.5596 - val_loss: 0.6889 - val_acc: 0.5140\n",
            "Epoch 2/50\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.6562 - acc: 0.6087 - val_loss: 0.6297 - val_acc: 0.6920\n",
            "Epoch 3/50\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.6077 - acc: 0.6715 - val_loss: 0.5379 - val_acc: 0.7500\n",
            "Epoch 4/50\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.5494 - acc: 0.7239 - val_loss: 0.5067 - val_acc: 0.7680\n",
            "Epoch 5/50\n",
            "24500/24500 [==============================] - 11s 447us/step - loss: 0.5052 - acc: 0.7550 - val_loss: 0.4759 - val_acc: 0.7640\n",
            "Epoch 6/50\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.4673 - acc: 0.7814 - val_loss: 0.4745 - val_acc: 0.7860\n",
            "Epoch 7/50\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.4262 - acc: 0.8039 - val_loss: 0.4420 - val_acc: 0.8040\n",
            "Epoch 8/50\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.4001 - acc: 0.8188 - val_loss: 0.3991 - val_acc: 0.8160\n",
            "Epoch 9/50\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.3720 - acc: 0.8317 - val_loss: 0.4199 - val_acc: 0.8040\n",
            "Epoch 10/50\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.3483 - acc: 0.8445 - val_loss: 0.3996 - val_acc: 0.8220\n",
            "Epoch 11/50\n",
            "24500/24500 [==============================] - 11s 445us/step - loss: 0.3232 - acc: 0.8597 - val_loss: 0.3834 - val_acc: 0.8340\n",
            "Epoch 12/50\n",
            "24500/24500 [==============================] - 11s 447us/step - loss: 0.3043 - acc: 0.8686 - val_loss: 0.3518 - val_acc: 0.8240\n",
            "Epoch 13/50\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.2898 - acc: 0.8752 - val_loss: 0.3718 - val_acc: 0.8360\n",
            "Epoch 14/50\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.2731 - acc: 0.8833 - val_loss: 0.3835 - val_acc: 0.8260\n",
            "Epoch 15/50\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.2503 - acc: 0.8956 - val_loss: 0.4057 - val_acc: 0.8300\n",
            "Epoch 16/50\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.2386 - acc: 0.9000 - val_loss: 0.3791 - val_acc: 0.8500\n",
            "Epoch 17/50\n",
            "24500/24500 [==============================] - 11s 447us/step - loss: 0.2316 - acc: 0.9031 - val_loss: 0.4465 - val_acc: 0.8120\n",
            "Epoch 18/50\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.2198 - acc: 0.9076 - val_loss: 0.3918 - val_acc: 0.8480\n",
            "Epoch 19/50\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.2130 - acc: 0.9110 - val_loss: 0.4140 - val_acc: 0.8260\n",
            "Epoch 20/50\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.2028 - acc: 0.9146 - val_loss: 0.3756 - val_acc: 0.8420\n",
            "Epoch 21/50\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.1910 - acc: 0.9221 - val_loss: 0.4466 - val_acc: 0.8220\n",
            "Epoch 22/50\n",
            "24500/24500 [==============================] - 11s 444us/step - loss: 0.1890 - acc: 0.9218 - val_loss: 0.3826 - val_acc: 0.8740\n",
            "Epoch 23/50\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.1843 - acc: 0.9234 - val_loss: 0.4443 - val_acc: 0.8480\n",
            "Epoch 24/50\n",
            "24500/24500 [==============================] - 11s 447us/step - loss: 0.1783 - acc: 0.9259 - val_loss: 0.3843 - val_acc: 0.8420\n",
            "Epoch 25/50\n",
            "24500/24500 [==============================] - 11s 446us/step - loss: 0.1656 - acc: 0.9314 - val_loss: 0.5619 - val_acc: 0.8220\n",
            "Epoch 26/50\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.1670 - acc: 0.9302 - val_loss: 0.4417 - val_acc: 0.8400\n",
            "Epoch 27/50\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.1689 - acc: 0.9308 - val_loss: 0.4873 - val_acc: 0.8180\n",
            "Epoch 28/50\n",
            "24500/24500 [==============================] - 11s 445us/step - loss: 0.1549 - acc: 0.9363 - val_loss: 0.4818 - val_acc: 0.8320\n",
            "Epoch 29/50\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.1505 - acc: 0.9398 - val_loss: 0.4618 - val_acc: 0.8500\n",
            "Epoch 30/50\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.1511 - acc: 0.9384 - val_loss: 0.5277 - val_acc: 0.8180\n",
            "Epoch 31/50\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.1414 - acc: 0.9437 - val_loss: 0.4798 - val_acc: 0.8420\n",
            "Epoch 32/50\n",
            "24500/24500 [==============================] - 11s 444us/step - loss: 0.1435 - acc: 0.9434 - val_loss: 0.5328 - val_acc: 0.8100\n",
            "Epoch 33/50\n",
            "24500/24500 [==============================] - 11s 444us/step - loss: 0.1408 - acc: 0.9447 - val_loss: 0.5287 - val_acc: 0.8280\n",
            "Epoch 34/50\n",
            "24500/24500 [==============================] - 11s 444us/step - loss: 0.1359 - acc: 0.9462 - val_loss: 0.5104 - val_acc: 0.8340\n",
            "Epoch 35/50\n",
            "24500/24500 [==============================] - 11s 447us/step - loss: 0.1254 - acc: 0.9499 - val_loss: 0.5475 - val_acc: 0.8420\n",
            "Epoch 36/50\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.1354 - acc: 0.9458 - val_loss: 0.5816 - val_acc: 0.8500\n",
            "Epoch 37/50\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.1302 - acc: 0.9486 - val_loss: 0.5777 - val_acc: 0.8540\n",
            "Epoch 38/50\n",
            "24500/24500 [==============================] - 11s 446us/step - loss: 0.1268 - acc: 0.9502 - val_loss: 0.7088 - val_acc: 0.8140\n",
            "Epoch 39/50\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.1270 - acc: 0.9510 - val_loss: 0.6410 - val_acc: 0.8420\n",
            "Epoch 40/50\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.1198 - acc: 0.9522 - val_loss: 0.6816 - val_acc: 0.8400\n",
            "Epoch 41/50\n",
            "24500/24500 [==============================] - 11s 444us/step - loss: 0.1292 - acc: 0.9497 - val_loss: 0.6975 - val_acc: 0.8180\n",
            "Epoch 42/50\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.1272 - acc: 0.9517 - val_loss: 0.6171 - val_acc: 0.8440\n",
            "Epoch 43/50\n",
            "24500/24500 [==============================] - 11s 446us/step - loss: 0.1194 - acc: 0.9527 - val_loss: 0.7104 - val_acc: 0.8280\n",
            "Epoch 44/50\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.1093 - acc: 0.9587 - val_loss: 0.7673 - val_acc: 0.8380\n",
            "Epoch 45/50\n",
            "24500/24500 [==============================] - 11s 447us/step - loss: 0.1189 - acc: 0.9538 - val_loss: 0.6585 - val_acc: 0.8320\n",
            "Epoch 46/50\n",
            "24500/24500 [==============================] - 11s 447us/step - loss: 0.1193 - acc: 0.9540 - val_loss: 0.7834 - val_acc: 0.8240\n",
            "Epoch 47/50\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.1150 - acc: 0.9560 - val_loss: 0.8231 - val_acc: 0.8400\n",
            "Epoch 48/50\n",
            "24500/24500 [==============================] - 11s 447us/step - loss: 0.1148 - acc: 0.9560 - val_loss: 0.6546 - val_acc: 0.8420\n",
            "Epoch 49/50\n",
            "24500/24500 [==============================] - 11s 441us/step - loss: 0.1090 - acc: 0.9595 - val_loss: 0.6956 - val_acc: 0.8260\n",
            "Epoch 50/50\n",
            "24500/24500 [==============================] - 11s 437us/step - loss: 0.1191 - acc: 0.9547 - val_loss: 0.7562 - val_acc: 0.8440\n",
            " F1 Score on Train :  0.9535264277532319\n",
            " F1 Score on Test :  0.8333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1ZNP7658owwe",
        "colab_type": "code",
        "outputId": "2433c9fa-e293-43ce-adfe-1100444173b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2863
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model2.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model2.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3)))\n",
        "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(layers.Dropout(0.8))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model2.fit(X_train,y_train, epochs=80, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_predicted_train_catDog = model2.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model2.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/80\n",
            "24500/24500 [==============================] - 13s 514us/step - loss: 1.0954 - acc: 0.5170 - val_loss: 0.6912 - val_acc: 0.5100\n",
            "Epoch 2/80\n",
            "24500/24500 [==============================] - 11s 461us/step - loss: 0.6908 - acc: 0.5149 - val_loss: 0.6933 - val_acc: 0.5000\n",
            "Epoch 3/80\n",
            "24500/24500 [==============================] - 11s 469us/step - loss: 0.6905 - acc: 0.5142 - val_loss: 0.6907 - val_acc: 0.5040\n",
            "Epoch 4/80\n",
            "24500/24500 [==============================] - 11s 459us/step - loss: 0.6878 - acc: 0.5227 - val_loss: 0.6906 - val_acc: 0.4900\n",
            "Epoch 5/80\n",
            "24500/24500 [==============================] - 11s 458us/step - loss: 0.6896 - acc: 0.5161 - val_loss: 0.6882 - val_acc: 0.4980\n",
            "Epoch 6/80\n",
            "24500/24500 [==============================] - 11s 458us/step - loss: 0.6877 - acc: 0.5230 - val_loss: 0.6953 - val_acc: 0.4800\n",
            "Epoch 7/80\n",
            "24500/24500 [==============================] - 11s 460us/step - loss: 0.6870 - acc: 0.5287 - val_loss: 0.6896 - val_acc: 0.5160\n",
            "Epoch 8/80\n",
            "24500/24500 [==============================] - 11s 459us/step - loss: 0.6902 - acc: 0.5188 - val_loss: 0.6907 - val_acc: 0.4900\n",
            "Epoch 9/80\n",
            "24500/24500 [==============================] - 11s 458us/step - loss: 0.6904 - acc: 0.5160 - val_loss: 0.6885 - val_acc: 0.4880\n",
            "Epoch 10/80\n",
            "24500/24500 [==============================] - 11s 460us/step - loss: 0.6885 - acc: 0.5202 - val_loss: 0.6878 - val_acc: 0.5000\n",
            "Epoch 11/80\n",
            "24500/24500 [==============================] - 11s 459us/step - loss: 0.6883 - acc: 0.5256 - val_loss: 0.6805 - val_acc: 0.5580\n",
            "Epoch 12/80\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.6852 - acc: 0.5426 - val_loss: 0.6796 - val_acc: 0.5220\n",
            "Epoch 13/80\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.6833 - acc: 0.5474 - val_loss: 0.6769 - val_acc: 0.5540\n",
            "Epoch 14/80\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.6813 - acc: 0.5548 - val_loss: 0.6638 - val_acc: 0.6260\n",
            "Epoch 15/80\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.6735 - acc: 0.5793 - val_loss: 0.6679 - val_acc: 0.5820\n",
            "Epoch 16/80\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.6453 - acc: 0.6296 - val_loss: 0.6015 - val_acc: 0.6840\n",
            "Epoch 17/80\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.6229 - acc: 0.6618 - val_loss: 0.6228 - val_acc: 0.6760\n",
            "Epoch 18/80\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.5966 - acc: 0.6833 - val_loss: 0.5288 - val_acc: 0.7440\n",
            "Epoch 19/80\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.5647 - acc: 0.7109 - val_loss: 0.5044 - val_acc: 0.7580\n",
            "Epoch 20/80\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.5341 - acc: 0.7380 - val_loss: 0.4903 - val_acc: 0.7680\n",
            "Epoch 21/80\n",
            "24500/24500 [==============================] - 11s 459us/step - loss: 0.5111 - acc: 0.7527 - val_loss: 0.4509 - val_acc: 0.8080\n",
            "Epoch 22/80\n",
            "24500/24500 [==============================] - 11s 460us/step - loss: 0.4934 - acc: 0.7679 - val_loss: 0.4565 - val_acc: 0.7940\n",
            "Epoch 23/80\n",
            "24500/24500 [==============================] - 11s 457us/step - loss: 0.4719 - acc: 0.7794 - val_loss: 0.4510 - val_acc: 0.7960\n",
            "Epoch 24/80\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.4626 - acc: 0.7800 - val_loss: 0.4422 - val_acc: 0.8020\n",
            "Epoch 25/80\n",
            "24500/24500 [==============================] - 11s 458us/step - loss: 0.4468 - acc: 0.7931 - val_loss: 0.4095 - val_acc: 0.8360\n",
            "Epoch 26/80\n",
            "24500/24500 [==============================] - 11s 463us/step - loss: 0.4255 - acc: 0.8056 - val_loss: 0.4153 - val_acc: 0.8120\n",
            "Epoch 27/80\n",
            "24500/24500 [==============================] - 11s 464us/step - loss: 0.4117 - acc: 0.8148 - val_loss: 0.4181 - val_acc: 0.8160\n",
            "Epoch 28/80\n",
            "24500/24500 [==============================] - 11s 464us/step - loss: 0.4061 - acc: 0.8181 - val_loss: 0.4118 - val_acc: 0.8200\n",
            "Epoch 29/80\n",
            "24500/24500 [==============================] - 11s 462us/step - loss: 0.3887 - acc: 0.8258 - val_loss: 0.4019 - val_acc: 0.8260\n",
            "Epoch 30/80\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.3784 - acc: 0.8293 - val_loss: 0.4100 - val_acc: 0.8100\n",
            "Epoch 31/80\n",
            "24500/24500 [==============================] - 11s 465us/step - loss: 0.3686 - acc: 0.8380 - val_loss: 0.3764 - val_acc: 0.8300\n",
            "Epoch 32/80\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.3611 - acc: 0.8400 - val_loss: 0.4187 - val_acc: 0.8120\n",
            "Epoch 33/80\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.3458 - acc: 0.8472 - val_loss: 0.4152 - val_acc: 0.8060\n",
            "Epoch 34/80\n",
            "24500/24500 [==============================] - 11s 456us/step - loss: 0.3417 - acc: 0.8492 - val_loss: 0.4551 - val_acc: 0.8140\n",
            "Epoch 35/80\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.3266 - acc: 0.8550 - val_loss: 0.4042 - val_acc: 0.8340\n",
            "Epoch 36/80\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.3272 - acc: 0.8593 - val_loss: 0.4001 - val_acc: 0.8180\n",
            "Epoch 37/80\n",
            "24500/24500 [==============================] - 11s 457us/step - loss: 0.3179 - acc: 0.8641 - val_loss: 0.4463 - val_acc: 0.8020\n",
            "Epoch 38/80\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.3065 - acc: 0.8689 - val_loss: 0.4081 - val_acc: 0.8220\n",
            "Epoch 39/80\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.3007 - acc: 0.8682 - val_loss: 0.3906 - val_acc: 0.8280\n",
            "Epoch 40/80\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.3017 - acc: 0.8690 - val_loss: 0.4615 - val_acc: 0.8140\n",
            "Epoch 41/80\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.2920 - acc: 0.8742 - val_loss: 0.4115 - val_acc: 0.8300\n",
            "Epoch 42/80\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.2809 - acc: 0.8797 - val_loss: 0.4260 - val_acc: 0.8200\n",
            "Epoch 43/80\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.2712 - acc: 0.8856 - val_loss: 0.4920 - val_acc: 0.8120\n",
            "Epoch 44/80\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.2640 - acc: 0.8887 - val_loss: 0.5164 - val_acc: 0.7960\n",
            "Epoch 45/80\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.2698 - acc: 0.8852 - val_loss: 0.4940 - val_acc: 0.8060\n",
            "Epoch 46/80\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.2606 - acc: 0.8906 - val_loss: 0.4695 - val_acc: 0.8120\n",
            "Epoch 47/80\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.2563 - acc: 0.8902 - val_loss: 0.4438 - val_acc: 0.8160\n",
            "Epoch 48/80\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.2568 - acc: 0.8920 - val_loss: 0.4404 - val_acc: 0.8120\n",
            "Epoch 49/80\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.2497 - acc: 0.8940 - val_loss: 0.4494 - val_acc: 0.8200\n",
            "Epoch 50/80\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.2472 - acc: 0.8957 - val_loss: 0.4432 - val_acc: 0.8100\n",
            "Epoch 51/80\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.2359 - acc: 0.9034 - val_loss: 0.4955 - val_acc: 0.8020\n",
            "Epoch 52/80\n",
            "24500/24500 [==============================] - 11s 446us/step - loss: 0.2344 - acc: 0.9011 - val_loss: 0.4631 - val_acc: 0.8180\n",
            "Epoch 53/80\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.2267 - acc: 0.9064 - val_loss: 0.5422 - val_acc: 0.8160\n",
            "Epoch 54/80\n",
            "24500/24500 [==============================] - 11s 448us/step - loss: 0.2294 - acc: 0.9048 - val_loss: 0.4682 - val_acc: 0.8120\n",
            "Epoch 55/80\n",
            "24500/24500 [==============================] - 11s 446us/step - loss: 0.2177 - acc: 0.9080 - val_loss: 0.4543 - val_acc: 0.8140\n",
            "Epoch 56/80\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.2148 - acc: 0.9105 - val_loss: 0.5400 - val_acc: 0.8000\n",
            "Epoch 57/80\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.2185 - acc: 0.9092 - val_loss: 0.5085 - val_acc: 0.8200\n",
            "Epoch 58/80\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.2098 - acc: 0.9144 - val_loss: 0.4329 - val_acc: 0.8400\n",
            "Epoch 59/80\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.2116 - acc: 0.9120 - val_loss: 0.5492 - val_acc: 0.8240\n",
            "Epoch 60/80\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.2012 - acc: 0.9172 - val_loss: 0.5552 - val_acc: 0.8080\n",
            "Epoch 61/80\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.1989 - acc: 0.9173 - val_loss: 0.5069 - val_acc: 0.8340\n",
            "Epoch 62/80\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.1996 - acc: 0.9187 - val_loss: 0.5925 - val_acc: 0.8200\n",
            "Epoch 63/80\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.1931 - acc: 0.9213 - val_loss: 0.5181 - val_acc: 0.8180\n",
            "Epoch 64/80\n",
            "24500/24500 [==============================] - 11s 456us/step - loss: 0.1973 - acc: 0.9183 - val_loss: 0.5676 - val_acc: 0.8140\n",
            "Epoch 65/80\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.1998 - acc: 0.9182 - val_loss: 0.5911 - val_acc: 0.8020\n",
            "Epoch 66/80\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.1940 - acc: 0.9210 - val_loss: 0.5749 - val_acc: 0.8140\n",
            "Epoch 67/80\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.1922 - acc: 0.9231 - val_loss: 0.6067 - val_acc: 0.8100\n",
            "Epoch 68/80\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.1925 - acc: 0.9204 - val_loss: 0.6512 - val_acc: 0.8100\n",
            "Epoch 69/80\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.1928 - acc: 0.9219 - val_loss: 0.6272 - val_acc: 0.8040\n",
            "Epoch 70/80\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.1809 - acc: 0.9268 - val_loss: 0.5913 - val_acc: 0.8200\n",
            "Epoch 71/80\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.1802 - acc: 0.9275 - val_loss: 0.6376 - val_acc: 0.8060\n",
            "Epoch 72/80\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.1837 - acc: 0.9257 - val_loss: 0.6002 - val_acc: 0.8180\n",
            "Epoch 73/80\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.1763 - acc: 0.9304 - val_loss: 0.6687 - val_acc: 0.8280\n",
            "Epoch 74/80\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.1819 - acc: 0.9279 - val_loss: 0.6222 - val_acc: 0.8280\n",
            "Epoch 75/80\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.1759 - acc: 0.9283 - val_loss: 0.5846 - val_acc: 0.8280\n",
            "Epoch 76/80\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.1753 - acc: 0.9295 - val_loss: 0.6379 - val_acc: 0.8340\n",
            "Epoch 77/80\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.1787 - acc: 0.9276 - val_loss: 0.6780 - val_acc: 0.8080\n",
            "Epoch 78/80\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.1694 - acc: 0.9307 - val_loss: 0.7091 - val_acc: 0.8200\n",
            "Epoch 79/80\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.1673 - acc: 0.9319 - val_loss: 0.6635 - val_acc: 0.8020\n",
            "Epoch 80/80\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.1653 - acc: 0.9349 - val_loss: 0.6185 - val_acc: 0.8140\n",
            " F1 Score on Train :  0.9623181091765497\n",
            " F1 Score on Test :  0.7910112359550561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9o4wA1_xowzX",
        "colab_type": "code",
        "outputId": "3dcd4b49-5a5d-4c0d-9768-2925822dcf67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4596
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model3.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model3.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model3.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model3.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model3.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model3.add(Conv2D(64, (3, 3)))\n",
        "model3.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model3.add(Flatten())\n",
        "model3.add(layers.Dropout(0.2))\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model3.fit(X_train,y_train, epochs=130, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_predicted_train_catDog = model3.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model3.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/130\n",
            "24500/24500 [==============================] - 13s 520us/step - loss: 0.7577 - acc: 0.5240 - val_loss: 0.6849 - val_acc: 0.5380\n",
            "Epoch 2/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.6839 - acc: 0.5460 - val_loss: 0.6918 - val_acc: 0.5620\n",
            "Epoch 3/130\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.6845 - acc: 0.5392 - val_loss: 0.6974 - val_acc: 0.5300\n",
            "Epoch 4/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.6846 - acc: 0.5450 - val_loss: 0.6933 - val_acc: 0.4900\n",
            "Epoch 5/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.6821 - acc: 0.5517 - val_loss: 0.6721 - val_acc: 0.5720\n",
            "Epoch 6/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.6751 - acc: 0.5728 - val_loss: 0.6490 - val_acc: 0.6380\n",
            "Epoch 7/130\n",
            "24500/24500 [==============================] - 11s 456us/step - loss: 0.6279 - acc: 0.6488 - val_loss: 0.6049 - val_acc: 0.6700\n",
            "Epoch 8/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.5802 - acc: 0.6996 - val_loss: 0.5642 - val_acc: 0.7060\n",
            "Epoch 9/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.5424 - acc: 0.7308 - val_loss: 0.5267 - val_acc: 0.7660\n",
            "Epoch 10/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.5074 - acc: 0.7560 - val_loss: 0.5138 - val_acc: 0.7340\n",
            "Epoch 11/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.4740 - acc: 0.7767 - val_loss: 0.4357 - val_acc: 0.8120\n",
            "Epoch 12/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.4442 - acc: 0.7937 - val_loss: 0.3840 - val_acc: 0.8320\n",
            "Epoch 13/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.4153 - acc: 0.8058 - val_loss: 0.3961 - val_acc: 0.8300\n",
            "Epoch 14/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.3884 - acc: 0.8258 - val_loss: 0.4005 - val_acc: 0.8200\n",
            "Epoch 15/130\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.3671 - acc: 0.8349 - val_loss: 0.4262 - val_acc: 0.8240\n",
            "Epoch 16/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.3478 - acc: 0.8447 - val_loss: 0.4087 - val_acc: 0.8380\n",
            "Epoch 17/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.3265 - acc: 0.8560 - val_loss: 0.4027 - val_acc: 0.8300\n",
            "Epoch 18/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.3158 - acc: 0.8630 - val_loss: 0.4102 - val_acc: 0.8260\n",
            "Epoch 19/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.2943 - acc: 0.8724 - val_loss: 0.3558 - val_acc: 0.8400\n",
            "Epoch 20/130\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.2825 - acc: 0.8764 - val_loss: 0.4229 - val_acc: 0.8460\n",
            "Epoch 21/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.2678 - acc: 0.8849 - val_loss: 0.4313 - val_acc: 0.8360\n",
            "Epoch 22/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.2492 - acc: 0.8924 - val_loss: 0.4474 - val_acc: 0.8400\n",
            "Epoch 23/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.2390 - acc: 0.8999 - val_loss: 0.4212 - val_acc: 0.8500\n",
            "Epoch 24/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.2255 - acc: 0.9057 - val_loss: 0.4434 - val_acc: 0.8380\n",
            "Epoch 25/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.2260 - acc: 0.9038 - val_loss: 0.4765 - val_acc: 0.8300\n",
            "Epoch 26/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.2093 - acc: 0.9134 - val_loss: 0.5388 - val_acc: 0.8180\n",
            "Epoch 27/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.1938 - acc: 0.9198 - val_loss: 0.4365 - val_acc: 0.8560\n",
            "Epoch 28/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.2013 - acc: 0.9148 - val_loss: 0.4499 - val_acc: 0.8340\n",
            "Epoch 29/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.1812 - acc: 0.9247 - val_loss: 0.6143 - val_acc: 0.8060\n",
            "Epoch 30/130\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.1774 - acc: 0.9280 - val_loss: 0.4931 - val_acc: 0.8460\n",
            "Epoch 31/130\n",
            "24500/24500 [==============================] - 11s 449us/step - loss: 0.1764 - acc: 0.9281 - val_loss: 0.5457 - val_acc: 0.8340\n",
            "Epoch 32/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.1706 - acc: 0.9300 - val_loss: 0.5214 - val_acc: 0.8340\n",
            "Epoch 33/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.1631 - acc: 0.9336 - val_loss: 0.4975 - val_acc: 0.8400\n",
            "Epoch 34/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.1563 - acc: 0.9353 - val_loss: 0.5600 - val_acc: 0.8540\n",
            "Epoch 35/130\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.1546 - acc: 0.9357 - val_loss: 0.5604 - val_acc: 0.8280\n",
            "Epoch 36/130\n",
            "24500/24500 [==============================] - 11s 456us/step - loss: 0.1552 - acc: 0.9370 - val_loss: 0.5894 - val_acc: 0.8240\n",
            "Epoch 37/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.1433 - acc: 0.9436 - val_loss: 0.6094 - val_acc: 0.8300\n",
            "Epoch 38/130\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.1383 - acc: 0.9435 - val_loss: 0.5778 - val_acc: 0.8300\n",
            "Epoch 39/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.1446 - acc: 0.9419 - val_loss: 0.5955 - val_acc: 0.8380\n",
            "Epoch 40/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.1365 - acc: 0.9453 - val_loss: 0.6292 - val_acc: 0.8160\n",
            "Epoch 41/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.1399 - acc: 0.9437 - val_loss: 0.8367 - val_acc: 0.8080\n",
            "Epoch 42/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.1302 - acc: 0.9480 - val_loss: 0.6129 - val_acc: 0.8440\n",
            "Epoch 43/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.1230 - acc: 0.9497 - val_loss: 0.6824 - val_acc: 0.8460\n",
            "Epoch 44/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.1273 - acc: 0.9494 - val_loss: 0.6149 - val_acc: 0.8180\n",
            "Epoch 45/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.1297 - acc: 0.9501 - val_loss: 0.6372 - val_acc: 0.8340\n",
            "Epoch 46/130\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.1171 - acc: 0.9544 - val_loss: 0.7638 - val_acc: 0.8300\n",
            "Epoch 47/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.1219 - acc: 0.9529 - val_loss: 0.7258 - val_acc: 0.8280\n",
            "Epoch 48/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.1139 - acc: 0.9550 - val_loss: 0.7251 - val_acc: 0.8260\n",
            "Epoch 49/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.1134 - acc: 0.9569 - val_loss: 0.7306 - val_acc: 0.8380\n",
            "Epoch 50/130\n",
            "24500/24500 [==============================] - 11s 458us/step - loss: 0.1164 - acc: 0.9555 - val_loss: 0.7852 - val_acc: 0.8320\n",
            "Epoch 51/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.1186 - acc: 0.9542 - val_loss: 0.6797 - val_acc: 0.8260\n",
            "Epoch 52/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.1154 - acc: 0.9544 - val_loss: 0.8256 - val_acc: 0.8100\n",
            "Epoch 53/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.1102 - acc: 0.9587 - val_loss: 0.6981 - val_acc: 0.8280\n",
            "Epoch 54/130\n",
            "24500/24500 [==============================] - 11s 462us/step - loss: 0.1135 - acc: 0.9569 - val_loss: 0.6773 - val_acc: 0.8400\n",
            "Epoch 55/130\n",
            "24500/24500 [==============================] - 11s 459us/step - loss: 0.1197 - acc: 0.9534 - val_loss: 0.7995 - val_acc: 0.8340\n",
            "Epoch 56/130\n",
            "24500/24500 [==============================] - 11s 457us/step - loss: 0.1014 - acc: 0.9606 - val_loss: 0.7403 - val_acc: 0.8480\n",
            "Epoch 57/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.1183 - acc: 0.9553 - val_loss: 0.7159 - val_acc: 0.8280\n",
            "Epoch 58/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.1091 - acc: 0.9594 - val_loss: 0.8221 - val_acc: 0.8300\n",
            "Epoch 59/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.0995 - acc: 0.9624 - val_loss: 0.8662 - val_acc: 0.8260\n",
            "Epoch 60/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.1100 - acc: 0.9580 - val_loss: 0.7237 - val_acc: 0.8220\n",
            "Epoch 61/130\n",
            "24500/24500 [==============================] - 11s 459us/step - loss: 0.1048 - acc: 0.9602 - val_loss: 0.9065 - val_acc: 0.7820\n",
            "Epoch 62/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.1077 - acc: 0.9587 - val_loss: 0.8742 - val_acc: 0.8060\n",
            "Epoch 63/130\n",
            "24500/24500 [==============================] - 11s 456us/step - loss: 0.1080 - acc: 0.9616 - val_loss: 0.7673 - val_acc: 0.8520\n",
            "Epoch 64/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.1048 - acc: 0.9618 - val_loss: 0.8216 - val_acc: 0.8460\n",
            "Epoch 65/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.1008 - acc: 0.9609 - val_loss: 0.9110 - val_acc: 0.8400\n",
            "Epoch 66/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.1028 - acc: 0.9612 - val_loss: 0.8441 - val_acc: 0.8440\n",
            "Epoch 67/130\n",
            "24500/24500 [==============================] - 11s 456us/step - loss: 0.0984 - acc: 0.9628 - val_loss: 0.7372 - val_acc: 0.8520\n",
            "Epoch 68/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.0990 - acc: 0.9636 - val_loss: 0.8964 - val_acc: 0.8260\n",
            "Epoch 69/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.1029 - acc: 0.9616 - val_loss: 0.7657 - val_acc: 0.8180\n",
            "Epoch 70/130\n",
            "24500/24500 [==============================] - 11s 456us/step - loss: 0.0896 - acc: 0.9671 - val_loss: 0.9154 - val_acc: 0.8200\n",
            "Epoch 71/130\n",
            "24500/24500 [==============================] - 11s 458us/step - loss: 0.1103 - acc: 0.9602 - val_loss: 0.7671 - val_acc: 0.8500\n",
            "Epoch 72/130\n",
            "24500/24500 [==============================] - 11s 456us/step - loss: 0.0915 - acc: 0.9669 - val_loss: 0.8416 - val_acc: 0.8280\n",
            "Epoch 73/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.0945 - acc: 0.9660 - val_loss: 0.8700 - val_acc: 0.8360\n",
            "Epoch 74/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.0967 - acc: 0.9651 - val_loss: 0.9027 - val_acc: 0.8140\n",
            "Epoch 75/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.0887 - acc: 0.9680 - val_loss: 0.8722 - val_acc: 0.8380\n",
            "Epoch 76/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.1014 - acc: 0.9629 - val_loss: 0.8720 - val_acc: 0.8200\n",
            "Epoch 77/130\n",
            "24500/24500 [==============================] - 11s 458us/step - loss: 0.0897 - acc: 0.9672 - val_loss: 1.0319 - val_acc: 0.8360\n",
            "Epoch 78/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.0961 - acc: 0.9650 - val_loss: 1.0073 - val_acc: 0.8160\n",
            "Epoch 79/130\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.0975 - acc: 0.9656 - val_loss: 1.0265 - val_acc: 0.8280\n",
            "Epoch 80/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.0950 - acc: 0.9653 - val_loss: 0.8654 - val_acc: 0.8300\n",
            "Epoch 81/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.0915 - acc: 0.9672 - val_loss: 0.8738 - val_acc: 0.8420\n",
            "Epoch 82/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.1014 - acc: 0.9640 - val_loss: 0.9198 - val_acc: 0.8260\n",
            "Epoch 83/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.0941 - acc: 0.9652 - val_loss: 1.0121 - val_acc: 0.8160\n",
            "Epoch 84/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.0905 - acc: 0.9667 - val_loss: 1.1744 - val_acc: 0.8220\n",
            "Epoch 85/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.0875 - acc: 0.9680 - val_loss: 0.9856 - val_acc: 0.8260\n",
            "Epoch 86/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.1017 - acc: 0.9649 - val_loss: 1.1184 - val_acc: 0.8400\n",
            "Epoch 87/130\n",
            "24500/24500 [==============================] - 11s 456us/step - loss: 0.0954 - acc: 0.9651 - val_loss: 0.9564 - val_acc: 0.8240\n",
            "Epoch 88/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.0860 - acc: 0.9706 - val_loss: 0.9508 - val_acc: 0.8460\n",
            "Epoch 89/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.0932 - acc: 0.9680 - val_loss: 1.0777 - val_acc: 0.8220\n",
            "Epoch 90/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.0941 - acc: 0.9677 - val_loss: 1.0957 - val_acc: 0.8460\n",
            "Epoch 91/130\n",
            "24500/24500 [==============================] - 11s 457us/step - loss: 0.0986 - acc: 0.9653 - val_loss: 0.9960 - val_acc: 0.8400\n",
            "Epoch 92/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.0938 - acc: 0.9664 - val_loss: 1.0379 - val_acc: 0.8380\n",
            "Epoch 93/130\n",
            "24500/24500 [==============================] - 11s 456us/step - loss: 0.0832 - acc: 0.9697 - val_loss: 0.9669 - val_acc: 0.8360\n",
            "Epoch 94/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.1048 - acc: 0.9649 - val_loss: 0.9480 - val_acc: 0.8320\n",
            "Epoch 95/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.0846 - acc: 0.9707 - val_loss: 1.0401 - val_acc: 0.8200\n",
            "Epoch 96/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.0996 - acc: 0.9660 - val_loss: 1.1048 - val_acc: 0.8140\n",
            "Epoch 97/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.0952 - acc: 0.9683 - val_loss: 1.0038 - val_acc: 0.8300\n",
            "Epoch 98/130\n",
            "24500/24500 [==============================] - 11s 457us/step - loss: 0.0932 - acc: 0.9686 - val_loss: 1.0098 - val_acc: 0.8420\n",
            "Epoch 99/130\n",
            "24500/24500 [==============================] - 11s 457us/step - loss: 0.0831 - acc: 0.9712 - val_loss: 1.0674 - val_acc: 0.8200\n",
            "Epoch 100/130\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.0887 - acc: 0.9679 - val_loss: 1.1403 - val_acc: 0.8280\n",
            "Epoch 101/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.0860 - acc: 0.9698 - val_loss: 0.9391 - val_acc: 0.8220\n",
            "Epoch 102/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.1008 - acc: 0.9662 - val_loss: 1.0910 - val_acc: 0.8220\n",
            "Epoch 103/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.1078 - acc: 0.9645 - val_loss: 0.9718 - val_acc: 0.8440\n",
            "Epoch 104/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.0918 - acc: 0.9689 - val_loss: 0.9647 - val_acc: 0.8320\n",
            "Epoch 105/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.0802 - acc: 0.9720 - val_loss: 1.0322 - val_acc: 0.8460\n",
            "Epoch 106/130\n",
            "24500/24500 [==============================] - 11s 450us/step - loss: 0.0955 - acc: 0.9696 - val_loss: 0.9243 - val_acc: 0.8420\n",
            "Epoch 107/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.0974 - acc: 0.9669 - val_loss: 1.1886 - val_acc: 0.8220\n",
            "Epoch 108/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.0873 - acc: 0.9697 - val_loss: 1.1495 - val_acc: 0.8300\n",
            "Epoch 109/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.1010 - acc: 0.9665 - val_loss: 1.1065 - val_acc: 0.8380\n",
            "Epoch 110/130\n",
            "24500/24500 [==============================] - 11s 457us/step - loss: 0.0907 - acc: 0.9700 - val_loss: 1.0363 - val_acc: 0.8380\n",
            "Epoch 111/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.0807 - acc: 0.9739 - val_loss: 0.9718 - val_acc: 0.8240\n",
            "Epoch 112/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.0976 - acc: 0.9680 - val_loss: 0.9980 - val_acc: 0.8220\n",
            "Epoch 113/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.0969 - acc: 0.9671 - val_loss: 1.1018 - val_acc: 0.8260\n",
            "Epoch 114/130\n",
            "24500/24500 [==============================] - 11s 458us/step - loss: 0.0796 - acc: 0.9731 - val_loss: 1.1596 - val_acc: 0.8380\n",
            "Epoch 115/130\n",
            "24500/24500 [==============================] - 11s 456us/step - loss: 0.0981 - acc: 0.9683 - val_loss: 1.0713 - val_acc: 0.8280\n",
            "Epoch 116/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.0868 - acc: 0.9711 - val_loss: 1.0732 - val_acc: 0.8180\n",
            "Epoch 117/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.0909 - acc: 0.9692 - val_loss: 1.1485 - val_acc: 0.8340\n",
            "Epoch 118/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.0925 - acc: 0.9698 - val_loss: 1.1353 - val_acc: 0.8100\n",
            "Epoch 119/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.0970 - acc: 0.9689 - val_loss: 1.3090 - val_acc: 0.8380\n",
            "Epoch 120/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.0919 - acc: 0.9694 - val_loss: 1.0992 - val_acc: 0.8180\n",
            "Epoch 121/130\n",
            "24500/24500 [==============================] - 11s 454us/step - loss: 0.0885 - acc: 0.9704 - val_loss: 1.1441 - val_acc: 0.8260\n",
            "Epoch 122/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.0802 - acc: 0.9722 - val_loss: 1.2255 - val_acc: 0.8320\n",
            "Epoch 123/130\n",
            "24500/24500 [==============================] - 11s 452us/step - loss: 0.0974 - acc: 0.9693 - val_loss: 1.1553 - val_acc: 0.8360\n",
            "Epoch 124/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.0906 - acc: 0.9722 - val_loss: 1.1393 - val_acc: 0.8420\n",
            "Epoch 125/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.1015 - acc: 0.9674 - val_loss: 1.2364 - val_acc: 0.8120\n",
            "Epoch 126/130\n",
            "24500/24500 [==============================] - 11s 459us/step - loss: 0.0790 - acc: 0.9751 - val_loss: 1.1528 - val_acc: 0.8340\n",
            "Epoch 127/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.0942 - acc: 0.9712 - val_loss: 1.1220 - val_acc: 0.8420\n",
            "Epoch 128/130\n",
            "24500/24500 [==============================] - 11s 451us/step - loss: 0.0805 - acc: 0.9748 - val_loss: 1.1772 - val_acc: 0.8260\n",
            "Epoch 129/130\n",
            "24500/24500 [==============================] - 11s 453us/step - loss: 0.1028 - acc: 0.9679 - val_loss: 1.1446 - val_acc: 0.8340\n",
            "Epoch 130/130\n",
            "24500/24500 [==============================] - 11s 455us/step - loss: 0.0820 - acc: 0.9743 - val_loss: 1.1286 - val_acc: 0.8460\n",
            " F1 Score on Train :  0.9808521788204942\n",
            " F1 Score on Test :  0.83991683991684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_v5P94vjuChG",
        "colab_type": "code",
        "outputId": "e60673d6-1b77-4e5b-a3fc-2791a4aca30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3556
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model4 = Sequential()\n",
        "\n",
        "model4.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model4.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model4.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model4.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model4.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model4.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model4.add(Conv2D(64, (3, 3)))\n",
        "model4.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(64, activation='relu'))\n",
        "model4.add(Dense(64, activation='relu'))\n",
        "model4.add(Dense(32, activation='relu'))\n",
        "model4.add(layers.Dropout(0.5))\n",
        "model4.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model4.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model4.fit(X_train,y_train, epochs=100, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_predicted_train_catDog = model4.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model4.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/100\n",
            "24500/24500 [==============================] - 13s 535us/step - loss: 0.6955 - acc: 0.5550 - val_loss: 0.6488 - val_acc: 0.6340\n",
            "Epoch 2/100\n",
            "24500/24500 [==============================] - 12s 493us/step - loss: 0.6165 - acc: 0.6718 - val_loss: 0.5142 - val_acc: 0.7360\n",
            "Epoch 3/100\n",
            "24500/24500 [==============================] - 12s 486us/step - loss: 0.5400 - acc: 0.7373 - val_loss: 0.5039 - val_acc: 0.7420\n",
            "Epoch 4/100\n",
            "24500/24500 [==============================] - 12s 493us/step - loss: 0.4875 - acc: 0.7738 - val_loss: 0.4354 - val_acc: 0.7820\n",
            "Epoch 5/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.4452 - acc: 0.7996 - val_loss: 0.3875 - val_acc: 0.8140\n",
            "Epoch 6/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.4104 - acc: 0.8193 - val_loss: 0.3375 - val_acc: 0.8440\n",
            "Epoch 7/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.3786 - acc: 0.8366 - val_loss: 0.4311 - val_acc: 0.8160\n",
            "Epoch 8/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.3594 - acc: 0.8449 - val_loss: 0.3831 - val_acc: 0.8340\n",
            "Epoch 9/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.3257 - acc: 0.8607 - val_loss: 0.3437 - val_acc: 0.8460\n",
            "Epoch 10/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.3009 - acc: 0.8750 - val_loss: 0.3258 - val_acc: 0.8540\n",
            "Epoch 11/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.2747 - acc: 0.8867 - val_loss: 0.3284 - val_acc: 0.8660\n",
            "Epoch 12/100\n",
            "24500/24500 [==============================] - 12s 486us/step - loss: 0.2656 - acc: 0.8917 - val_loss: 0.3291 - val_acc: 0.8620\n",
            "Epoch 13/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.2272 - acc: 0.9075 - val_loss: 0.4044 - val_acc: 0.8380\n",
            "Epoch 14/100\n",
            "24500/24500 [==============================] - 12s 485us/step - loss: 0.2179 - acc: 0.9131 - val_loss: 0.3863 - val_acc: 0.8300\n",
            "Epoch 15/100\n",
            "24500/24500 [==============================] - 12s 484us/step - loss: 0.1947 - acc: 0.9219 - val_loss: 0.3433 - val_acc: 0.8580\n",
            "Epoch 16/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.1840 - acc: 0.9269 - val_loss: 0.4767 - val_acc: 0.8580\n",
            "Epoch 17/100\n",
            "24500/24500 [==============================] - 12s 485us/step - loss: 0.1705 - acc: 0.9329 - val_loss: 0.4431 - val_acc: 0.8580\n",
            "Epoch 18/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.1531 - acc: 0.9406 - val_loss: 0.5543 - val_acc: 0.8520\n",
            "Epoch 19/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.1397 - acc: 0.9458 - val_loss: 0.5246 - val_acc: 0.8420\n",
            "Epoch 20/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.1351 - acc: 0.9489 - val_loss: 0.6072 - val_acc: 0.8580\n",
            "Epoch 21/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.1285 - acc: 0.9500 - val_loss: 0.6342 - val_acc: 0.8420\n",
            "Epoch 22/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.1150 - acc: 0.9567 - val_loss: 0.6197 - val_acc: 0.8520\n",
            "Epoch 23/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.1097 - acc: 0.9585 - val_loss: 0.4976 - val_acc: 0.8560\n",
            "Epoch 24/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.1032 - acc: 0.9625 - val_loss: 0.6149 - val_acc: 0.8480\n",
            "Epoch 25/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.1038 - acc: 0.9616 - val_loss: 0.6099 - val_acc: 0.8460\n",
            "Epoch 26/100\n",
            "24500/24500 [==============================] - 12s 491us/step - loss: 0.0932 - acc: 0.9667 - val_loss: 0.7772 - val_acc: 0.8400\n",
            "Epoch 27/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0959 - acc: 0.9649 - val_loss: 0.5695 - val_acc: 0.8520\n",
            "Epoch 28/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0882 - acc: 0.9686 - val_loss: 0.7234 - val_acc: 0.8380\n",
            "Epoch 29/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0948 - acc: 0.9661 - val_loss: 0.6197 - val_acc: 0.8380\n",
            "Epoch 30/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0729 - acc: 0.9745 - val_loss: 0.7461 - val_acc: 0.8460\n",
            "Epoch 31/100\n",
            "24500/24500 [==============================] - 12s 492us/step - loss: 0.0802 - acc: 0.9716 - val_loss: 0.6690 - val_acc: 0.8320\n",
            "Epoch 32/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0879 - acc: 0.9713 - val_loss: 0.6107 - val_acc: 0.8480\n",
            "Epoch 33/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0700 - acc: 0.9757 - val_loss: 0.7994 - val_acc: 0.8420\n",
            "Epoch 34/100\n",
            "24500/24500 [==============================] - 12s 485us/step - loss: 0.0802 - acc: 0.9719 - val_loss: 0.5707 - val_acc: 0.8400\n",
            "Epoch 35/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0759 - acc: 0.9731 - val_loss: 0.6537 - val_acc: 0.8480\n",
            "Epoch 36/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0639 - acc: 0.9777 - val_loss: 0.8941 - val_acc: 0.8420\n",
            "Epoch 37/100\n",
            "24500/24500 [==============================] - 12s 486us/step - loss: 0.0730 - acc: 0.9749 - val_loss: 0.7537 - val_acc: 0.8600\n",
            "Epoch 38/100\n",
            "24500/24500 [==============================] - 12s 486us/step - loss: 0.0726 - acc: 0.9746 - val_loss: 0.8217 - val_acc: 0.8540\n",
            "Epoch 39/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0652 - acc: 0.9780 - val_loss: 0.6560 - val_acc: 0.8560\n",
            "Epoch 40/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0694 - acc: 0.9749 - val_loss: 0.7512 - val_acc: 0.8540\n",
            "Epoch 41/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.0610 - acc: 0.9785 - val_loss: 0.6973 - val_acc: 0.8540\n",
            "Epoch 42/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0611 - acc: 0.9797 - val_loss: 1.0370 - val_acc: 0.8460\n",
            "Epoch 43/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0686 - acc: 0.9776 - val_loss: 0.9625 - val_acc: 0.8420\n",
            "Epoch 44/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0576 - acc: 0.9803 - val_loss: 0.8583 - val_acc: 0.8460\n",
            "Epoch 45/100\n",
            "24500/24500 [==============================] - 12s 491us/step - loss: 0.0581 - acc: 0.9811 - val_loss: 1.0055 - val_acc: 0.8460\n",
            "Epoch 46/100\n",
            "24500/24500 [==============================] - 12s 491us/step - loss: 0.0519 - acc: 0.9829 - val_loss: 0.9038 - val_acc: 0.8420\n",
            "Epoch 47/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0580 - acc: 0.9805 - val_loss: 1.0747 - val_acc: 0.8360\n",
            "Epoch 48/100\n",
            "24500/24500 [==============================] - 12s 483us/step - loss: 0.0663 - acc: 0.9786 - val_loss: 1.0092 - val_acc: 0.8300\n",
            "Epoch 49/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.0605 - acc: 0.9811 - val_loss: 0.8942 - val_acc: 0.8480\n",
            "Epoch 50/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0567 - acc: 0.9814 - val_loss: 0.8798 - val_acc: 0.8280\n",
            "Epoch 51/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0576 - acc: 0.9810 - val_loss: 0.9367 - val_acc: 0.8520\n",
            "Epoch 52/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0521 - acc: 0.9829 - val_loss: 0.9177 - val_acc: 0.8420\n",
            "Epoch 53/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0522 - acc: 0.9829 - val_loss: 0.9120 - val_acc: 0.8320\n",
            "Epoch 54/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.0549 - acc: 0.9832 - val_loss: 0.9112 - val_acc: 0.8600\n",
            "Epoch 55/100\n",
            "24500/24500 [==============================] - 12s 486us/step - loss: 0.0510 - acc: 0.9839 - val_loss: 0.7823 - val_acc: 0.8440\n",
            "Epoch 56/100\n",
            "24500/24500 [==============================] - 12s 486us/step - loss: 0.0481 - acc: 0.9846 - val_loss: 0.6619 - val_acc: 0.8480\n",
            "Epoch 57/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0487 - acc: 0.9837 - val_loss: 1.0867 - val_acc: 0.8440\n",
            "Epoch 58/100\n",
            "24500/24500 [==============================] - 12s 484us/step - loss: 0.0507 - acc: 0.9839 - val_loss: 0.8021 - val_acc: 0.8480\n",
            "Epoch 59/100\n",
            "24500/24500 [==============================] - 12s 483us/step - loss: 0.0668 - acc: 0.9775 - val_loss: 0.7505 - val_acc: 0.8420\n",
            "Epoch 60/100\n",
            "24500/24500 [==============================] - 12s 484us/step - loss: 0.0493 - acc: 0.9844 - val_loss: 0.9902 - val_acc: 0.8380\n",
            "Epoch 61/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0468 - acc: 0.9847 - val_loss: 0.8808 - val_acc: 0.8520\n",
            "Epoch 62/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.0529 - acc: 0.9836 - val_loss: 0.7408 - val_acc: 0.8420\n",
            "Epoch 63/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.0471 - acc: 0.9851 - val_loss: 1.0108 - val_acc: 0.8480\n",
            "Epoch 64/100\n",
            "24500/24500 [==============================] - 12s 491us/step - loss: 0.0457 - acc: 0.9851 - val_loss: 0.9943 - val_acc: 0.8700\n",
            "Epoch 65/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0503 - acc: 0.9847 - val_loss: 0.8247 - val_acc: 0.8260\n",
            "Epoch 66/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0489 - acc: 0.9840 - val_loss: 0.9165 - val_acc: 0.8520\n",
            "Epoch 67/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0471 - acc: 0.9851 - val_loss: 0.8930 - val_acc: 0.8480\n",
            "Epoch 68/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0468 - acc: 0.9853 - val_loss: 1.0163 - val_acc: 0.8380\n",
            "Epoch 69/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0426 - acc: 0.9873 - val_loss: 1.1300 - val_acc: 0.8320\n",
            "Epoch 70/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0458 - acc: 0.9864 - val_loss: 0.8957 - val_acc: 0.8500\n",
            "Epoch 71/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.0588 - acc: 0.9816 - val_loss: 1.1172 - val_acc: 0.8360\n",
            "Epoch 72/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0447 - acc: 0.9857 - val_loss: 0.7835 - val_acc: 0.8500\n",
            "Epoch 73/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0334 - acc: 0.9890 - val_loss: 1.0520 - val_acc: 0.8420\n",
            "Epoch 74/100\n",
            "24500/24500 [==============================] - 12s 483us/step - loss: 0.0481 - acc: 0.9836 - val_loss: 0.8190 - val_acc: 0.8380\n",
            "Epoch 75/100\n",
            "24500/24500 [==============================] - 12s 482us/step - loss: 0.0371 - acc: 0.9880 - val_loss: 1.1153 - val_acc: 0.8400\n",
            "Epoch 76/100\n",
            "24500/24500 [==============================] - 12s 485us/step - loss: 0.0391 - acc: 0.9872 - val_loss: 0.9205 - val_acc: 0.8460\n",
            "Epoch 77/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0567 - acc: 0.9811 - val_loss: 0.8625 - val_acc: 0.8440\n",
            "Epoch 78/100\n",
            "24500/24500 [==============================] - 12s 486us/step - loss: 0.0552 - acc: 0.9822 - val_loss: 0.8802 - val_acc: 0.8380\n",
            "Epoch 79/100\n",
            "24500/24500 [==============================] - 12s 484us/step - loss: 0.0474 - acc: 0.9852 - val_loss: 0.9560 - val_acc: 0.8580\n",
            "Epoch 80/100\n",
            "24500/24500 [==============================] - 12s 484us/step - loss: 0.0404 - acc: 0.9869 - val_loss: 0.9309 - val_acc: 0.8360\n",
            "Epoch 81/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0399 - acc: 0.9871 - val_loss: 0.7125 - val_acc: 0.8160\n",
            "Epoch 82/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0593 - acc: 0.9804 - val_loss: 1.0168 - val_acc: 0.8320\n",
            "Epoch 83/100\n",
            "24500/24500 [==============================] - 12s 492us/step - loss: 0.0421 - acc: 0.9868 - val_loss: 0.9653 - val_acc: 0.8400\n",
            "Epoch 84/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0483 - acc: 0.9851 - val_loss: 1.0909 - val_acc: 0.8460\n",
            "Epoch 85/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0473 - acc: 0.9842 - val_loss: 1.0878 - val_acc: 0.8500\n",
            "Epoch 86/100\n",
            "24500/24500 [==============================] - 12s 491us/step - loss: 0.0468 - acc: 0.9861 - val_loss: 0.9743 - val_acc: 0.8420\n",
            "Epoch 87/100\n",
            "24500/24500 [==============================] - 12s 491us/step - loss: 0.0369 - acc: 0.9876 - val_loss: 0.8302 - val_acc: 0.8660\n",
            "Epoch 88/100\n",
            "24500/24500 [==============================] - 12s 490us/step - loss: 0.0349 - acc: 0.9894 - val_loss: 1.0114 - val_acc: 0.8460\n",
            "Epoch 89/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.0409 - acc: 0.9872 - val_loss: 1.0402 - val_acc: 0.8460\n",
            "Epoch 90/100\n",
            "24500/24500 [==============================] - 12s 489us/step - loss: 0.0425 - acc: 0.9867 - val_loss: 1.1697 - val_acc: 0.8180\n",
            "Epoch 91/100\n",
            "24500/24500 [==============================] - 12s 492us/step - loss: 0.0434 - acc: 0.9855 - val_loss: 0.9029 - val_acc: 0.8380\n",
            "Epoch 92/100\n",
            "24500/24500 [==============================] - 12s 491us/step - loss: 0.0287 - acc: 0.9913 - val_loss: 1.3913 - val_acc: 0.8240\n",
            "Epoch 93/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0501 - acc: 0.9849 - val_loss: 1.1996 - val_acc: 0.8380\n",
            "Epoch 94/100\n",
            "24500/24500 [==============================] - 12s 486us/step - loss: 0.0347 - acc: 0.9890 - val_loss: 0.9598 - val_acc: 0.8260\n",
            "Epoch 95/100\n",
            "24500/24500 [==============================] - 12s 484us/step - loss: 0.0507 - acc: 0.9840 - val_loss: 1.0128 - val_acc: 0.8500\n",
            "Epoch 96/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0387 - acc: 0.9870 - val_loss: 1.1086 - val_acc: 0.8480\n",
            "Epoch 97/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0402 - acc: 0.9873 - val_loss: 1.0219 - val_acc: 0.8480\n",
            "Epoch 98/100\n",
            "24500/24500 [==============================] - 12s 487us/step - loss: 0.0432 - acc: 0.9868 - val_loss: 1.1305 - val_acc: 0.8600\n",
            "Epoch 99/100\n",
            "24500/24500 [==============================] - 12s 488us/step - loss: 0.0393 - acc: 0.9868 - val_loss: 1.1358 - val_acc: 0.8360\n",
            "Epoch 100/100\n",
            "24500/24500 [==============================] - 12s 485us/step - loss: 0.0675 - acc: 0.9794 - val_loss: 1.0009 - val_acc: 0.8620\n",
            " F1 Score on Train :  0.9824401557193739\n",
            " F1 Score on Test :  0.8442437923250565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mot2O-4SOl1e",
        "colab_type": "code",
        "outputId": "777cd7ff-be77-486d-834c-3e87d38435ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3556
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model5 = Sequential()\n",
        "\n",
        "model5.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model5.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model5.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model5.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model5.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model5.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model5.add(Conv2D(64, (3, 3)))\n",
        "model5.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model5.add(Flatten())\n",
        "model5.add(Dense(64, activation='relu'))\n",
        "model5.add(Dense(64, activation='relu'))\n",
        "model5.add(Dense(64, activation='relu'))\n",
        "model5.add(layers.Dropout(0.7))\n",
        "model5.add(Dense(64, activation='relu'))\n",
        "model5.add(Dense(32, activation='relu'))\n",
        "model5.add(layers.Dropout(0.7))\n",
        "model5.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model5.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model5.fit(X_train,y_train, epochs=100, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_predicted_train_catDog = model5.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model5.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/100\n",
            "24500/24500 [==============================] - 15s 630us/step - loss: 0.7193 - acc: 0.4977 - val_loss: 0.6928 - val_acc: 0.5280\n",
            "Epoch 2/100\n",
            "24500/24500 [==============================] - 14s 565us/step - loss: 0.6931 - acc: 0.5089 - val_loss: 0.6922 - val_acc: 0.5860\n",
            "Epoch 3/100\n",
            "24500/24500 [==============================] - 14s 566us/step - loss: 0.6916 - acc: 0.5265 - val_loss: 0.6917 - val_acc: 0.5280\n",
            "Epoch 4/100\n",
            "24500/24500 [==============================] - 14s 566us/step - loss: 0.6883 - acc: 0.5421 - val_loss: 0.6820 - val_acc: 0.5600\n",
            "Epoch 5/100\n",
            "24500/24500 [==============================] - 14s 561us/step - loss: 0.6736 - acc: 0.5848 - val_loss: 0.6416 - val_acc: 0.6580\n",
            "Epoch 6/100\n",
            "24500/24500 [==============================] - 14s 560us/step - loss: 0.6387 - acc: 0.6510 - val_loss: 0.6255 - val_acc: 0.6640\n",
            "Epoch 7/100\n",
            "24500/24500 [==============================] - 14s 560us/step - loss: 0.6110 - acc: 0.6827 - val_loss: 0.5832 - val_acc: 0.7440\n",
            "Epoch 8/100\n",
            "24500/24500 [==============================] - 14s 561us/step - loss: 0.5780 - acc: 0.7148 - val_loss: 0.5573 - val_acc: 0.7520\n",
            "Epoch 9/100\n",
            "24500/24500 [==============================] - 14s 561us/step - loss: 0.5498 - acc: 0.7348 - val_loss: 0.5760 - val_acc: 0.6900\n",
            "Epoch 10/100\n",
            "24500/24500 [==============================] - 14s 560us/step - loss: 0.5247 - acc: 0.7560 - val_loss: 0.4991 - val_acc: 0.7680\n",
            "Epoch 11/100\n",
            "24500/24500 [==============================] - 14s 561us/step - loss: 0.5020 - acc: 0.7693 - val_loss: 0.5238 - val_acc: 0.7540\n",
            "Epoch 12/100\n",
            "24500/24500 [==============================] - 14s 560us/step - loss: 0.4743 - acc: 0.7887 - val_loss: 0.4872 - val_acc: 0.8100\n",
            "Epoch 13/100\n",
            "24500/24500 [==============================] - 14s 568us/step - loss: 0.4478 - acc: 0.8030 - val_loss: 0.4995 - val_acc: 0.7700\n",
            "Epoch 14/100\n",
            "24500/24500 [==============================] - 14s 564us/step - loss: 0.4291 - acc: 0.8136 - val_loss: 0.4629 - val_acc: 0.7980\n",
            "Epoch 15/100\n",
            "24500/24500 [==============================] - 14s 561us/step - loss: 0.4024 - acc: 0.8246 - val_loss: 0.5010 - val_acc: 0.7940\n",
            "Epoch 16/100\n",
            "24500/24500 [==============================] - 14s 565us/step - loss: 0.3800 - acc: 0.8393 - val_loss: 0.4805 - val_acc: 0.8000\n",
            "Epoch 17/100\n",
            "24500/24500 [==============================] - 14s 564us/step - loss: 0.3758 - acc: 0.8407 - val_loss: 0.4564 - val_acc: 0.8040\n",
            "Epoch 18/100\n",
            "24500/24500 [==============================] - 14s 567us/step - loss: 0.3475 - acc: 0.8542 - val_loss: 0.4721 - val_acc: 0.7660\n",
            "Epoch 19/100\n",
            "24500/24500 [==============================] - 14s 564us/step - loss: 0.3363 - acc: 0.8625 - val_loss: 0.4512 - val_acc: 0.7900\n",
            "Epoch 20/100\n",
            "24500/24500 [==============================] - 14s 558us/step - loss: 0.3067 - acc: 0.8722 - val_loss: 0.4451 - val_acc: 0.8160\n",
            "Epoch 21/100\n",
            "24500/24500 [==============================] - 14s 559us/step - loss: 0.2904 - acc: 0.8816 - val_loss: 0.4856 - val_acc: 0.8180\n",
            "Epoch 22/100\n",
            "24500/24500 [==============================] - 14s 562us/step - loss: 0.2700 - acc: 0.8891 - val_loss: 0.4995 - val_acc: 0.7740\n",
            "Epoch 23/100\n",
            "24500/24500 [==============================] - 14s 553us/step - loss: 0.2624 - acc: 0.8898 - val_loss: 0.4738 - val_acc: 0.7800\n",
            "Epoch 24/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.2489 - acc: 0.9005 - val_loss: 0.4545 - val_acc: 0.8320\n",
            "Epoch 25/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.2337 - acc: 0.9083 - val_loss: 0.6023 - val_acc: 0.7860\n",
            "Epoch 26/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.2264 - acc: 0.9109 - val_loss: 0.6141 - val_acc: 0.7920\n",
            "Epoch 27/100\n",
            "24500/24500 [==============================] - 14s 555us/step - loss: 0.2096 - acc: 0.9182 - val_loss: 0.4608 - val_acc: 0.8120\n",
            "Epoch 28/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.1957 - acc: 0.9242 - val_loss: 0.5541 - val_acc: 0.8040\n",
            "Epoch 29/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.1979 - acc: 0.9223 - val_loss: 0.5009 - val_acc: 0.8080\n",
            "Epoch 30/100\n",
            "24500/24500 [==============================] - 14s 558us/step - loss: 0.1940 - acc: 0.9251 - val_loss: 0.4891 - val_acc: 0.8200\n",
            "Epoch 31/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.1704 - acc: 0.9367 - val_loss: 0.4765 - val_acc: 0.8120\n",
            "Epoch 32/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.1684 - acc: 0.9381 - val_loss: 0.5820 - val_acc: 0.7900\n",
            "Epoch 33/100\n",
            "24500/24500 [==============================] - 14s 560us/step - loss: 0.1611 - acc: 0.9402 - val_loss: 0.5506 - val_acc: 0.7940\n",
            "Epoch 34/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.1698 - acc: 0.9384 - val_loss: 0.5186 - val_acc: 0.7960\n",
            "Epoch 35/100\n",
            "24500/24500 [==============================] - 14s 559us/step - loss: 0.1564 - acc: 0.9404 - val_loss: 0.6801 - val_acc: 0.7620\n",
            "Epoch 36/100\n",
            "24500/24500 [==============================] - 14s 558us/step - loss: 0.1497 - acc: 0.9447 - val_loss: 0.5444 - val_acc: 0.7760\n",
            "Epoch 37/100\n",
            "24500/24500 [==============================] - 14s 557us/step - loss: 0.1466 - acc: 0.9443 - val_loss: 0.7118 - val_acc: 0.7700\n",
            "Epoch 38/100\n",
            "24500/24500 [==============================] - 14s 555us/step - loss: 0.1584 - acc: 0.9434 - val_loss: 0.5190 - val_acc: 0.8080\n",
            "Epoch 39/100\n",
            "24500/24500 [==============================] - 14s 562us/step - loss: 0.1357 - acc: 0.9505 - val_loss: 0.5981 - val_acc: 0.7680\n",
            "Epoch 40/100\n",
            "24500/24500 [==============================] - 14s 559us/step - loss: 0.1213 - acc: 0.9559 - val_loss: 0.6003 - val_acc: 0.8100\n",
            "Epoch 41/100\n",
            "24500/24500 [==============================] - 14s 553us/step - loss: 0.1198 - acc: 0.9561 - val_loss: 0.5161 - val_acc: 0.8100\n",
            "Epoch 42/100\n",
            "24500/24500 [==============================] - 14s 554us/step - loss: 0.1214 - acc: 0.9578 - val_loss: 0.4856 - val_acc: 0.8240\n",
            "Epoch 43/100\n",
            "24500/24500 [==============================] - 14s 555us/step - loss: 0.1220 - acc: 0.9574 - val_loss: 0.5872 - val_acc: 0.7820\n",
            "Epoch 44/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.1361 - acc: 0.9524 - val_loss: 0.5319 - val_acc: 0.8120\n",
            "Epoch 45/100\n",
            "24500/24500 [==============================] - 14s 554us/step - loss: 0.1126 - acc: 0.9598 - val_loss: 0.6851 - val_acc: 0.8180\n",
            "Epoch 46/100\n",
            "24500/24500 [==============================] - 14s 553us/step - loss: 0.1038 - acc: 0.9650 - val_loss: 0.5706 - val_acc: 0.8140\n",
            "Epoch 47/100\n",
            "24500/24500 [==============================] - 14s 553us/step - loss: 0.1144 - acc: 0.9604 - val_loss: 0.6688 - val_acc: 0.7960\n",
            "Epoch 48/100\n",
            "24500/24500 [==============================] - 14s 557us/step - loss: 0.1149 - acc: 0.9613 - val_loss: 0.8232 - val_acc: 0.7780\n",
            "Epoch 49/100\n",
            "24500/24500 [==============================] - 14s 554us/step - loss: 0.1225 - acc: 0.9579 - val_loss: 0.5671 - val_acc: 0.8140\n",
            "Epoch 50/100\n",
            "24500/24500 [==============================] - 14s 558us/step - loss: 0.1272 - acc: 0.9537 - val_loss: 0.6900 - val_acc: 0.8120\n",
            "Epoch 51/100\n",
            "24500/24500 [==============================] - 14s 555us/step - loss: 0.1205 - acc: 0.9581 - val_loss: 0.6852 - val_acc: 0.8140\n",
            "Epoch 52/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.0941 - acc: 0.9671 - val_loss: 0.6061 - val_acc: 0.8220\n",
            "Epoch 53/100\n",
            "24500/24500 [==============================] - 14s 559us/step - loss: 0.1040 - acc: 0.9638 - val_loss: 0.6961 - val_acc: 0.8140\n",
            "Epoch 54/100\n",
            "24500/24500 [==============================] - 14s 554us/step - loss: 0.0994 - acc: 0.9647 - val_loss: 0.5339 - val_acc: 0.8260\n",
            "Epoch 55/100\n",
            "24500/24500 [==============================] - 14s 563us/step - loss: 0.1067 - acc: 0.9645 - val_loss: 0.6760 - val_acc: 0.8180\n",
            "Epoch 56/100\n",
            "24500/24500 [==============================] - 14s 554us/step - loss: 0.1126 - acc: 0.9608 - val_loss: 0.6764 - val_acc: 0.7900\n",
            "Epoch 57/100\n",
            "24500/24500 [==============================] - 14s 564us/step - loss: 0.1145 - acc: 0.9618 - val_loss: 0.6504 - val_acc: 0.8160\n",
            "Epoch 58/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.1138 - acc: 0.9586 - val_loss: 0.5891 - val_acc: 0.8060\n",
            "Epoch 59/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.1029 - acc: 0.9644 - val_loss: 0.5015 - val_acc: 0.8060\n",
            "Epoch 60/100\n",
            "24500/24500 [==============================] - 14s 555us/step - loss: 0.1285 - acc: 0.9535 - val_loss: 0.6632 - val_acc: 0.8120\n",
            "Epoch 61/100\n",
            "24500/24500 [==============================] - 14s 557us/step - loss: 0.0868 - acc: 0.9716 - val_loss: 0.6581 - val_acc: 0.7900\n",
            "Epoch 62/100\n",
            "24500/24500 [==============================] - 14s 557us/step - loss: 0.1148 - acc: 0.9597 - val_loss: 0.4531 - val_acc: 0.8020\n",
            "Epoch 63/100\n",
            "24500/24500 [==============================] - 14s 555us/step - loss: 0.1167 - acc: 0.9592 - val_loss: 0.5329 - val_acc: 0.7920\n",
            "Epoch 64/100\n",
            "24500/24500 [==============================] - 14s 554us/step - loss: 0.0988 - acc: 0.9662 - val_loss: 0.7193 - val_acc: 0.8000\n",
            "Epoch 65/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.1206 - acc: 0.9625 - val_loss: 0.5755 - val_acc: 0.8180\n",
            "Epoch 66/100\n",
            "24500/24500 [==============================] - 14s 558us/step - loss: 0.0927 - acc: 0.9682 - val_loss: 0.7965 - val_acc: 0.8220\n",
            "Epoch 67/100\n",
            "24500/24500 [==============================] - 14s 554us/step - loss: 0.1167 - acc: 0.9602 - val_loss: 0.6552 - val_acc: 0.7980\n",
            "Epoch 68/100\n",
            "24500/24500 [==============================] - 14s 559us/step - loss: 0.1428 - acc: 0.9504 - val_loss: 0.5868 - val_acc: 0.7920\n",
            "Epoch 69/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.1046 - acc: 0.9626 - val_loss: 0.5679 - val_acc: 0.7920\n",
            "Epoch 70/100\n",
            "24500/24500 [==============================] - 14s 564us/step - loss: 0.0821 - acc: 0.9706 - val_loss: 0.7432 - val_acc: 0.8300\n",
            "Epoch 71/100\n",
            "24500/24500 [==============================] - 14s 562us/step - loss: 0.0848 - acc: 0.9718 - val_loss: 0.8356 - val_acc: 0.8260\n",
            "Epoch 72/100\n",
            "24500/24500 [==============================] - 14s 557us/step - loss: 0.2951 - acc: 0.8802 - val_loss: 0.5395 - val_acc: 0.7960\n",
            "Epoch 73/100\n",
            "24500/24500 [==============================] - 14s 559us/step - loss: 0.1213 - acc: 0.9584 - val_loss: 0.8205 - val_acc: 0.8060\n",
            "Epoch 74/100\n",
            "24500/24500 [==============================] - 14s 561us/step - loss: 0.1190 - acc: 0.9609 - val_loss: 0.5555 - val_acc: 0.7740\n",
            "Epoch 75/100\n",
            "24500/24500 [==============================] - 14s 557us/step - loss: 0.0974 - acc: 0.9669 - val_loss: 0.6872 - val_acc: 0.8060\n",
            "Epoch 76/100\n",
            "24500/24500 [==============================] - 14s 555us/step - loss: 0.1463 - acc: 0.9498 - val_loss: 0.6014 - val_acc: 0.7660\n",
            "Epoch 77/100\n",
            "24500/24500 [==============================] - 14s 557us/step - loss: 0.1562 - acc: 0.9418 - val_loss: 0.9114 - val_acc: 0.8180\n",
            "Epoch 78/100\n",
            "24500/24500 [==============================] - 14s 554us/step - loss: 0.1051 - acc: 0.9644 - val_loss: 0.6151 - val_acc: 0.8140\n",
            "Epoch 79/100\n",
            "24500/24500 [==============================] - 14s 555us/step - loss: 0.0958 - acc: 0.9687 - val_loss: 0.6628 - val_acc: 0.8040\n",
            "Epoch 80/100\n",
            "24500/24500 [==============================] - 14s 557us/step - loss: 0.0877 - acc: 0.9709 - val_loss: 0.7236 - val_acc: 0.8020\n",
            "Epoch 81/100\n",
            "24500/24500 [==============================] - 14s 555us/step - loss: 0.1442 - acc: 0.9491 - val_loss: 0.7120 - val_acc: 0.8300\n",
            "Epoch 82/100\n",
            "24500/24500 [==============================] - 14s 554us/step - loss: 0.2215 - acc: 0.9187 - val_loss: 0.4532 - val_acc: 0.7960\n",
            "Epoch 83/100\n",
            "24500/24500 [==============================] - 14s 557us/step - loss: 0.1746 - acc: 0.9367 - val_loss: 0.6056 - val_acc: 0.8340\n",
            "Epoch 84/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.2178 - acc: 0.9073 - val_loss: 0.5651 - val_acc: 0.7060\n",
            "Epoch 85/100\n",
            "24500/24500 [==============================] - 14s 553us/step - loss: 0.4581 - acc: 0.7926 - val_loss: 0.4585 - val_acc: 0.7940\n",
            "Epoch 86/100\n",
            "24500/24500 [==============================] - 14s 554us/step - loss: 0.2432 - acc: 0.9021 - val_loss: 0.5915 - val_acc: 0.8060\n",
            "Epoch 87/100\n",
            "24500/24500 [==============================] - 14s 560us/step - loss: 0.1296 - acc: 0.9529 - val_loss: 0.8808 - val_acc: 0.7960\n",
            "Epoch 88/100\n",
            "24500/24500 [==============================] - 14s 561us/step - loss: 0.0984 - acc: 0.9650 - val_loss: 0.6684 - val_acc: 0.8180\n",
            "Epoch 89/100\n",
            "24500/24500 [==============================] - 14s 554us/step - loss: 0.0855 - acc: 0.9716 - val_loss: 0.7796 - val_acc: 0.8060\n",
            "Epoch 90/100\n",
            "24500/24500 [==============================] - 14s 557us/step - loss: 0.1523 - acc: 0.9436 - val_loss: 0.7337 - val_acc: 0.8240\n",
            "Epoch 91/100\n",
            "24500/24500 [==============================] - 14s 559us/step - loss: 0.0721 - acc: 0.9758 - val_loss: 0.9367 - val_acc: 0.7680\n",
            "Epoch 92/100\n",
            "24500/24500 [==============================] - 14s 567us/step - loss: 0.1659 - acc: 0.9418 - val_loss: 0.6554 - val_acc: 0.8340\n",
            "Epoch 93/100\n",
            "24500/24500 [==============================] - 14s 553us/step - loss: 0.4069 - acc: 0.8090 - val_loss: 0.5646 - val_acc: 0.7140\n",
            "Epoch 94/100\n",
            "24500/24500 [==============================] - 14s 556us/step - loss: 0.4231 - acc: 0.8136 - val_loss: 0.4435 - val_acc: 0.7920\n",
            "Epoch 95/100\n",
            "24500/24500 [==============================] - 14s 555us/step - loss: 0.2953 - acc: 0.8819 - val_loss: 0.5552 - val_acc: 0.7900\n",
            "Epoch 96/100\n",
            "24500/24500 [==============================] - 14s 558us/step - loss: 0.2009 - acc: 0.9231 - val_loss: 0.6057 - val_acc: 0.8160\n",
            "Epoch 97/100\n",
            "24500/24500 [==============================] - 14s 558us/step - loss: 0.2344 - acc: 0.9108 - val_loss: 0.6006 - val_acc: 0.7880\n",
            "Epoch 98/100\n",
            "24500/24500 [==============================] - 14s 555us/step - loss: 0.1256 - acc: 0.9551 - val_loss: 0.6415 - val_acc: 0.8120\n",
            "Epoch 99/100\n",
            "24500/24500 [==============================] - 14s 558us/step - loss: 0.1798 - acc: 0.9297 - val_loss: 0.4782 - val_acc: 0.7880\n",
            "Epoch 100/100\n",
            "24500/24500 [==============================] - 14s 557us/step - loss: 0.2260 - acc: 0.9094 - val_loss: 0.6229 - val_acc: 0.8060\n",
            " F1 Score on Train :  0.9532483302975105\n",
            " F1 Score on Test :  0.8040404040404041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_3KUSe5wXyP0",
        "colab_type": "code",
        "outputId": "52b53a29-2d9f-46c6-a414-0c67acb48fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3556
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model6 = Sequential()\n",
        "\n",
        "model6.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model6.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model6.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model6.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model6.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model6.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model6.add(Conv2D(64, (3, 3)))\n",
        "model6.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Dropout(0.2))\n",
        "\n",
        "model6.add(Flatten())\n",
        "model6.add(Dense(128, activation='relu'))\n",
        "model6.add(Dense(64, activation='relu'))\n",
        "model6.add(Dense(64, activation='relu'))\n",
        "model6.add(layers.Dropout(0.7))\n",
        "model6.add(Dense(64, activation='relu'))\n",
        "model6.add(Dense(32, activation='relu'))\n",
        "model6.add(layers.Dropout(0.7))\n",
        "model6.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model6.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model6.fit(X_train,y_train, epochs=100, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_predicted_train_catDog = model6.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model6.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/100\n",
            "24500/24500 [==============================] - 17s 682us/step - loss: 0.7030 - acc: 0.5191 - val_loss: 0.6841 - val_acc: 0.5660\n",
            "Epoch 2/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.6798 - acc: 0.5722 - val_loss: 0.6623 - val_acc: 0.6580\n",
            "Epoch 3/100\n",
            "24500/24500 [==============================] - 15s 605us/step - loss: 0.6350 - acc: 0.6413 - val_loss: 0.5835 - val_acc: 0.6560\n",
            "Epoch 4/100\n",
            "24500/24500 [==============================] - 15s 600us/step - loss: 0.5495 - acc: 0.7310 - val_loss: 0.9355 - val_acc: 0.5700\n",
            "Epoch 5/100\n",
            "24500/24500 [==============================] - 15s 601us/step - loss: 0.4771 - acc: 0.7884 - val_loss: 0.4122 - val_acc: 0.8220\n",
            "Epoch 6/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.4366 - acc: 0.8146 - val_loss: 0.4389 - val_acc: 0.7840\n",
            "Epoch 7/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.4015 - acc: 0.8312 - val_loss: 0.3950 - val_acc: 0.8020\n",
            "Epoch 8/100\n",
            "24500/24500 [==============================] - 15s 596us/step - loss: 0.3723 - acc: 0.8471 - val_loss: 0.3794 - val_acc: 0.8040\n",
            "Epoch 9/100\n",
            "24500/24500 [==============================] - 15s 594us/step - loss: 0.3523 - acc: 0.8583 - val_loss: 0.4121 - val_acc: 0.7880\n",
            "Epoch 10/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.3304 - acc: 0.8669 - val_loss: 0.4042 - val_acc: 0.8020\n",
            "Epoch 11/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.3088 - acc: 0.8751 - val_loss: 0.3272 - val_acc: 0.8340\n",
            "Epoch 12/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.2950 - acc: 0.8839 - val_loss: 0.3050 - val_acc: 0.8720\n",
            "Epoch 13/100\n",
            "24500/24500 [==============================] - 15s 604us/step - loss: 0.2771 - acc: 0.8907 - val_loss: 0.3002 - val_acc: 0.8840\n",
            "Epoch 14/100\n",
            "24500/24500 [==============================] - 15s 598us/step - loss: 0.2646 - acc: 0.8944 - val_loss: 0.2834 - val_acc: 0.8760\n",
            "Epoch 15/100\n",
            "24500/24500 [==============================] - 15s 599us/step - loss: 0.2497 - acc: 0.9011 - val_loss: 0.3859 - val_acc: 0.8560\n",
            "Epoch 16/100\n",
            "24500/24500 [==============================] - 15s 600us/step - loss: 0.2415 - acc: 0.9065 - val_loss: 0.2853 - val_acc: 0.8920\n",
            "Epoch 17/100\n",
            "24500/24500 [==============================] - 15s 602us/step - loss: 0.2271 - acc: 0.9091 - val_loss: 0.3930 - val_acc: 0.8120\n",
            "Epoch 18/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.2115 - acc: 0.9171 - val_loss: 0.3319 - val_acc: 0.8580\n",
            "Epoch 19/100\n",
            "24500/24500 [==============================] - 15s 601us/step - loss: 0.2160 - acc: 0.9193 - val_loss: 0.3236 - val_acc: 0.8640\n",
            "Epoch 20/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.1979 - acc: 0.9220 - val_loss: 0.4357 - val_acc: 0.8140\n",
            "Epoch 21/100\n",
            "24500/24500 [==============================] - 15s 601us/step - loss: 0.1952 - acc: 0.9252 - val_loss: 0.2759 - val_acc: 0.8980\n",
            "Epoch 22/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.1864 - acc: 0.9290 - val_loss: 0.2961 - val_acc: 0.8820\n",
            "Epoch 23/100\n",
            "24500/24500 [==============================] - 14s 591us/step - loss: 0.1726 - acc: 0.9348 - val_loss: 0.3429 - val_acc: 0.8320\n",
            "Epoch 24/100\n",
            "24500/24500 [==============================] - 15s 594us/step - loss: 0.1731 - acc: 0.9339 - val_loss: 0.2945 - val_acc: 0.8820\n",
            "Epoch 25/100\n",
            "24500/24500 [==============================] - 15s 596us/step - loss: 0.1803 - acc: 0.9332 - val_loss: 0.2796 - val_acc: 0.8900\n",
            "Epoch 26/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.1612 - acc: 0.9397 - val_loss: 0.2676 - val_acc: 0.8980\n",
            "Epoch 27/100\n",
            "24500/24500 [==============================] - 15s 598us/step - loss: 0.1464 - acc: 0.9453 - val_loss: 0.3030 - val_acc: 0.8760\n",
            "Epoch 28/100\n",
            "24500/24500 [==============================] - 15s 599us/step - loss: 0.1511 - acc: 0.9451 - val_loss: 0.2885 - val_acc: 0.8840\n",
            "Epoch 29/100\n",
            "24500/24500 [==============================] - 15s 592us/step - loss: 0.1469 - acc: 0.9456 - val_loss: 0.2826 - val_acc: 0.8800\n",
            "Epoch 30/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.1346 - acc: 0.9498 - val_loss: 0.2908 - val_acc: 0.8880\n",
            "Epoch 31/100\n",
            "24500/24500 [==============================] - 15s 601us/step - loss: 0.1293 - acc: 0.9531 - val_loss: 0.2864 - val_acc: 0.8820\n",
            "Epoch 32/100\n",
            "24500/24500 [==============================] - 15s 593us/step - loss: 0.1271 - acc: 0.9518 - val_loss: 0.2775 - val_acc: 0.8920\n",
            "Epoch 33/100\n",
            "24500/24500 [==============================] - 15s 602us/step - loss: 0.1264 - acc: 0.9531 - val_loss: 0.3082 - val_acc: 0.8720\n",
            "Epoch 34/100\n",
            "24500/24500 [==============================] - 15s 599us/step - loss: 0.1193 - acc: 0.9578 - val_loss: 0.3829 - val_acc: 0.8660\n",
            "Epoch 35/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.1269 - acc: 0.9532 - val_loss: 0.3550 - val_acc: 0.8440\n",
            "Epoch 36/100\n",
            "24500/24500 [==============================] - 15s 599us/step - loss: 0.1246 - acc: 0.9553 - val_loss: 0.2958 - val_acc: 0.8740\n",
            "Epoch 37/100\n",
            "24500/24500 [==============================] - 15s 603us/step - loss: 0.1187 - acc: 0.9593 - val_loss: 0.3355 - val_acc: 0.8860\n",
            "Epoch 38/100\n",
            "24500/24500 [==============================] - 15s 594us/step - loss: 0.1176 - acc: 0.9574 - val_loss: 0.2809 - val_acc: 0.8980\n",
            "Epoch 39/100\n",
            "24500/24500 [==============================] - 15s 596us/step - loss: 0.1109 - acc: 0.9592 - val_loss: 0.3106 - val_acc: 0.8980\n",
            "Epoch 40/100\n",
            "24500/24500 [==============================] - 15s 598us/step - loss: 0.1133 - acc: 0.9598 - val_loss: 0.3648 - val_acc: 0.8640\n",
            "Epoch 41/100\n",
            "24500/24500 [==============================] - 15s 596us/step - loss: 0.1094 - acc: 0.9613 - val_loss: 0.3882 - val_acc: 0.8640\n",
            "Epoch 42/100\n",
            "24500/24500 [==============================] - 15s 596us/step - loss: 0.1030 - acc: 0.9647 - val_loss: 0.3848 - val_acc: 0.8700\n",
            "Epoch 43/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.1039 - acc: 0.9627 - val_loss: 0.5321 - val_acc: 0.8480\n",
            "Epoch 44/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.1118 - acc: 0.9600 - val_loss: 0.3629 - val_acc: 0.8440\n",
            "Epoch 45/100\n",
            "24500/24500 [==============================] - 15s 604us/step - loss: 0.0991 - acc: 0.9622 - val_loss: 0.2790 - val_acc: 0.8920\n",
            "Epoch 46/100\n",
            "24500/24500 [==============================] - 15s 605us/step - loss: 0.0955 - acc: 0.9667 - val_loss: 0.3176 - val_acc: 0.8740\n",
            "Epoch 47/100\n",
            "24500/24500 [==============================] - 15s 602us/step - loss: 0.0970 - acc: 0.9671 - val_loss: 0.2943 - val_acc: 0.8920\n",
            "Epoch 48/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.0944 - acc: 0.9665 - val_loss: 0.3358 - val_acc: 0.8900\n",
            "Epoch 49/100\n",
            "24500/24500 [==============================] - 15s 602us/step - loss: 0.0922 - acc: 0.9674 - val_loss: 0.2757 - val_acc: 0.9020\n",
            "Epoch 50/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0970 - acc: 0.9672 - val_loss: 0.2719 - val_acc: 0.8840\n",
            "Epoch 51/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.0881 - acc: 0.9712 - val_loss: 0.3603 - val_acc: 0.8520\n",
            "Epoch 52/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0928 - acc: 0.9680 - val_loss: 0.2900 - val_acc: 0.8800\n",
            "Epoch 53/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0932 - acc: 0.9690 - val_loss: 0.2821 - val_acc: 0.8860\n",
            "Epoch 54/100\n",
            "24500/24500 [==============================] - 15s 601us/step - loss: 0.0784 - acc: 0.9727 - val_loss: 0.3084 - val_acc: 0.8820\n",
            "Epoch 55/100\n",
            "24500/24500 [==============================] - 15s 596us/step - loss: 0.0819 - acc: 0.9730 - val_loss: 0.2997 - val_acc: 0.8880\n",
            "Epoch 56/100\n",
            "24500/24500 [==============================] - 14s 592us/step - loss: 0.0795 - acc: 0.9718 - val_loss: 0.2696 - val_acc: 0.8940\n",
            "Epoch 57/100\n",
            "24500/24500 [==============================] - 15s 593us/step - loss: 0.0851 - acc: 0.9701 - val_loss: 0.2804 - val_acc: 0.8900\n",
            "Epoch 58/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0820 - acc: 0.9730 - val_loss: 0.3684 - val_acc: 0.8840\n",
            "Epoch 59/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0863 - acc: 0.9711 - val_loss: 0.4225 - val_acc: 0.8860\n",
            "Epoch 60/100\n",
            "24500/24500 [==============================] - 15s 596us/step - loss: 0.0788 - acc: 0.9741 - val_loss: 0.3648 - val_acc: 0.8640\n",
            "Epoch 61/100\n",
            "24500/24500 [==============================] - 15s 602us/step - loss: 0.0850 - acc: 0.9718 - val_loss: 0.3329 - val_acc: 0.8680\n",
            "Epoch 62/100\n",
            "24500/24500 [==============================] - 15s 594us/step - loss: 0.0805 - acc: 0.9746 - val_loss: 0.3577 - val_acc: 0.8640\n",
            "Epoch 63/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0755 - acc: 0.9758 - val_loss: 0.3278 - val_acc: 0.8860\n",
            "Epoch 64/100\n",
            "24500/24500 [==============================] - 15s 602us/step - loss: 0.0802 - acc: 0.9733 - val_loss: 0.3801 - val_acc: 0.8600\n",
            "Epoch 65/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.0793 - acc: 0.9738 - val_loss: 0.3377 - val_acc: 0.8840\n",
            "Epoch 66/100\n",
            "24500/24500 [==============================] - 15s 603us/step - loss: 0.0722 - acc: 0.9758 - val_loss: 0.2931 - val_acc: 0.9100\n",
            "Epoch 67/100\n",
            "24500/24500 [==============================] - 15s 599us/step - loss: 0.0757 - acc: 0.9747 - val_loss: 0.3072 - val_acc: 0.8740\n",
            "Epoch 68/100\n",
            "24500/24500 [==============================] - 15s 599us/step - loss: 0.0711 - acc: 0.9757 - val_loss: 0.2556 - val_acc: 0.9060\n",
            "Epoch 69/100\n",
            "24500/24500 [==============================] - 15s 596us/step - loss: 0.0725 - acc: 0.9767 - val_loss: 0.2717 - val_acc: 0.9160\n",
            "Epoch 70/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.0665 - acc: 0.9782 - val_loss: 0.3690 - val_acc: 0.8980\n",
            "Epoch 71/100\n",
            "24500/24500 [==============================] - 15s 596us/step - loss: 0.0839 - acc: 0.9724 - val_loss: 0.3236 - val_acc: 0.8880\n",
            "Epoch 72/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0748 - acc: 0.9760 - val_loss: 0.3080 - val_acc: 0.8960\n",
            "Epoch 73/100\n",
            "24500/24500 [==============================] - 15s 594us/step - loss: 0.0720 - acc: 0.9775 - val_loss: 0.3100 - val_acc: 0.8960\n",
            "Epoch 74/100\n",
            "24500/24500 [==============================] - 15s 593us/step - loss: 0.0686 - acc: 0.9770 - val_loss: 0.2996 - val_acc: 0.8980\n",
            "Epoch 75/100\n",
            "24500/24500 [==============================] - 15s 594us/step - loss: 0.0677 - acc: 0.9781 - val_loss: 0.2962 - val_acc: 0.8940\n",
            "Epoch 76/100\n",
            "24500/24500 [==============================] - 15s 593us/step - loss: 0.0612 - acc: 0.9801 - val_loss: 0.3356 - val_acc: 0.8920\n",
            "Epoch 77/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0653 - acc: 0.9795 - val_loss: 0.3080 - val_acc: 0.8880\n",
            "Epoch 78/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.0618 - acc: 0.9798 - val_loss: 0.3381 - val_acc: 0.8940\n",
            "Epoch 79/100\n",
            "24500/24500 [==============================] - 15s 596us/step - loss: 0.0704 - acc: 0.9783 - val_loss: 0.2692 - val_acc: 0.8900\n",
            "Epoch 80/100\n",
            "24500/24500 [==============================] - 15s 598us/step - loss: 0.0652 - acc: 0.9785 - val_loss: 0.3155 - val_acc: 0.8820\n",
            "Epoch 81/100\n",
            "24500/24500 [==============================] - 15s 596us/step - loss: 0.0687 - acc: 0.9795 - val_loss: 0.2943 - val_acc: 0.8940\n",
            "Epoch 82/100\n",
            "24500/24500 [==============================] - 15s 604us/step - loss: 0.0594 - acc: 0.9798 - val_loss: 0.6169 - val_acc: 0.8640\n",
            "Epoch 83/100\n",
            "24500/24500 [==============================] - 15s 600us/step - loss: 0.0678 - acc: 0.9788 - val_loss: 0.5152 - val_acc: 0.8760\n",
            "Epoch 84/100\n",
            "24500/24500 [==============================] - 15s 599us/step - loss: 0.0623 - acc: 0.9793 - val_loss: 0.3097 - val_acc: 0.8800\n",
            "Epoch 85/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.0650 - acc: 0.9792 - val_loss: 0.3299 - val_acc: 0.8920\n",
            "Epoch 86/100\n",
            "24500/24500 [==============================] - 15s 604us/step - loss: 0.0597 - acc: 0.9809 - val_loss: 0.3054 - val_acc: 0.8940\n",
            "Epoch 87/100\n",
            "24500/24500 [==============================] - 15s 592us/step - loss: 0.0632 - acc: 0.9797 - val_loss: 0.2697 - val_acc: 0.8900\n",
            "Epoch 88/100\n",
            "24500/24500 [==============================] - 15s 594us/step - loss: 0.0545 - acc: 0.9817 - val_loss: 0.3114 - val_acc: 0.9000\n",
            "Epoch 89/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0579 - acc: 0.9808 - val_loss: 0.3080 - val_acc: 0.8820\n",
            "Epoch 90/100\n",
            "24500/24500 [==============================] - 15s 597us/step - loss: 0.0610 - acc: 0.9804 - val_loss: 0.4743 - val_acc: 0.8220\n",
            "Epoch 91/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0552 - acc: 0.9819 - val_loss: 0.8842 - val_acc: 0.7680\n",
            "Epoch 92/100\n",
            "24500/24500 [==============================] - 15s 593us/step - loss: 0.0621 - acc: 0.9815 - val_loss: 0.5079 - val_acc: 0.8620\n",
            "Epoch 93/100\n",
            "24500/24500 [==============================] - 15s 593us/step - loss: 0.0536 - acc: 0.9827 - val_loss: 0.2935 - val_acc: 0.9020\n",
            "Epoch 94/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0594 - acc: 0.9809 - val_loss: 0.3487 - val_acc: 0.8820\n",
            "Epoch 95/100\n",
            "24500/24500 [==============================] - 15s 598us/step - loss: 0.0605 - acc: 0.9805 - val_loss: 0.3831 - val_acc: 0.8960\n",
            "Epoch 96/100\n",
            "24500/24500 [==============================] - 15s 593us/step - loss: 0.0661 - acc: 0.9783 - val_loss: 0.5145 - val_acc: 0.8220\n",
            "Epoch 97/100\n",
            "24500/24500 [==============================] - 15s 595us/step - loss: 0.0629 - acc: 0.9795 - val_loss: 0.3850 - val_acc: 0.8700\n",
            "Epoch 98/100\n",
            "24500/24500 [==============================] - 15s 598us/step - loss: 0.0581 - acc: 0.9815 - val_loss: 0.4025 - val_acc: 0.8860\n",
            "Epoch 99/100\n",
            "24500/24500 [==============================] - 15s 601us/step - loss: 0.0538 - acc: 0.9825 - val_loss: 0.3019 - val_acc: 0.8860\n",
            "Epoch 100/100\n",
            "24500/24500 [==============================] - 15s 599us/step - loss: 0.0588 - acc: 0.9817 - val_loss: 0.3109 - val_acc: 0.9000\n",
            " F1 Score on Train :  0.9958814174448477\n",
            " F1 Score on Test :  0.8966942148760331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "38dn_sQLzbs8",
        "colab_type": "code",
        "outputId": "d8f40f39-bec9-4527-c992-cbb712366ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5289
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model7 = Sequential()\n",
        "\n",
        "model7.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model7.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model7.add(Conv2D(64, (3, 3),  activation = 'relu'))\n",
        "model7.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model7.add(Conv2D(128, (3, 3),  activation = 'relu'))\n",
        "model7.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model7.add(Conv2D(64, (3, 3)))\n",
        "model7.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model7.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model7.add(Flatten())\n",
        "model7.add(Dense(128, activation='relu'))\n",
        "model7.add(BatchNormalization())\n",
        "model7.add(Dense(64, activation='relu'))\n",
        "model7.add(layers.Dropout(0.7))\n",
        "model7.add(Dense(128, activation='relu'))\n",
        "model7.add(Dense(64, activation='relu'))\n",
        "model7.add(Dense(128, activation='relu'))\n",
        "model7.add(BatchNormalization())\n",
        "model7.add(Dense(64, activation='relu'))\n",
        "model7.add(layers.Dropout(0.7))\n",
        "model7.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model7.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model7.fit(X_train,y_train, epochs=150, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_predicted_train_catDog = model7.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model7.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/150\n",
            "24500/24500 [==============================] - 23s 958us/step - loss: 0.7410 - acc: 0.5317 - val_loss: 0.6850 - val_acc: 0.5900\n",
            "Epoch 2/150\n",
            "24500/24500 [==============================] - 22s 915us/step - loss: 0.6538 - acc: 0.6287 - val_loss: 0.7289 - val_acc: 0.5600\n",
            "Epoch 3/150\n",
            "24500/24500 [==============================] - 23s 919us/step - loss: 0.5606 - acc: 0.7301 - val_loss: 1.1664 - val_acc: 0.5000\n",
            "Epoch 4/150\n",
            "24500/24500 [==============================] - 23s 925us/step - loss: 0.4904 - acc: 0.7820 - val_loss: 0.5841 - val_acc: 0.5940\n",
            "Epoch 5/150\n",
            "24500/24500 [==============================] - 23s 923us/step - loss: 0.4435 - acc: 0.8116 - val_loss: 0.5352 - val_acc: 0.7200\n",
            "Epoch 6/150\n",
            "24500/24500 [==============================] - 23s 928us/step - loss: 0.4148 - acc: 0.8240 - val_loss: 0.6882 - val_acc: 0.6700\n",
            "Epoch 7/150\n",
            "24500/24500 [==============================] - 23s 925us/step - loss: 0.3828 - acc: 0.8417 - val_loss: 0.3365 - val_acc: 0.8540\n",
            "Epoch 8/150\n",
            "24500/24500 [==============================] - 23s 921us/step - loss: 0.3654 - acc: 0.8494 - val_loss: 0.3297 - val_acc: 0.8560\n",
            "Epoch 9/150\n",
            "24500/24500 [==============================] - 23s 928us/step - loss: 0.3500 - acc: 0.8547 - val_loss: 1.0017 - val_acc: 0.6940\n",
            "Epoch 10/150\n",
            "24500/24500 [==============================] - 23s 959us/step - loss: 0.3300 - acc: 0.8682 - val_loss: 0.3696 - val_acc: 0.8260\n",
            "Epoch 11/150\n",
            "24500/24500 [==============================] - 23s 940us/step - loss: 0.3104 - acc: 0.8768 - val_loss: 0.5371 - val_acc: 0.7720\n",
            "Epoch 12/150\n",
            "24500/24500 [==============================] - 23s 929us/step - loss: 0.2898 - acc: 0.8861 - val_loss: 0.3139 - val_acc: 0.8580\n",
            "Epoch 13/150\n",
            "24500/24500 [==============================] - 23s 938us/step - loss: 0.2727 - acc: 0.8947 - val_loss: 0.3603 - val_acc: 0.8480\n",
            "Epoch 14/150\n",
            "24500/24500 [==============================] - 23s 930us/step - loss: 0.2631 - acc: 0.8972 - val_loss: 0.3679 - val_acc: 0.8440\n",
            "Epoch 15/150\n",
            "24500/24500 [==============================] - 23s 937us/step - loss: 0.2660 - acc: 0.8964 - val_loss: 0.7151 - val_acc: 0.7620\n",
            "Epoch 16/150\n",
            "24500/24500 [==============================] - 23s 938us/step - loss: 0.2508 - acc: 0.9037 - val_loss: 0.4106 - val_acc: 0.8500\n",
            "Epoch 17/150\n",
            "24500/24500 [==============================] - 23s 929us/step - loss: 0.2525 - acc: 0.9047 - val_loss: 1.4634 - val_acc: 0.5960\n",
            "Epoch 18/150\n",
            "24500/24500 [==============================] - 23s 933us/step - loss: 0.2404 - acc: 0.9107 - val_loss: 0.2903 - val_acc: 0.8780\n",
            "Epoch 19/150\n",
            "24500/24500 [==============================] - 23s 933us/step - loss: 0.2322 - acc: 0.9142 - val_loss: 0.4881 - val_acc: 0.7700\n",
            "Epoch 20/150\n",
            "24500/24500 [==============================] - 23s 928us/step - loss: 0.2254 - acc: 0.9174 - val_loss: 0.3374 - val_acc: 0.8500\n",
            "Epoch 21/150\n",
            "24500/24500 [==============================] - 23s 929us/step - loss: 0.2222 - acc: 0.9172 - val_loss: 0.3576 - val_acc: 0.8840\n",
            "Epoch 22/150\n",
            "24500/24500 [==============================] - 23s 947us/step - loss: 0.2231 - acc: 0.9206 - val_loss: 0.3177 - val_acc: 0.8720\n",
            "Epoch 23/150\n",
            "24500/24500 [==============================] - 23s 946us/step - loss: 0.2157 - acc: 0.9220 - val_loss: 0.3262 - val_acc: 0.8820\n",
            "Epoch 24/150\n",
            "24500/24500 [==============================] - 23s 933us/step - loss: 0.2168 - acc: 0.9264 - val_loss: 0.3978 - val_acc: 0.8460\n",
            "Epoch 25/150\n",
            "24500/24500 [==============================] - 23s 941us/step - loss: 0.1988 - acc: 0.9291 - val_loss: 0.3063 - val_acc: 0.8780\n",
            "Epoch 26/150\n",
            "24500/24500 [==============================] - 23s 955us/step - loss: 0.1879 - acc: 0.9317 - val_loss: 0.3463 - val_acc: 0.8400\n",
            "Epoch 27/150\n",
            "24500/24500 [==============================] - 23s 948us/step - loss: 0.2016 - acc: 0.9267 - val_loss: 1.3552 - val_acc: 0.7480\n",
            "Epoch 28/150\n",
            "24500/24500 [==============================] - 23s 942us/step - loss: 0.1993 - acc: 0.9314 - val_loss: 2.5129 - val_acc: 0.5920\n",
            "Epoch 29/150\n",
            "24500/24500 [==============================] - 23s 954us/step - loss: 0.1896 - acc: 0.9364 - val_loss: 0.8892 - val_acc: 0.7260\n",
            "Epoch 30/150\n",
            "24500/24500 [==============================] - 23s 943us/step - loss: 0.1969 - acc: 0.9332 - val_loss: 0.3336 - val_acc: 0.8540\n",
            "Epoch 31/150\n",
            "24500/24500 [==============================] - 23s 949us/step - loss: 0.1853 - acc: 0.9388 - val_loss: 0.3301 - val_acc: 0.8900\n",
            "Epoch 32/150\n",
            "24500/24500 [==============================] - 23s 947us/step - loss: 0.1822 - acc: 0.9394 - val_loss: 0.7169 - val_acc: 0.8420\n",
            "Epoch 33/150\n",
            "24500/24500 [==============================] - 23s 947us/step - loss: 0.1703 - acc: 0.9415 - val_loss: 0.3228 - val_acc: 0.8900\n",
            "Epoch 34/150\n",
            "24500/24500 [==============================] - 23s 948us/step - loss: 0.1585 - acc: 0.9434 - val_loss: 0.3414 - val_acc: 0.8740\n",
            "Epoch 35/150\n",
            "24500/24500 [==============================] - 23s 955us/step - loss: 0.1671 - acc: 0.9420 - val_loss: 0.3096 - val_acc: 0.8880\n",
            "Epoch 36/150\n",
            "24500/24500 [==============================] - 23s 934us/step - loss: 0.1565 - acc: 0.9442 - val_loss: 0.4575 - val_acc: 0.8780\n",
            "Epoch 37/150\n",
            "24500/24500 [==============================] - 23s 930us/step - loss: 0.1718 - acc: 0.9464 - val_loss: 0.6767 - val_acc: 0.6420\n",
            "Epoch 38/150\n",
            "24500/24500 [==============================] - 23s 928us/step - loss: 0.1765 - acc: 0.9437 - val_loss: 0.6040 - val_acc: 0.8660\n",
            "Epoch 39/150\n",
            "24500/24500 [==============================] - 23s 930us/step - loss: 0.1735 - acc: 0.9478 - val_loss: 0.3477 - val_acc: 0.8840\n",
            "Epoch 40/150\n",
            "24500/24500 [==============================] - 23s 934us/step - loss: 0.1583 - acc: 0.9523 - val_loss: 0.5901 - val_acc: 0.8300\n",
            "Epoch 41/150\n",
            "24500/24500 [==============================] - 23s 950us/step - loss: 0.1645 - acc: 0.9504 - val_loss: 0.3163 - val_acc: 0.8280\n",
            "Epoch 42/150\n",
            "24500/24500 [==============================] - 24s 963us/step - loss: 0.1469 - acc: 0.9563 - val_loss: 0.4690 - val_acc: 0.8720\n",
            "Epoch 43/150\n",
            "24500/24500 [==============================] - 23s 949us/step - loss: 0.1536 - acc: 0.9526 - val_loss: 0.3550 - val_acc: 0.8560\n",
            "Epoch 44/150\n",
            "24500/24500 [==============================] - 23s 947us/step - loss: 0.1410 - acc: 0.9591 - val_loss: 0.3129 - val_acc: 0.8800\n",
            "Epoch 45/150\n",
            "24500/24500 [==============================] - 23s 950us/step - loss: 0.1327 - acc: 0.9605 - val_loss: 1.0120 - val_acc: 0.8120\n",
            "Epoch 46/150\n",
            "24500/24500 [==============================] - 23s 947us/step - loss: 0.1312 - acc: 0.9624 - val_loss: 0.2395 - val_acc: 0.9000\n",
            "Epoch 47/150\n",
            "24500/24500 [==============================] - 23s 955us/step - loss: 0.1219 - acc: 0.9630 - val_loss: 0.3157 - val_acc: 0.8420\n",
            "Epoch 48/150\n",
            "24500/24500 [==============================] - 23s 956us/step - loss: 0.1213 - acc: 0.9636 - val_loss: 0.9249 - val_acc: 0.8220\n",
            "Epoch 49/150\n",
            "24500/24500 [==============================] - 23s 949us/step - loss: 0.1155 - acc: 0.9641 - val_loss: 0.5331 - val_acc: 0.8240\n",
            "Epoch 50/150\n",
            "24500/24500 [==============================] - 23s 959us/step - loss: 0.1112 - acc: 0.9666 - val_loss: 0.9546 - val_acc: 0.8420\n",
            "Epoch 51/150\n",
            "24500/24500 [==============================] - 23s 953us/step - loss: 0.1081 - acc: 0.9682 - val_loss: 0.3053 - val_acc: 0.8580\n",
            "Epoch 52/150\n",
            "24500/24500 [==============================] - 23s 951us/step - loss: 0.1012 - acc: 0.9706 - val_loss: 0.4046 - val_acc: 0.8740\n",
            "Epoch 53/150\n",
            "24500/24500 [==============================] - 23s 952us/step - loss: 0.1052 - acc: 0.9722 - val_loss: 0.2831 - val_acc: 0.8760\n",
            "Epoch 54/150\n",
            "24500/24500 [==============================] - 23s 941us/step - loss: 0.0943 - acc: 0.9721 - val_loss: 0.9057 - val_acc: 0.7060\n",
            "Epoch 55/150\n",
            "24500/24500 [==============================] - 24s 960us/step - loss: 0.0897 - acc: 0.9755 - val_loss: 1.5534 - val_acc: 0.7740\n",
            "Epoch 56/150\n",
            "24500/24500 [==============================] - 23s 939us/step - loss: 0.0903 - acc: 0.9743 - val_loss: 0.8876 - val_acc: 0.8300\n",
            "Epoch 57/150\n",
            "24500/24500 [==============================] - 23s 926us/step - loss: 0.0823 - acc: 0.9759 - val_loss: 0.7968 - val_acc: 0.8300\n",
            "Epoch 58/150\n",
            "24500/24500 [==============================] - 22s 911us/step - loss: 0.0849 - acc: 0.9750 - val_loss: 1.9173 - val_acc: 0.7980\n",
            "Epoch 59/150\n",
            "24500/24500 [==============================] - 22s 908us/step - loss: 0.0796 - acc: 0.9766 - val_loss: 0.3179 - val_acc: 0.8980\n",
            "Epoch 60/150\n",
            "24500/24500 [==============================] - 22s 910us/step - loss: 0.0784 - acc: 0.9803 - val_loss: 0.4111 - val_acc: 0.9020\n",
            "Epoch 61/150\n",
            "24500/24500 [==============================] - 22s 911us/step - loss: 0.0810 - acc: 0.9797 - val_loss: 0.4277 - val_acc: 0.8800\n",
            "Epoch 62/150\n",
            "24500/24500 [==============================] - 22s 915us/step - loss: 0.0754 - acc: 0.9802 - val_loss: 2.4471 - val_acc: 0.7300\n",
            "Epoch 63/150\n",
            "24500/24500 [==============================] - 22s 916us/step - loss: 0.0722 - acc: 0.9792 - val_loss: 0.4368 - val_acc: 0.8200\n",
            "Epoch 64/150\n",
            "24500/24500 [==============================] - 22s 913us/step - loss: 0.0657 - acc: 0.9821 - val_loss: 0.3043 - val_acc: 0.8920\n",
            "Epoch 65/150\n",
            "24500/24500 [==============================] - 22s 916us/step - loss: 0.0690 - acc: 0.9815 - val_loss: 0.5312 - val_acc: 0.8760\n",
            "Epoch 66/150\n",
            "24500/24500 [==============================] - 22s 915us/step - loss: 0.0660 - acc: 0.9832 - val_loss: 0.9256 - val_acc: 0.7780\n",
            "Epoch 67/150\n",
            "24500/24500 [==============================] - 23s 920us/step - loss: 0.0678 - acc: 0.9825 - val_loss: 0.3721 - val_acc: 0.9000\n",
            "Epoch 68/150\n",
            "24500/24500 [==============================] - 23s 919us/step - loss: 0.0648 - acc: 0.9822 - val_loss: 0.3641 - val_acc: 0.8900\n",
            "Epoch 69/150\n",
            "24500/24500 [==============================] - 23s 923us/step - loss: 0.0611 - acc: 0.9837 - val_loss: 0.3303 - val_acc: 0.9000\n",
            "Epoch 70/150\n",
            "24500/24500 [==============================] - 23s 919us/step - loss: 0.0611 - acc: 0.9835 - val_loss: 0.6671 - val_acc: 0.8580\n",
            "Epoch 71/150\n",
            "24500/24500 [==============================] - 23s 920us/step - loss: 0.0662 - acc: 0.9817 - val_loss: 0.4316 - val_acc: 0.8460\n",
            "Epoch 72/150\n",
            "24500/24500 [==============================] - 23s 921us/step - loss: 0.0617 - acc: 0.9831 - val_loss: 0.2494 - val_acc: 0.8880\n",
            "Epoch 73/150\n",
            "24500/24500 [==============================] - 23s 921us/step - loss: 0.0611 - acc: 0.9842 - val_loss: 3.3483 - val_acc: 0.6280\n",
            "Epoch 74/150\n",
            "24500/24500 [==============================] - 23s 926us/step - loss: 0.0606 - acc: 0.9837 - val_loss: 0.3106 - val_acc: 0.8820\n",
            "Epoch 75/150\n",
            "24500/24500 [==============================] - 23s 924us/step - loss: 0.0529 - acc: 0.9875 - val_loss: 0.4314 - val_acc: 0.8820\n",
            "Epoch 76/150\n",
            "24500/24500 [==============================] - 23s 926us/step - loss: 0.0544 - acc: 0.9872 - val_loss: 0.3932 - val_acc: 0.8860\n",
            "Epoch 77/150\n",
            "24500/24500 [==============================] - 23s 922us/step - loss: 0.0517 - acc: 0.9865 - val_loss: 0.2696 - val_acc: 0.8860\n",
            "Epoch 78/150\n",
            "24500/24500 [==============================] - 23s 957us/step - loss: 0.0538 - acc: 0.9877 - val_loss: 0.5564 - val_acc: 0.8240\n",
            "Epoch 79/150\n",
            "24500/24500 [==============================] - 23s 943us/step - loss: 0.0543 - acc: 0.9871 - val_loss: 0.3263 - val_acc: 0.8720\n",
            "Epoch 80/150\n",
            "24500/24500 [==============================] - 23s 934us/step - loss: 0.0597 - acc: 0.9833 - val_loss: 0.5257 - val_acc: 0.8700\n",
            "Epoch 81/150\n",
            "24500/24500 [==============================] - 23s 935us/step - loss: 0.0574 - acc: 0.9855 - val_loss: 0.9655 - val_acc: 0.8440\n",
            "Epoch 82/150\n",
            "24500/24500 [==============================] - 23s 938us/step - loss: 0.0600 - acc: 0.9826 - val_loss: 0.3239 - val_acc: 0.8700\n",
            "Epoch 83/150\n",
            "24500/24500 [==============================] - 23s 936us/step - loss: 0.0559 - acc: 0.9846 - val_loss: 0.5293 - val_acc: 0.8280\n",
            "Epoch 84/150\n",
            "24500/24500 [==============================] - 23s 936us/step - loss: 0.0504 - acc: 0.9877 - val_loss: 0.5480 - val_acc: 0.8840\n",
            "Epoch 85/150\n",
            "24500/24500 [==============================] - 23s 937us/step - loss: 0.0558 - acc: 0.9853 - val_loss: 0.3545 - val_acc: 0.9000\n",
            "Epoch 86/150\n",
            "24500/24500 [==============================] - 23s 937us/step - loss: 0.0559 - acc: 0.9859 - val_loss: 0.3094 - val_acc: 0.9020\n",
            "Epoch 87/150\n",
            "24500/24500 [==============================] - 23s 934us/step - loss: 0.0537 - acc: 0.9867 - val_loss: 0.3761 - val_acc: 0.8900\n",
            "Epoch 88/150\n",
            "24500/24500 [==============================] - 23s 932us/step - loss: 0.0470 - acc: 0.9876 - val_loss: 1.0718 - val_acc: 0.8160\n",
            "Epoch 89/150\n",
            "24500/24500 [==============================] - 23s 948us/step - loss: 0.0516 - acc: 0.9876 - val_loss: 0.5009 - val_acc: 0.8300\n",
            "Epoch 90/150\n",
            "24500/24500 [==============================] - 23s 944us/step - loss: 0.0538 - acc: 0.9864 - val_loss: 0.7415 - val_acc: 0.8480\n",
            "Epoch 91/150\n",
            "24500/24500 [==============================] - 23s 951us/step - loss: 0.0548 - acc: 0.9862 - val_loss: 0.3798 - val_acc: 0.8920\n",
            "Epoch 92/150\n",
            "24500/24500 [==============================] - 23s 955us/step - loss: 0.0475 - acc: 0.9884 - val_loss: 0.2974 - val_acc: 0.8980\n",
            "Epoch 93/150\n",
            "24500/24500 [==============================] - 23s 958us/step - loss: 0.0517 - acc: 0.9876 - val_loss: 0.4346 - val_acc: 0.9080\n",
            "Epoch 94/150\n",
            "24500/24500 [==============================] - 23s 953us/step - loss: 0.0483 - acc: 0.9890 - val_loss: 1.1648 - val_acc: 0.7580\n",
            "Epoch 95/150\n",
            "24500/24500 [==============================] - 23s 952us/step - loss: 0.0463 - acc: 0.9891 - val_loss: 0.3934 - val_acc: 0.8900\n",
            "Epoch 96/150\n",
            "24500/24500 [==============================] - 23s 945us/step - loss: 0.0497 - acc: 0.9878 - val_loss: 1.7320 - val_acc: 0.8340\n",
            "Epoch 97/150\n",
            "24500/24500 [==============================] - 23s 948us/step - loss: 0.0580 - acc: 0.9868 - val_loss: 0.2633 - val_acc: 0.9040\n",
            "Epoch 98/150\n",
            "24500/24500 [==============================] - 23s 947us/step - loss: 0.0497 - acc: 0.9878 - val_loss: 0.8276 - val_acc: 0.8340\n",
            "Epoch 99/150\n",
            "24500/24500 [==============================] - 23s 944us/step - loss: 0.0465 - acc: 0.9881 - val_loss: 0.4259 - val_acc: 0.8820\n",
            "Epoch 100/150\n",
            "24500/24500 [==============================] - 23s 939us/step - loss: 0.0512 - acc: 0.9869 - val_loss: 0.7044 - val_acc: 0.8980\n",
            "Epoch 101/150\n",
            "24500/24500 [==============================] - 23s 945us/step - loss: 0.0452 - acc: 0.9897 - val_loss: 0.4451 - val_acc: 0.8940\n",
            "Epoch 102/150\n",
            "24500/24500 [==============================] - 23s 941us/step - loss: 0.0512 - acc: 0.9879 - val_loss: 0.7100 - val_acc: 0.8720\n",
            "Epoch 103/150\n",
            "24500/24500 [==============================] - 23s 947us/step - loss: 0.0479 - acc: 0.9885 - val_loss: 0.3619 - val_acc: 0.8860\n",
            "Epoch 104/150\n",
            "24500/24500 [==============================] - 23s 938us/step - loss: 0.0531 - acc: 0.9877 - val_loss: 0.6819 - val_acc: 0.8580\n",
            "Epoch 105/150\n",
            "24500/24500 [==============================] - 23s 928us/step - loss: 0.0503 - acc: 0.9881 - val_loss: 0.5107 - val_acc: 0.8760\n",
            "Epoch 106/150\n",
            "24500/24500 [==============================] - 23s 922us/step - loss: 0.0496 - acc: 0.9893 - val_loss: 0.5695 - val_acc: 0.8840\n",
            "Epoch 107/150\n",
            "24500/24500 [==============================] - 23s 931us/step - loss: 0.0453 - acc: 0.9896 - val_loss: 0.5077 - val_acc: 0.8780\n",
            "Epoch 108/150\n",
            "24500/24500 [==============================] - 23s 929us/step - loss: 0.0435 - acc: 0.9899 - val_loss: 0.4366 - val_acc: 0.8900\n",
            "Epoch 109/150\n",
            "24500/24500 [==============================] - 23s 926us/step - loss: 0.0457 - acc: 0.9907 - val_loss: 0.4456 - val_acc: 0.8460\n",
            "Epoch 110/150\n",
            "24500/24500 [==============================] - 23s 924us/step - loss: 0.0396 - acc: 0.9910 - val_loss: 0.5077 - val_acc: 0.8820\n",
            "Epoch 111/150\n",
            "24500/24500 [==============================] - 23s 931us/step - loss: 0.0461 - acc: 0.9895 - val_loss: 0.8150 - val_acc: 0.8800\n",
            "Epoch 112/150\n",
            "24500/24500 [==============================] - 24s 960us/step - loss: 0.0486 - acc: 0.9899 - val_loss: 0.4307 - val_acc: 0.8760\n",
            "Epoch 113/150\n",
            "24500/24500 [==============================] - 23s 955us/step - loss: 0.0399 - acc: 0.9907 - val_loss: 0.5397 - val_acc: 0.8600\n",
            "Epoch 114/150\n",
            "24500/24500 [==============================] - 23s 943us/step - loss: 0.0499 - acc: 0.9886 - val_loss: 0.5117 - val_acc: 0.8620\n",
            "Epoch 115/150\n",
            "24500/24500 [==============================] - 23s 946us/step - loss: 0.0431 - acc: 0.9904 - val_loss: 0.4786 - val_acc: 0.8760\n",
            "Epoch 116/150\n",
            "24500/24500 [==============================] - 23s 942us/step - loss: 0.0447 - acc: 0.9909 - val_loss: 0.7453 - val_acc: 0.8580\n",
            "Epoch 117/150\n",
            "24500/24500 [==============================] - 23s 953us/step - loss: 0.0487 - acc: 0.9894 - val_loss: 0.2559 - val_acc: 0.8900\n",
            "Epoch 118/150\n",
            "24500/24500 [==============================] - 23s 952us/step - loss: 0.0520 - acc: 0.9891 - val_loss: 2.5144 - val_acc: 0.5940\n",
            "Epoch 119/150\n",
            "24500/24500 [==============================] - 23s 949us/step - loss: 0.0480 - acc: 0.9897 - val_loss: 0.5280 - val_acc: 0.8800\n",
            "Epoch 120/150\n",
            "24500/24500 [==============================] - 23s 952us/step - loss: 0.0486 - acc: 0.9898 - val_loss: 0.5844 - val_acc: 0.8680\n",
            "Epoch 121/150\n",
            "24500/24500 [==============================] - 23s 956us/step - loss: 0.0393 - acc: 0.9919 - val_loss: 0.4539 - val_acc: 0.8680\n",
            "Epoch 122/150\n",
            "24500/24500 [==============================] - 23s 953us/step - loss: 0.0507 - acc: 0.9900 - val_loss: 0.5888 - val_acc: 0.8920\n",
            "Epoch 123/150\n",
            "24500/24500 [==============================] - 23s 938us/step - loss: 0.0434 - acc: 0.9908 - val_loss: 0.9034 - val_acc: 0.8660\n",
            "Epoch 124/150\n",
            "24500/24500 [==============================] - 23s 955us/step - loss: 0.0500 - acc: 0.9895 - val_loss: 1.0836 - val_acc: 0.8640\n",
            "Epoch 125/150\n",
            "24500/24500 [==============================] - 24s 962us/step - loss: 0.0407 - acc: 0.9913 - val_loss: 0.5088 - val_acc: 0.8860\n",
            "Epoch 126/150\n",
            "24500/24500 [==============================] - 24s 971us/step - loss: 0.0433 - acc: 0.9912 - val_loss: 0.6469 - val_acc: 0.8940\n",
            "Epoch 127/150\n",
            "24500/24500 [==============================] - 23s 948us/step - loss: 0.0407 - acc: 0.9913 - val_loss: 0.6770 - val_acc: 0.8920\n",
            "Epoch 128/150\n",
            "24500/24500 [==============================] - 24s 962us/step - loss: 0.0453 - acc: 0.9916 - val_loss: 0.5839 - val_acc: 0.8700\n",
            "Epoch 129/150\n",
            "24500/24500 [==============================] - 23s 939us/step - loss: 0.0434 - acc: 0.9913 - val_loss: 0.3921 - val_acc: 0.8820\n",
            "Epoch 130/150\n",
            "24500/24500 [==============================] - 23s 918us/step - loss: 0.0396 - acc: 0.9920 - val_loss: 0.8295 - val_acc: 0.8700\n",
            "Epoch 131/150\n",
            "24500/24500 [==============================] - 23s 920us/step - loss: 0.0498 - acc: 0.9901 - val_loss: 1.9234 - val_acc: 0.7260\n",
            "Epoch 132/150\n",
            "24500/24500 [==============================] - 22s 916us/step - loss: 0.0407 - acc: 0.9920 - val_loss: 0.4794 - val_acc: 0.8600\n",
            "Epoch 133/150\n",
            "24500/24500 [==============================] - 23s 918us/step - loss: 0.0445 - acc: 0.9915 - val_loss: 0.6358 - val_acc: 0.8820\n",
            "Epoch 134/150\n",
            "24500/24500 [==============================] - 23s 925us/step - loss: 0.0439 - acc: 0.9918 - val_loss: 0.5534 - val_acc: 0.8660\n",
            "Epoch 135/150\n",
            "24500/24500 [==============================] - 22s 916us/step - loss: 0.0407 - acc: 0.9918 - val_loss: 0.5137 - val_acc: 0.8780\n",
            "Epoch 136/150\n",
            "24500/24500 [==============================] - 22s 913us/step - loss: 0.0438 - acc: 0.9916 - val_loss: 0.6703 - val_acc: 0.8820\n",
            "Epoch 137/150\n",
            "24500/24500 [==============================] - 22s 913us/step - loss: 0.0397 - acc: 0.9915 - val_loss: 0.9275 - val_acc: 0.8480\n",
            "Epoch 138/150\n",
            "24500/24500 [==============================] - 22s 913us/step - loss: 0.0435 - acc: 0.9916 - val_loss: 0.3782 - val_acc: 0.8900\n",
            "Epoch 139/150\n",
            "24500/24500 [==============================] - 23s 926us/step - loss: 0.0402 - acc: 0.9913 - val_loss: 0.8559 - val_acc: 0.8880\n",
            "Epoch 140/150\n",
            "24500/24500 [==============================] - 23s 924us/step - loss: 0.0474 - acc: 0.9900 - val_loss: 0.4427 - val_acc: 0.8920\n",
            "Epoch 141/150\n",
            "24500/24500 [==============================] - 23s 925us/step - loss: 0.0497 - acc: 0.9908 - val_loss: 0.5199 - val_acc: 0.8820\n",
            "Epoch 142/150\n",
            "24500/24500 [==============================] - 23s 927us/step - loss: 0.0414 - acc: 0.9917 - val_loss: 0.5257 - val_acc: 0.8600\n",
            "Epoch 143/150\n",
            "24500/24500 [==============================] - 23s 926us/step - loss: 0.0406 - acc: 0.9918 - val_loss: 0.9603 - val_acc: 0.8280\n",
            "Epoch 144/150\n",
            "24500/24500 [==============================] - 23s 923us/step - loss: 0.0510 - acc: 0.9907 - val_loss: 0.3808 - val_acc: 0.8840\n",
            "Epoch 145/150\n",
            "24500/24500 [==============================] - 22s 917us/step - loss: 0.0450 - acc: 0.9920 - val_loss: 0.9298 - val_acc: 0.8880\n",
            "Epoch 146/150\n",
            "24500/24500 [==============================] - 23s 919us/step - loss: 0.0503 - acc: 0.9912 - val_loss: 0.5008 - val_acc: 0.8760\n",
            "Epoch 147/150\n",
            "24500/24500 [==============================] - 23s 924us/step - loss: 0.0424 - acc: 0.9922 - val_loss: 0.5478 - val_acc: 0.8560\n",
            "Epoch 148/150\n",
            "24500/24500 [==============================] - 23s 932us/step - loss: 0.0453 - acc: 0.9916 - val_loss: 0.6513 - val_acc: 0.8760\n",
            "Epoch 149/150\n",
            "24500/24500 [==============================] - 23s 927us/step - loss: 0.0424 - acc: 0.9920 - val_loss: 0.9049 - val_acc: 0.8800\n",
            "Epoch 150/150\n",
            "24500/24500 [==============================] - 23s 923us/step - loss: 0.0544 - acc: 0.9915 - val_loss: 0.5107 - val_acc: 0.8840\n",
            " F1 Score on Train :  0.9916546762589927\n",
            " F1 Score on Test :  0.8657407407407407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hq8F-1CIww8e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "R_jeYChCGPuF",
        "colab_type": "code",
        "outputId": "0b476d89-1491-4a62-a7f1-05fdadb6f221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        }
      },
      "cell_type": "code",
      "source": [
        "model6.summary()\n",
        "model6.save('initialized-model.keras')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_45 (Conv2D)           (None, 62, 62, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 12, 12, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 4, 4, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2, 2, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 89,153\n",
            "Trainable params: 89,025\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "owQKB8B1m8Da",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1847
        },
        "outputId": "fe44f416-fdae-4397-b9d5-153e6a86bcb6"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model8 = Sequential()\n",
        "\n",
        "model8.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model8.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model8.add(Conv2D(64, (3, 3),  activation = 'relu'))\n",
        "model8.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model8.add(Conv2D(128, (3, 3),  activation = 'relu'))\n",
        "model8.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "model8.add(Flatten())\n",
        "model8.add(Dense(128, activation='relu'))\n",
        "model8.add(BatchNormalization())\n",
        "model8.add(layers.Dropout(0.5))\n",
        "model8.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model8.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model8.fit(X_train,y_train, epochs=50, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "\n",
        "\n",
        "y_predicted_train_catDog = model8.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model8.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "24500/24500 [==============================] - 19s 784us/step - loss: 0.5892 - acc: 0.7016 - val_loss: 0.4937 - val_acc: 0.7700\n",
            "Epoch 2/50\n",
            "24500/24500 [==============================] - 14s 585us/step - loss: 0.4465 - acc: 0.7938 - val_loss: 0.6942 - val_acc: 0.6940\n",
            "Epoch 3/50\n",
            "24500/24500 [==============================] - 14s 584us/step - loss: 0.3807 - acc: 0.8328 - val_loss: 0.4145 - val_acc: 0.8060\n",
            "Epoch 4/50\n",
            "24500/24500 [==============================] - 14s 582us/step - loss: 0.3237 - acc: 0.8591 - val_loss: 0.2984 - val_acc: 0.8900\n",
            "Epoch 5/50\n",
            "24500/24500 [==============================] - 14s 583us/step - loss: 0.2864 - acc: 0.8792 - val_loss: 0.3655 - val_acc: 0.8380\n",
            "Epoch 6/50\n",
            "24500/24500 [==============================] - 14s 585us/step - loss: 0.2455 - acc: 0.8983 - val_loss: 0.3173 - val_acc: 0.8740\n",
            "Epoch 7/50\n",
            "24500/24500 [==============================] - 14s 583us/step - loss: 0.2099 - acc: 0.9138 - val_loss: 0.3596 - val_acc: 0.8620\n",
            "Epoch 8/50\n",
            "24500/24500 [==============================] - 14s 581us/step - loss: 0.1772 - acc: 0.9276 - val_loss: 1.5782 - val_acc: 0.6680\n",
            "Epoch 9/50\n",
            "24500/24500 [==============================] - 14s 581us/step - loss: 0.1504 - acc: 0.9397 - val_loss: 0.7709 - val_acc: 0.7660\n",
            "Epoch 10/50\n",
            "24500/24500 [==============================] - 14s 584us/step - loss: 0.1353 - acc: 0.9457 - val_loss: 0.4557 - val_acc: 0.8340\n",
            "Epoch 11/50\n",
            "24500/24500 [==============================] - 14s 584us/step - loss: 0.1188 - acc: 0.9541 - val_loss: 0.4620 - val_acc: 0.8640\n",
            "Epoch 12/50\n",
            "24500/24500 [==============================] - 14s 582us/step - loss: 0.1027 - acc: 0.9606 - val_loss: 0.7212 - val_acc: 0.8120\n",
            "Epoch 13/50\n",
            "24500/24500 [==============================] - 14s 584us/step - loss: 0.1012 - acc: 0.9608 - val_loss: 0.5878 - val_acc: 0.8360\n",
            "Epoch 14/50\n",
            "24500/24500 [==============================] - 14s 584us/step - loss: 0.0869 - acc: 0.9672 - val_loss: 0.5636 - val_acc: 0.8560\n",
            "Epoch 15/50\n",
            "24500/24500 [==============================] - 14s 587us/step - loss: 0.0812 - acc: 0.9699 - val_loss: 1.0648 - val_acc: 0.8100\n",
            "Epoch 16/50\n",
            "24500/24500 [==============================] - 14s 587us/step - loss: 0.0739 - acc: 0.9726 - val_loss: 0.5971 - val_acc: 0.8380\n",
            "Epoch 17/50\n",
            "24500/24500 [==============================] - 14s 584us/step - loss: 0.0715 - acc: 0.9722 - val_loss: 0.5873 - val_acc: 0.8640\n",
            "Epoch 18/50\n",
            "24500/24500 [==============================] - 14s 585us/step - loss: 0.0681 - acc: 0.9753 - val_loss: 0.6764 - val_acc: 0.8560\n",
            "Epoch 19/50\n",
            "24500/24500 [==============================] - 14s 589us/step - loss: 0.0622 - acc: 0.9776 - val_loss: 0.6733 - val_acc: 0.8900\n",
            "Epoch 20/50\n",
            "24500/24500 [==============================] - 14s 581us/step - loss: 0.0641 - acc: 0.9764 - val_loss: 0.5813 - val_acc: 0.8640\n",
            "Epoch 21/50\n",
            "24500/24500 [==============================] - 14s 587us/step - loss: 0.0628 - acc: 0.9778 - val_loss: 0.5906 - val_acc: 0.8720\n",
            "Epoch 22/50\n",
            "24500/24500 [==============================] - 14s 582us/step - loss: 0.0581 - acc: 0.9803 - val_loss: 0.5297 - val_acc: 0.8700\n",
            "Epoch 23/50\n",
            "24500/24500 [==============================] - 14s 586us/step - loss: 0.0520 - acc: 0.9807 - val_loss: 0.5168 - val_acc: 0.8800\n",
            "Epoch 24/50\n",
            "24500/24500 [==============================] - 14s 584us/step - loss: 0.0479 - acc: 0.9829 - val_loss: 0.5081 - val_acc: 0.8500\n",
            "Epoch 25/50\n",
            "24500/24500 [==============================] - 14s 588us/step - loss: 0.0503 - acc: 0.9810 - val_loss: 0.6085 - val_acc: 0.8620\n",
            "Epoch 26/50\n",
            "24500/24500 [==============================] - 14s 583us/step - loss: 0.0489 - acc: 0.9820 - val_loss: 1.3500 - val_acc: 0.7820\n",
            "Epoch 27/50\n",
            "24500/24500 [==============================] - 14s 587us/step - loss: 0.0424 - acc: 0.9845 - val_loss: 1.0315 - val_acc: 0.8180\n",
            "Epoch 28/50\n",
            "24500/24500 [==============================] - 14s 586us/step - loss: 0.0435 - acc: 0.9849 - val_loss: 0.5249 - val_acc: 0.8700\n",
            "Epoch 29/50\n",
            "24500/24500 [==============================] - 14s 587us/step - loss: 0.0424 - acc: 0.9841 - val_loss: 0.7626 - val_acc: 0.8540\n",
            "Epoch 30/50\n",
            "24500/24500 [==============================] - 14s 584us/step - loss: 0.0439 - acc: 0.9838 - val_loss: 0.6831 - val_acc: 0.8580\n",
            "Epoch 31/50\n",
            "24500/24500 [==============================] - 14s 585us/step - loss: 0.0450 - acc: 0.9848 - val_loss: 0.6946 - val_acc: 0.8580\n",
            "Epoch 32/50\n",
            "24500/24500 [==============================] - 14s 579us/step - loss: 0.0423 - acc: 0.9840 - val_loss: 0.6366 - val_acc: 0.8680\n",
            "Epoch 33/50\n",
            "24500/24500 [==============================] - 14s 575us/step - loss: 0.0441 - acc: 0.9846 - val_loss: 0.7567 - val_acc: 0.8540\n",
            "Epoch 34/50\n",
            "24500/24500 [==============================] - 14s 571us/step - loss: 0.0381 - acc: 0.9860 - val_loss: 0.7970 - val_acc: 0.8620\n",
            "Epoch 35/50\n",
            "24500/24500 [==============================] - 14s 572us/step - loss: 0.0385 - acc: 0.9862 - val_loss: 0.9800 - val_acc: 0.8000\n",
            "Epoch 36/50\n",
            "24500/24500 [==============================] - 14s 572us/step - loss: 0.0344 - acc: 0.9877 - val_loss: 0.7325 - val_acc: 0.8700\n",
            "Epoch 37/50\n",
            "24500/24500 [==============================] - 14s 571us/step - loss: 0.0367 - acc: 0.9878 - val_loss: 0.9111 - val_acc: 0.8500\n",
            "Epoch 38/50\n",
            "24500/24500 [==============================] - 14s 573us/step - loss: 0.0332 - acc: 0.9882 - val_loss: 0.8082 - val_acc: 0.8540\n",
            "Epoch 39/50\n",
            "24500/24500 [==============================] - 14s 572us/step - loss: 0.0366 - acc: 0.9874 - val_loss: 1.0549 - val_acc: 0.8380\n",
            "Epoch 40/50\n",
            "24500/24500 [==============================] - 14s 571us/step - loss: 0.0365 - acc: 0.9864 - val_loss: 0.7633 - val_acc: 0.8500\n",
            "Epoch 41/50\n",
            "24500/24500 [==============================] - 14s 572us/step - loss: 0.0369 - acc: 0.9882 - val_loss: 0.7527 - val_acc: 0.8620\n",
            "Epoch 42/50\n",
            "24500/24500 [==============================] - 14s 567us/step - loss: 0.0325 - acc: 0.9889 - val_loss: 0.8090 - val_acc: 0.8500\n",
            "Epoch 43/50\n",
            "24500/24500 [==============================] - 14s 571us/step - loss: 0.0335 - acc: 0.9891 - val_loss: 0.8211 - val_acc: 0.8700\n",
            "Epoch 44/50\n",
            "24500/24500 [==============================] - 14s 570us/step - loss: 0.0296 - acc: 0.9895 - val_loss: 0.7800 - val_acc: 0.8620\n",
            "Epoch 45/50\n",
            "24500/24500 [==============================] - 14s 571us/step - loss: 0.0354 - acc: 0.9886 - val_loss: 0.7951 - val_acc: 0.8420\n",
            "Epoch 46/50\n",
            "24500/24500 [==============================] - 14s 572us/step - loss: 0.0329 - acc: 0.9883 - val_loss: 0.6238 - val_acc: 0.8540\n",
            "Epoch 47/50\n",
            "24500/24500 [==============================] - 14s 570us/step - loss: 0.0320 - acc: 0.9897 - val_loss: 0.9151 - val_acc: 0.8700\n",
            "Epoch 48/50\n",
            "24500/24500 [==============================] - 14s 572us/step - loss: 0.0302 - acc: 0.9892 - val_loss: 0.7676 - val_acc: 0.8720\n",
            "Epoch 49/50\n",
            "24500/24500 [==============================] - 14s 574us/step - loss: 0.0299 - acc: 0.9891 - val_loss: 0.8349 - val_acc: 0.8420\n",
            "Epoch 50/50\n",
            "24500/24500 [==============================] - 14s 573us/step - loss: 0.0305 - acc: 0.9895 - val_loss: 0.7490 - val_acc: 0.8780\n",
            " F1 Score on Train :  0.9984092670391974\n",
            " F1 Score on Test :  0.871578947368421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8b6IZuHeC50d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1847
        },
        "outputId": "14c2042b-a472-45dc-bcef-059261b7308a"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model9 = Sequential()\n",
        "\n",
        "model9.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model9.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model9.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model9.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model9.add(Conv2D(64, (3, 3),  activation = 'relu'))\n",
        "model9.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model9.add(Flatten())\n",
        "model9.add(layers.Dropout(0.5))\n",
        "model9.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model9.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model9.fit(X_train,y_train, epochs=50, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "y_predicted_train_catDog = model9.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model9.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "24500/24500 [==============================] - 10s 392us/step - loss: 0.8068 - acc: 0.5329 - val_loss: 0.6822 - val_acc: 0.5500\n",
            "Epoch 2/50\n",
            "24500/24500 [==============================] - 9s 375us/step - loss: 0.6945 - acc: 0.5469 - val_loss: 0.6893 - val_acc: 0.5440\n",
            "Epoch 3/50\n",
            "24500/24500 [==============================] - 9s 375us/step - loss: 0.6866 - acc: 0.5610 - val_loss: 0.6724 - val_acc: 0.5860\n",
            "Epoch 4/50\n",
            "24500/24500 [==============================] - 9s 375us/step - loss: 0.6753 - acc: 0.5987 - val_loss: 0.6458 - val_acc: 0.6140\n",
            "Epoch 5/50\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 0.6331 - acc: 0.6511 - val_loss: 0.5889 - val_acc: 0.7000\n",
            "Epoch 6/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.5932 - acc: 0.6903 - val_loss: 0.5829 - val_acc: 0.7080\n",
            "Epoch 7/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.5642 - acc: 0.7168 - val_loss: 0.4952 - val_acc: 0.7860\n",
            "Epoch 8/50\n",
            "24500/24500 [==============================] - 9s 370us/step - loss: 0.5401 - acc: 0.7321 - val_loss: 0.5162 - val_acc: 0.7520\n",
            "Epoch 9/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.5286 - acc: 0.7443 - val_loss: 0.4733 - val_acc: 0.7980\n",
            "Epoch 10/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.5183 - acc: 0.7459 - val_loss: 0.4845 - val_acc: 0.7840\n",
            "Epoch 11/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.5180 - acc: 0.7511 - val_loss: 0.4787 - val_acc: 0.7840\n",
            "Epoch 12/50\n",
            "24500/24500 [==============================] - 9s 373us/step - loss: 0.5108 - acc: 0.7567 - val_loss: 0.4374 - val_acc: 0.8140\n",
            "Epoch 13/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.4974 - acc: 0.7664 - val_loss: 0.5177 - val_acc: 0.7460\n",
            "Epoch 14/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.4977 - acc: 0.7651 - val_loss: 0.4351 - val_acc: 0.8200\n",
            "Epoch 15/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.4867 - acc: 0.7743 - val_loss: 0.4426 - val_acc: 0.8160\n",
            "Epoch 16/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.4883 - acc: 0.7719 - val_loss: 0.4819 - val_acc: 0.7640\n",
            "Epoch 17/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.4965 - acc: 0.7718 - val_loss: 0.4329 - val_acc: 0.8160\n",
            "Epoch 18/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.4932 - acc: 0.7755 - val_loss: 0.5191 - val_acc: 0.7540\n",
            "Epoch 19/50\n",
            "24500/24500 [==============================] - 9s 370us/step - loss: 0.4946 - acc: 0.7725 - val_loss: 0.4654 - val_acc: 0.7800\n",
            "Epoch 20/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.4870 - acc: 0.7740 - val_loss: 0.4328 - val_acc: 0.8060\n",
            "Epoch 21/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.4884 - acc: 0.7755 - val_loss: 0.4493 - val_acc: 0.8040\n",
            "Epoch 22/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.4917 - acc: 0.7703 - val_loss: 0.4474 - val_acc: 0.7960\n",
            "Epoch 23/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.4942 - acc: 0.7724 - val_loss: 0.4699 - val_acc: 0.7900\n",
            "Epoch 24/50\n",
            "24500/24500 [==============================] - 9s 370us/step - loss: 0.4932 - acc: 0.7726 - val_loss: 0.4245 - val_acc: 0.8120\n",
            "Epoch 25/50\n",
            "24500/24500 [==============================] - 9s 370us/step - loss: 0.4899 - acc: 0.7775 - val_loss: 0.4280 - val_acc: 0.8180\n",
            "Epoch 26/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.4966 - acc: 0.7716 - val_loss: 0.4504 - val_acc: 0.8240\n",
            "Epoch 27/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.4888 - acc: 0.7750 - val_loss: 0.4474 - val_acc: 0.8140\n",
            "Epoch 28/50\n",
            "24500/24500 [==============================] - 9s 370us/step - loss: 0.4933 - acc: 0.7729 - val_loss: 0.5174 - val_acc: 0.7500\n",
            "Epoch 29/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.4938 - acc: 0.7700 - val_loss: 0.4547 - val_acc: 0.8020\n",
            "Epoch 30/50\n",
            "24500/24500 [==============================] - 9s 370us/step - loss: 0.4912 - acc: 0.7724 - val_loss: 0.4746 - val_acc: 0.7840\n",
            "Epoch 31/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.4995 - acc: 0.7680 - val_loss: 0.4499 - val_acc: 0.8160\n",
            "Epoch 32/50\n",
            "24500/24500 [==============================] - 9s 373us/step - loss: 0.5008 - acc: 0.7677 - val_loss: 0.5335 - val_acc: 0.7540\n",
            "Epoch 33/50\n",
            "24500/24500 [==============================] - 9s 370us/step - loss: 0.4964 - acc: 0.7740 - val_loss: 0.4433 - val_acc: 0.8020\n",
            "Epoch 34/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.5014 - acc: 0.7676 - val_loss: 0.4979 - val_acc: 0.7720\n",
            "Epoch 35/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.5056 - acc: 0.7701 - val_loss: 0.4887 - val_acc: 0.8040\n",
            "Epoch 36/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.5116 - acc: 0.7636 - val_loss: 0.4849 - val_acc: 0.7820\n",
            "Epoch 37/50\n",
            "24500/24500 [==============================] - 9s 370us/step - loss: 0.5075 - acc: 0.7653 - val_loss: 0.5027 - val_acc: 0.8020\n",
            "Epoch 38/50\n",
            "24500/24500 [==============================] - 9s 369us/step - loss: 0.5017 - acc: 0.7696 - val_loss: 0.5710 - val_acc: 0.7360\n",
            "Epoch 39/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.5140 - acc: 0.7645 - val_loss: 0.5445 - val_acc: 0.7740\n",
            "Epoch 40/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.5147 - acc: 0.7651 - val_loss: 0.4914 - val_acc: 0.7760\n",
            "Epoch 41/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.5368 - acc: 0.7538 - val_loss: 0.5358 - val_acc: 0.7620\n",
            "Epoch 42/50\n",
            "24500/24500 [==============================] - 9s 370us/step - loss: 0.5293 - acc: 0.7565 - val_loss: 0.5832 - val_acc: 0.6980\n",
            "Epoch 43/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.5255 - acc: 0.7600 - val_loss: 0.5211 - val_acc: 0.7660\n",
            "Epoch 44/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.5272 - acc: 0.7566 - val_loss: 0.5018 - val_acc: 0.7840\n",
            "Epoch 45/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.5341 - acc: 0.7490 - val_loss: 0.5286 - val_acc: 0.7860\n",
            "Epoch 46/50\n",
            "24500/24500 [==============================] - 9s 371us/step - loss: 0.5462 - acc: 0.7478 - val_loss: 0.5099 - val_acc: 0.7940\n",
            "Epoch 47/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.5468 - acc: 0.7446 - val_loss: 0.5392 - val_acc: 0.7620\n",
            "Epoch 48/50\n",
            "24500/24500 [==============================] - 9s 372us/step - loss: 0.5569 - acc: 0.7379 - val_loss: 0.4595 - val_acc: 0.7960\n",
            "Epoch 49/50\n",
            "24500/24500 [==============================] - 9s 368us/step - loss: 0.5779 - acc: 0.7312 - val_loss: 0.4984 - val_acc: 0.7760\n",
            "Epoch 50/50\n",
            "24500/24500 [==============================] - 9s 369us/step - loss: 0.5745 - acc: 0.7259 - val_loss: 0.5432 - val_acc: 0.7880\n",
            " F1 Score on Train :  0.7119331854857737\n",
            " F1 Score on Test :  0.7511737089201876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lej4mVbJJq80",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "i7sSz9mlJrqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1882
        },
        "outputId": "8c23ff9d-e242-4972-cdec-a47f4a80c5f2"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model10 = Sequential()\n",
        "\n",
        "model10.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model10.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model10.add(Conv2D(64, (3, 3),  activation = 'relu'))\n",
        "model10.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model10.add(Conv2D(64, (3, 3),  activation = 'relu'))\n",
        "model10.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model10.add(Flatten())\n",
        "model10.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model10.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model10.fit(X_train,y_train, epochs=50, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "y_predicted_train_catDog = model10.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model10.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "24500/24500 [==============================] - 11s 439us/step - loss: 8.0653 - acc: 0.4993 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 2/50\n",
            "24500/24500 [==============================] - 10s 409us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 3/50\n",
            "24500/24500 [==============================] - 10s 406us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 4/50\n",
            "24500/24500 [==============================] - 10s 403us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 5/50\n",
            "24500/24500 [==============================] - 10s 401us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 6/50\n",
            "24500/24500 [==============================] - 10s 399us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 7/50\n",
            "24500/24500 [==============================] - 10s 397us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 8/50\n",
            "24500/24500 [==============================] - 10s 395us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 9/50\n",
            "24500/24500 [==============================] - 10s 395us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 10/50\n",
            "24500/24500 [==============================] - 10s 393us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 11/50\n",
            "24500/24500 [==============================] - 10s 392us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 12/50\n",
            "24500/24500 [==============================] - 10s 392us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 13/50\n",
            "24500/24500 [==============================] - 10s 389us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 14/50\n",
            "24500/24500 [==============================] - 10s 393us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 15/50\n",
            "24500/24500 [==============================] - 10s 392us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 16/50\n",
            "24500/24500 [==============================] - 10s 391us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 17/50\n",
            "24500/24500 [==============================] - 10s 392us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 18/50\n",
            "24500/24500 [==============================] - 10s 392us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 19/50\n",
            "24500/24500 [==============================] - 10s 394us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 20/50\n",
            "24500/24500 [==============================] - 10s 393us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 21/50\n",
            "24500/24500 [==============================] - 10s 392us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 22/50\n",
            "24500/24500 [==============================] - 10s 394us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 23/50\n",
            "24500/24500 [==============================] - 10s 391us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 24/50\n",
            "24500/24500 [==============================] - 10s 392us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 25/50\n",
            "24500/24500 [==============================] - 10s 391us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 26/50\n",
            "24500/24500 [==============================] - 10s 390us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 27/50\n",
            "24500/24500 [==============================] - 10s 390us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 28/50\n",
            "24500/24500 [==============================] - 10s 391us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 29/50\n",
            "24500/24500 [==============================] - 10s 392us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 30/50\n",
            "24500/24500 [==============================] - 10s 391us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 31/50\n",
            "24500/24500 [==============================] - 10s 391us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 32/50\n",
            "24500/24500 [==============================] - 10s 392us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 33/50\n",
            "24500/24500 [==============================] - 9s 388us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 34/50\n",
            "24500/24500 [==============================] - 10s 390us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 35/50\n",
            "24500/24500 [==============================] - 10s 392us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 36/50\n",
            "24500/24500 [==============================] - 10s 391us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 37/50\n",
            "24500/24500 [==============================] - 10s 391us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 38/50\n",
            "24500/24500 [==============================] - 10s 389us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 39/50\n",
            "24500/24500 [==============================] - 10s 389us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 40/50\n",
            "24500/24500 [==============================] - 9s 388us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 41/50\n",
            "24500/24500 [==============================] - 10s 390us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 42/50\n",
            "24500/24500 [==============================] - 10s 390us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 43/50\n",
            "24500/24500 [==============================] - 9s 388us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 44/50\n",
            "24500/24500 [==============================] - 10s 398us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 45/50\n",
            "24500/24500 [==============================] - 9s 387us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 46/50\n",
            "24500/24500 [==============================] - 10s 389us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 47/50\n",
            "24500/24500 [==============================] - 10s 388us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 48/50\n",
            "24500/24500 [==============================] - 10s 391us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 49/50\n",
            "24500/24500 [==============================] - 10s 390us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 50/50\n",
            "24500/24500 [==============================] - 10s 388us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            " F1 Score on Train :  0.0\n",
            " F1 Score on Test :  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-h_HzNBxBmNg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "64y1v4iDk8yx",
        "colab_type": "code",
        "outputId": "63c9c66b-22cc-4f34-fe86-2fdb72008513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "cell_type": "code",
      "source": [
        "model10.summary()\n",
        "model10.save('10initialized-model.keras')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 62, 62, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 12, 12, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 2305      \n",
            "=================================================================\n",
            "Total params: 58,049\n",
            "Trainable params: 58,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ktGluWjtKHuI",
        "colab_type": "code",
        "outputId": "7292dab0-369b-482f-db37-b1782cc18e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "X = pd.read_csv(\"X.csv\", sep = ' ', header = None , dtype = float)\n",
        "X = X.values\n",
        "y= pd.read_csv(\"y_bush_vs_others.csv\" , header = None)\n",
        "y_bush = y.values.ravel()\n",
        "y= pd.read_csv(\"y_williams_vs_others.csv\" , header = None)\n",
        "y_williams = y.values.ravel()\n",
        "print(\"X Shape\",X.shape)\n",
        "print(\"# of Bush's photos\",np.sum(y_bush))\n",
        "print(\"# of Bush's photos\",np.sum(y_williams))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_reshaped=X.reshape((X.shape[0],64,64,1))\n",
        "X_reshaped.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Shape (13233, 4096)\n",
            "# of Bush's photos 530\n",
            "# of Bush's photos 52\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13233, 64, 64, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "LCr4_QsxG-ON",
        "colab_type": "code",
        "outputId": "220ff69d-3b02-4a75-bcaf-9874f6f862d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5289
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "modelForBush=load_model(\"7initialized-model.keras\")\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_reshaped, \n",
        "             y_bush,shuffle = True ,test_size= 1./3, random_state=6099, stratify  = y_bush) # A20396099\n",
        "\n",
        "\n",
        "modelForBush.fit(X_train_b,y_train_b, epochs=150, batch_size=32, validation_data = (X_test_b, y_test_b ) )\n",
        "\n",
        "y_predicted_train_bush = modelForBush.predict_classes(X_train_b) \n",
        "y_predicted_test_bush = modelForBush.predict_classes(X_test_b) \n",
        "result_f1_train_bush_E70=f1_score(y_train_b, y_predicted_train_bush)\n",
        "result_f1_test_bush_E70=f1_score(y_test_b, y_predicted_test_bush)\n",
        "print(\"Bush F1 Score on Train : \",result_f1_train_bush_E70)\n",
        "print(\"Bush F1 Score on Test : \",result_f1_test_bush_E70)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8822 samples, validate on 4411 samples\n",
            "Epoch 1/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.3605 - acc: 0.9468 - val_loss: 0.6419 - val_acc: 0.9599\n",
            "Epoch 2/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.1911 - acc: 0.9595 - val_loss: 0.2820 - val_acc: 0.9599\n",
            "Epoch 3/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.1668 - acc: 0.9613 - val_loss: 0.2143 - val_acc: 0.9599\n",
            "Epoch 4/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.1361 - acc: 0.9621 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 5/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.1107 - acc: 0.9684 - val_loss: 0.2927 - val_acc: 0.8939\n",
            "Epoch 6/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.1016 - acc: 0.9723 - val_loss: 0.1839 - val_acc: 0.9599\n",
            "Epoch 7/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0844 - acc: 0.9778 - val_loss: 0.0660 - val_acc: 0.9803\n",
            "Epoch 8/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0776 - acc: 0.9763 - val_loss: 0.1421 - val_acc: 0.9800\n",
            "Epoch 9/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0741 - acc: 0.9763 - val_loss: 0.0906 - val_acc: 0.9760\n",
            "Epoch 10/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0729 - acc: 0.9776 - val_loss: 0.6245 - val_acc: 0.4641\n",
            "Epoch 11/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0635 - acc: 0.9785 - val_loss: 0.3490 - val_acc: 0.9247\n",
            "Epoch 12/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0613 - acc: 0.9811 - val_loss: 0.1387 - val_acc: 0.9678\n",
            "Epoch 13/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0639 - acc: 0.9864 - val_loss: 3.0201 - val_acc: 0.1870\n",
            "Epoch 14/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0597 - acc: 0.9837 - val_loss: 11.2706 - val_acc: 0.0401\n",
            "Epoch 15/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0507 - acc: 0.9859 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 16/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0549 - acc: 0.9825 - val_loss: 11.9207 - val_acc: 0.0451\n",
            "Epoch 17/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0542 - acc: 0.9842 - val_loss: 0.5047 - val_acc: 0.9603\n",
            "Epoch 18/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0507 - acc: 0.9857 - val_loss: 0.6000 - val_acc: 0.9626\n",
            "Epoch 19/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0502 - acc: 0.9876 - val_loss: 0.2922 - val_acc: 0.8978\n",
            "Epoch 20/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0569 - acc: 0.9881 - val_loss: 0.6273 - val_acc: 0.9599\n",
            "Epoch 21/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0461 - acc: 0.9896 - val_loss: 0.3136 - val_acc: 0.8953\n",
            "Epoch 22/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0369 - acc: 0.9910 - val_loss: 0.6403 - val_acc: 0.9599\n",
            "Epoch 23/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0512 - acc: 0.9879 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 24/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0360 - acc: 0.9913 - val_loss: 0.5944 - val_acc: 0.9606\n",
            "Epoch 25/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0484 - acc: 0.9886 - val_loss: 13.9361 - val_acc: 0.0424\n",
            "Epoch 26/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0390 - acc: 0.9900 - val_loss: 0.5250 - val_acc: 0.9599\n",
            "Epoch 27/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0366 - acc: 0.9909 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 28/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0355 - acc: 0.9915 - val_loss: 2.4030 - val_acc: 0.4681\n",
            "Epoch 29/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0339 - acc: 0.9922 - val_loss: 8.3543 - val_acc: 0.1206\n",
            "Epoch 30/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0502 - acc: 0.9909 - val_loss: 0.4784 - val_acc: 0.9696\n",
            "Epoch 31/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0355 - acc: 0.9927 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 32/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0402 - acc: 0.9924 - val_loss: 0.1642 - val_acc: 0.8959\n",
            "Epoch 33/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0476 - acc: 0.9922 - val_loss: 0.0664 - val_acc: 0.9798\n",
            "Epoch 34/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0398 - acc: 0.9938 - val_loss: 11.7150 - val_acc: 0.0515\n",
            "Epoch 35/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0418 - acc: 0.9920 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 36/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0387 - acc: 0.9901 - val_loss: 12.9194 - val_acc: 0.0401\n",
            "Epoch 37/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0305 - acc: 0.9948 - val_loss: 0.4445 - val_acc: 0.6749\n",
            "Epoch 38/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0351 - acc: 0.9924 - val_loss: 14.3274 - val_acc: 0.0401\n",
            "Epoch 39/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0352 - acc: 0.9947 - val_loss: 0.6395 - val_acc: 0.9603\n",
            "Epoch 40/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0429 - acc: 0.9925 - val_loss: 0.2490 - val_acc: 0.9832\n",
            "Epoch 41/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0413 - acc: 0.9926 - val_loss: 1.6849 - val_acc: 0.4845\n",
            "Epoch 42/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0254 - acc: 0.9958 - val_loss: 0.2225 - val_acc: 0.9356\n",
            "Epoch 43/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0363 - acc: 0.9941 - val_loss: 0.1079 - val_acc: 0.9748\n",
            "Epoch 44/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0287 - acc: 0.9954 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 45/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0451 - acc: 0.9944 - val_loss: 1.0989 - val_acc: 0.6676\n",
            "Epoch 46/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0380 - acc: 0.9938 - val_loss: 0.1259 - val_acc: 0.9782\n",
            "Epoch 47/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0224 - acc: 0.9956 - val_loss: 4.7535 - val_acc: 0.1714\n",
            "Epoch 48/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0202 - acc: 0.9957 - val_loss: 0.1696 - val_acc: 0.9560\n",
            "Epoch 49/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0142 - acc: 0.9977 - val_loss: 0.1576 - val_acc: 0.9272\n",
            "Epoch 50/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0303 - acc: 0.9948 - val_loss: 0.4865 - val_acc: 0.9683\n",
            "Epoch 51/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0302 - acc: 0.9959 - val_loss: 0.6144 - val_acc: 0.9610\n",
            "Epoch 52/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0194 - acc: 0.9967 - val_loss: 0.5970 - val_acc: 0.9606\n",
            "Epoch 53/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0405 - acc: 0.9955 - val_loss: 0.4275 - val_acc: 0.9732\n",
            "Epoch 54/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0487 - acc: 0.9939 - val_loss: 10.8444 - val_acc: 0.0589\n",
            "Epoch 55/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0326 - acc: 0.9952 - val_loss: 0.3194 - val_acc: 0.9687\n",
            "Epoch 56/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0243 - acc: 0.9952 - val_loss: 0.1799 - val_acc: 0.9744\n",
            "Epoch 57/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0382 - acc: 0.9943 - val_loss: 0.1946 - val_acc: 0.9773\n",
            "Epoch 58/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0207 - acc: 0.9963 - val_loss: 0.8638 - val_acc: 0.7991\n",
            "Epoch 59/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0149 - acc: 0.9975 - val_loss: 0.9310 - val_acc: 0.8996\n",
            "Epoch 60/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0342 - acc: 0.9938 - val_loss: 4.5822 - val_acc: 0.1784\n",
            "Epoch 61/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0223 - acc: 0.9963 - val_loss: 0.2779 - val_acc: 0.9760\n",
            "Epoch 62/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0163 - acc: 0.9982 - val_loss: 0.1756 - val_acc: 0.9259\n",
            "Epoch 63/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0257 - acc: 0.9965 - val_loss: 0.1731 - val_acc: 0.9719\n",
            "Epoch 64/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0319 - acc: 0.9955 - val_loss: 5.4368 - val_acc: 0.3242\n",
            "Epoch 65/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0357 - acc: 0.9955 - val_loss: 10.0962 - val_acc: 0.1236\n",
            "Epoch 66/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0329 - acc: 0.9949 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 67/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0150 - acc: 0.9977 - val_loss: 0.1844 - val_acc: 0.9748\n",
            "Epoch 68/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0232 - acc: 0.9966 - val_loss: 0.9416 - val_acc: 0.8962\n",
            "Epoch 69/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0099 - acc: 0.9984 - val_loss: 10.0043 - val_acc: 0.1510\n",
            "Epoch 70/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0200 - acc: 0.9973 - val_loss: 0.6340 - val_acc: 0.9599\n",
            "Epoch 71/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0152 - acc: 0.9976 - val_loss: 0.2729 - val_acc: 0.9356\n",
            "Epoch 72/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0165 - acc: 0.9977 - val_loss: 0.5054 - val_acc: 0.9637\n",
            "Epoch 73/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0183 - acc: 0.9977 - val_loss: 5.6159 - val_acc: 0.3480\n",
            "Epoch 74/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0261 - acc: 0.9964 - val_loss: 0.2946 - val_acc: 0.9732\n",
            "Epoch 75/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0323 - acc: 0.9964 - val_loss: 0.2644 - val_acc: 0.9748\n",
            "Epoch 76/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0155 - acc: 0.9982 - val_loss: 0.2126 - val_acc: 0.9816\n",
            "Epoch 77/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0284 - acc: 0.9958 - val_loss: 0.4196 - val_acc: 0.9644\n",
            "Epoch 78/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0381 - acc: 0.9954 - val_loss: 0.4727 - val_acc: 0.9621\n",
            "Epoch 79/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0224 - acc: 0.9976 - val_loss: 0.8123 - val_acc: 0.8805\n",
            "Epoch 80/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0225 - acc: 0.9967 - val_loss: 5.0657 - val_acc: 0.4142\n",
            "Epoch 81/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0160 - acc: 0.9982 - val_loss: 4.0103 - val_acc: 0.4770\n",
            "Epoch 82/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0218 - acc: 0.9975 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 83/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0213 - acc: 0.9972 - val_loss: 0.3733 - val_acc: 0.9762\n",
            "Epoch 84/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0112 - acc: 0.9982 - val_loss: 2.8544 - val_acc: 0.6749\n",
            "Epoch 85/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0271 - acc: 0.9973 - val_loss: 0.1790 - val_acc: 0.9873\n",
            "Epoch 86/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0166 - acc: 0.9983 - val_loss: 0.5761 - val_acc: 0.9615\n",
            "Epoch 87/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0226 - acc: 0.9977 - val_loss: 1.6771 - val_acc: 0.8558\n",
            "Epoch 88/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0256 - acc: 0.9975 - val_loss: 0.5825 - val_acc: 0.9624\n",
            "Epoch 89/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0167 - acc: 0.9977 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 90/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0189 - acc: 0.9981 - val_loss: 0.5019 - val_acc: 0.9633\n",
            "Epoch 91/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0171 - acc: 0.9985 - val_loss: 6.7608 - val_acc: 0.3883\n",
            "Epoch 92/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0232 - acc: 0.9976 - val_loss: 0.5693 - val_acc: 0.9610\n",
            "Epoch 93/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0201 - acc: 0.9976 - val_loss: 0.2746 - val_acc: 0.9825\n",
            "Epoch 94/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0251 - acc: 0.9976 - val_loss: 0.3723 - val_acc: 0.8996\n",
            "Epoch 95/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0149 - acc: 0.9983 - val_loss: 0.3418 - val_acc: 0.9710\n",
            "Epoch 96/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0178 - acc: 0.9981 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 97/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0156 - acc: 0.9978 - val_loss: 0.2779 - val_acc: 0.9757\n",
            "Epoch 98/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0183 - acc: 0.9977 - val_loss: 0.6407 - val_acc: 0.9601\n",
            "Epoch 99/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0251 - acc: 0.9975 - val_loss: 0.3789 - val_acc: 0.9687\n",
            "Epoch 100/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0228 - acc: 0.9972 - val_loss: 0.1423 - val_acc: 0.9871\n",
            "Epoch 101/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0146 - acc: 0.9986 - val_loss: 0.9126 - val_acc: 0.9352\n",
            "Epoch 102/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0190 - acc: 0.9980 - val_loss: 0.1175 - val_acc: 0.9900\n",
            "Epoch 103/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0209 - acc: 0.9978 - val_loss: 0.4541 - val_acc: 0.9655\n",
            "Epoch 104/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0158 - acc: 0.9982 - val_loss: 3.8014 - val_acc: 0.6606\n",
            "Epoch 105/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0201 - acc: 0.9977 - val_loss: 1.0192 - val_acc: 0.9229\n",
            "Epoch 106/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0222 - acc: 0.9978 - val_loss: 0.3741 - val_acc: 0.9703\n",
            "Epoch 107/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0102 - acc: 0.9984 - val_loss: 0.3720 - val_acc: 0.9712\n",
            "Epoch 108/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0127 - acc: 0.9984 - val_loss: 0.1509 - val_acc: 0.9889\n",
            "Epoch 109/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0177 - acc: 0.9978 - val_loss: 0.3944 - val_acc: 0.9689\n",
            "Epoch 110/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0200 - acc: 0.9976 - val_loss: 0.1905 - val_acc: 0.9839\n",
            "Epoch 111/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0106 - acc: 0.9983 - val_loss: 0.4281 - val_acc: 0.9601\n",
            "Epoch 112/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0217 - acc: 0.9977 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 113/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0221 - acc: 0.9978 - val_loss: 0.1641 - val_acc: 0.9875\n",
            "Epoch 114/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0201 - acc: 0.9978 - val_loss: 2.5012 - val_acc: 0.6561\n",
            "Epoch 115/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0288 - acc: 0.9973 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 116/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0363 - acc: 0.9965 - val_loss: 0.1371 - val_acc: 0.9812\n",
            "Epoch 117/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0227 - acc: 0.9974 - val_loss: 5.5891 - val_acc: 0.4278\n",
            "Epoch 118/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0194 - acc: 0.9983 - val_loss: 0.1492 - val_acc: 0.9798\n",
            "Epoch 119/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0087 - acc: 0.9991 - val_loss: 0.5509 - val_acc: 0.9626\n",
            "Epoch 120/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0196 - acc: 0.9984 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 121/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0314 - acc: 0.9971 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 122/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0140 - acc: 0.9988 - val_loss: 0.1256 - val_acc: 0.9900\n",
            "Epoch 123/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0139 - acc: 0.9990 - val_loss: 1.3025 - val_acc: 0.8853\n",
            "Epoch 124/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0325 - acc: 0.9971 - val_loss: 0.0922 - val_acc: 0.9882\n",
            "Epoch 125/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0181 - acc: 0.9982 - val_loss: 0.1085 - val_acc: 0.9903\n",
            "Epoch 126/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0080 - acc: 0.9990 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 127/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0131 - acc: 0.9985 - val_loss: 0.3001 - val_acc: 0.9460\n",
            "Epoch 128/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0088 - acc: 0.9993 - val_loss: 0.1601 - val_acc: 0.9710\n",
            "Epoch 129/150\n",
            "8822/8822 [==============================] - 10s 1ms/step - loss: 0.0075 - acc: 0.9991 - val_loss: 0.3643 - val_acc: 0.9696\n",
            "Epoch 130/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0396 - acc: 0.9961 - val_loss: 0.4446 - val_acc: 0.9052\n",
            "Epoch 131/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 3.1722 - val_acc: 0.6763\n",
            "Epoch 132/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0023 - acc: 0.9998 - val_loss: 0.4942 - val_acc: 0.9630\n",
            "Epoch 133/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0870 - val_acc: 0.9907\n",
            "Epoch 134/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0107 - acc: 0.9986 - val_loss: 0.3696 - val_acc: 0.9696\n",
            "Epoch 135/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0139 - acc: 0.9982 - val_loss: 0.2435 - val_acc: 0.9769\n",
            "Epoch 136/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0132 - acc: 0.9986 - val_loss: 10.3877 - val_acc: 0.2292\n",
            "Epoch 137/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0169 - acc: 0.9982 - val_loss: 0.3056 - val_acc: 0.9807\n",
            "Epoch 138/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0251 - acc: 0.9975 - val_loss: 0.2274 - val_acc: 0.9569\n",
            "Epoch 139/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0102 - acc: 0.9984 - val_loss: 5.0612 - val_acc: 0.4353\n",
            "Epoch 140/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0047 - acc: 0.9993 - val_loss: 0.1631 - val_acc: 0.9864\n",
            "Epoch 141/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0090 - acc: 0.9991 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 142/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0097 - acc: 0.9990 - val_loss: 13.5466 - val_acc: 0.0791\n",
            "Epoch 143/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0125 - acc: 0.9991 - val_loss: 0.4762 - val_acc: 0.9644\n",
            "Epoch 144/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0035 - acc: 0.9995 - val_loss: 1.7723 - val_acc: 0.7731\n",
            "Epoch 145/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0084 - acc: 0.9992 - val_loss: 5.6714 - val_acc: 0.3911\n",
            "Epoch 146/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0064 - acc: 0.9995 - val_loss: 0.3398 - val_acc: 0.9789\n",
            "Epoch 147/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0134 - acc: 0.9986 - val_loss: 4.2778 - val_acc: 0.6139\n",
            "Epoch 148/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0079 - acc: 0.9991 - val_loss: 0.3801 - val_acc: 0.9762\n",
            "Epoch 149/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0154 - acc: 0.9989 - val_loss: 0.3626 - val_acc: 0.9771\n",
            "Epoch 150/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.0306 - acc: 0.9976 - val_loss: 0.5033 - val_acc: 0.9524\n",
            "Bush F1 Score on Train :  0.541374474053296\n",
            "Bush F1 Score on Test :  0.39655172413793105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "utbpwt1NjQHn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result_f1_train_bush_E70"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c0Gdx5QnG-RJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result_f1_test_bush_E70"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sU7w5ahZG-TV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vcEWFhE4G-WG",
        "colab_type": "code",
        "outputId": "e5802571-b1e8-429d-807c-aaff68da8eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "modelForWilliams=load_model(\"7initialized-model.keras\")\n",
        "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_reshaped, \n",
        "             y_bush,shuffle = True ,test_size= 1./3, random_state=6099, stratify  = y_williams) # A20396099\n",
        "\n",
        "\n",
        "modelForWilliams.fit(X_train_w,y_train_w, epochs=150, batch_size=32, validation_data = (X_test_b, y_test_b ) )\n",
        "\n",
        "y_predicted_train_will = modelForWilliams.predict_classes(X_train_w) \n",
        "y_predicted_test_will = modelForWilliams.predict_classes(X_test_w) \n",
        "\n",
        "result_f1_train_will_E100=f1_score(y_train_b, y_predicted_train_will)\n",
        "result_f1_test_will_E100=f1_score(y_test_b, y_predicted_test_will)\n",
        "print(\"Williams F1 Score on Train : \",result_f1_train_will_E100)\n",
        "print(\"Williams F1 Score on Test : \",result_f1_test_will_E100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8822 samples, validate on 4411 samples\n",
            "Epoch 1/150\n",
            "8822/8822 [==============================] - 11s 1ms/step - loss: 0.3606 - acc: 0.9455 - val_loss: 0.6468 - val_acc: 0.9599\n",
            "Epoch 2/150\n",
            "8822/8822 [==============================] - 9s 1ms/step - loss: 0.1729 - acc: 0.9583 - val_loss: 0.3379 - val_acc: 0.9599\n",
            "Epoch 3/150\n",
            "8352/8822 [===========================>..] - ETA: 0s - loss: 0.1354 - acc: 0.9614"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9tOpjXJ7u7AF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result_f1_train_will_E100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WKJIKu-XG-Y_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result_f1_test_will_E100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X4laes3JG-Mo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "outputId": "14fa7bd9-77d6-446b-c2df-571a093cede0"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model11 = Sequential()\n",
        "\n",
        "model11.add(Conv2D(64, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model11.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model11.add(Conv2D(64, (3, 3),  activation = 'relu'))\n",
        "model11.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model11.add(Flatten())\n",
        "model11.add(Dense(64, activation='relu'))\n",
        "model11.add(Dropout(0.5))\n",
        "model11.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model11.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model11.fit(X_train,y_train, epochs=20, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_predicted_train_catDog = model11.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model11.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/20\n",
            "24500/24500 [==============================] - 14s 565us/step - loss: 7.9595 - acc: 0.5001 - val_loss: 8.4176 - val_acc: 0.4720\n",
            "Epoch 2/20\n",
            " 8896/24500 [=========>....................] - ETA: 8s - loss: 7.8763 - acc: 0.5060"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c89aef6d7591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mmodel11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mmodel11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xufpSfFA41p8",
        "colab_type": "code",
        "outputId": "0138220d-6ee3-4277-8df6-d8142b92554a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "X_data = []\n",
        "files = glob.glob (\"train/*.jpg\")\n",
        "for myFile in files:\n",
        "#     print(myFile)\n",
        "    image = cv2.imread (myFile)\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # convert to greyscale\n",
        "    X_data.append (gray_image)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-6fd12b33991e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmyFile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     print(myFile)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmyFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mgray_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert to greyscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgray_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "LiGdfHto5zOF",
        "colab_type": "code",
        "outputId": "1f220899-8055-4a0c-ebcc-c29a49672a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.array(X_data)\n",
        "print('X_data shape:', X.shape)\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_data shape: (25000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "ue8SVBDx55OL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_reshaped=X.reshape((X.shape[0],64,64,1))\n",
        "X_reshaped.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dhv-xkdR3lkM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Emld8BDNNYLi",
        "colab_type": "code",
        "outputId": "866988bc-38ac-411d-feb5-886b1a2083f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 115s 1us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mp4D-DqoYkO_",
        "colab_type": "code",
        "outputId": "a4630bef-302f-47d5-b3d0-bdcd2ac36f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "x_train_reshaped = tf.image.resize_images(x_train, (64,64))\n",
        "print(x_train_reshaped.shape)\n",
        "\n",
        "\n",
        "x_test_reshaped = tf.image.resize_images(x_test, (64,64))\n",
        "print(x_test_reshaped.shape)\n",
        "\n",
        "x_train_reshaped= tf.image.rgb_to_grayscale(x_train_reshaped)\n",
        "print(x_train_reshaped.shape)\n",
        "\n",
        "\n",
        "x_test_reshaped= tf.image.rgb_to_grayscale(x_test_reshaped)\n",
        "print(x_test_reshaped.shape)\n",
        "\n",
        "y_train_ML = np.zeros((y_train.shape))\n",
        "for cla in range(len(y_train)):\n",
        "  if y_train[cla] == 1:\n",
        "    y_train_ML[cla] = 1\n",
        "  else:\n",
        "    y_train_ML[cla] = 0\n",
        "    \n",
        "y_train_ML.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0ee4e459a4b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_reshaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "By-nRycGZlhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3605
        },
        "outputId": "49b133f8-4e60-46b6-b120-334d97773980"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model12 = Sequential()\n",
        "\n",
        "model12.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model12.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model12.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model12.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model12.add(Conv2D(64, (3, 3),  activation = 'relu'))\n",
        "model12.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model12.add(Flatten())\n",
        "model12.add(layers.Dropout(0.5))\n",
        "model12.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model12.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model12.fit(X_train,y_train, epochs=100, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "y_predicted_train_catDog = model12.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model12.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/100\n",
            "24500/24500 [==============================] - 11s 433us/step - loss: 1.1885 - acc: 0.5351 - val_loss: 0.6925 - val_acc: 0.5440\n",
            "Epoch 2/100\n",
            "24500/24500 [==============================] - 9s 381us/step - loss: 0.6876 - acc: 0.5708 - val_loss: 0.6472 - val_acc: 0.6500\n",
            "Epoch 3/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 0.6529 - acc: 0.6283 - val_loss: 0.5671 - val_acc: 0.7160\n",
            "Epoch 4/100\n",
            "24500/24500 [==============================] - 9s 380us/step - loss: 0.5938 - acc: 0.6874 - val_loss: 0.5643 - val_acc: 0.7380\n",
            "Epoch 5/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5611 - acc: 0.7157 - val_loss: 0.4905 - val_acc: 0.7660\n",
            "Epoch 6/100\n",
            "24500/24500 [==============================] - 9s 383us/step - loss: 0.5342 - acc: 0.7397 - val_loss: 0.4934 - val_acc: 0.7680\n",
            "Epoch 7/100\n",
            "24500/24500 [==============================] - 9s 383us/step - loss: 0.5130 - acc: 0.7525 - val_loss: 0.4414 - val_acc: 0.7920\n",
            "Epoch 8/100\n",
            "24500/24500 [==============================] - 9s 381us/step - loss: 0.5022 - acc: 0.7633 - val_loss: 0.4719 - val_acc: 0.7880\n",
            "Epoch 9/100\n",
            "24500/24500 [==============================] - 9s 382us/step - loss: 0.4914 - acc: 0.7696 - val_loss: 0.5422 - val_acc: 0.7480\n",
            "Epoch 10/100\n",
            "24500/24500 [==============================] - 9s 382us/step - loss: 0.4815 - acc: 0.7779 - val_loss: 0.7727 - val_acc: 0.6320\n",
            "Epoch 11/100\n",
            "24500/24500 [==============================] - 9s 382us/step - loss: 0.4782 - acc: 0.7796 - val_loss: 0.4707 - val_acc: 0.7940\n",
            "Epoch 12/100\n",
            "24500/24500 [==============================] - 9s 381us/step - loss: 0.4720 - acc: 0.7804 - val_loss: 0.4627 - val_acc: 0.8120\n",
            "Epoch 13/100\n",
            "24500/24500 [==============================] - 9s 382us/step - loss: 0.4734 - acc: 0.7813 - val_loss: 0.4672 - val_acc: 0.7900\n",
            "Epoch 14/100\n",
            "24500/24500 [==============================] - 9s 380us/step - loss: 0.4667 - acc: 0.7873 - val_loss: 0.4155 - val_acc: 0.8200\n",
            "Epoch 15/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 0.4568 - acc: 0.7905 - val_loss: 0.4013 - val_acc: 0.8300\n",
            "Epoch 16/100\n",
            "24500/24500 [==============================] - 9s 381us/step - loss: 0.4543 - acc: 0.7969 - val_loss: 0.4635 - val_acc: 0.8100\n",
            "Epoch 17/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.4587 - acc: 0.7946 - val_loss: 0.4993 - val_acc: 0.7520\n",
            "Epoch 18/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.4527 - acc: 0.7962 - val_loss: 0.5248 - val_acc: 0.7620\n",
            "Epoch 19/100\n",
            "24500/24500 [==============================] - 9s 381us/step - loss: 0.4587 - acc: 0.7958 - val_loss: 0.3739 - val_acc: 0.8480\n",
            "Epoch 20/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.4531 - acc: 0.7954 - val_loss: 0.4448 - val_acc: 0.8360\n",
            "Epoch 21/100\n",
            "24500/24500 [==============================] - 9s 375us/step - loss: 0.4545 - acc: 0.7973 - val_loss: 0.6039 - val_acc: 0.7140\n",
            "Epoch 22/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.4608 - acc: 0.7976 - val_loss: 0.4257 - val_acc: 0.8060\n",
            "Epoch 23/100\n",
            "24500/24500 [==============================] - 9s 381us/step - loss: 0.4609 - acc: 0.7969 - val_loss: 0.4509 - val_acc: 0.8140\n",
            "Epoch 24/100\n",
            "24500/24500 [==============================] - 9s 380us/step - loss: 0.4864 - acc: 0.7931 - val_loss: 0.4529 - val_acc: 0.8260\n",
            "Epoch 25/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.4690 - acc: 0.7905 - val_loss: 0.4588 - val_acc: 0.7960\n",
            "Epoch 26/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.4669 - acc: 0.7910 - val_loss: 0.4725 - val_acc: 0.8000\n",
            "Epoch 27/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.4665 - acc: 0.7928 - val_loss: 0.4631 - val_acc: 0.8100\n",
            "Epoch 28/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 0.4761 - acc: 0.7894 - val_loss: 0.4112 - val_acc: 0.8240\n",
            "Epoch 29/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.4801 - acc: 0.7853 - val_loss: 0.4504 - val_acc: 0.8180\n",
            "Epoch 30/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 0.4906 - acc: 0.7809 - val_loss: 0.3962 - val_acc: 0.8340\n",
            "Epoch 31/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.4938 - acc: 0.7775 - val_loss: 0.4757 - val_acc: 0.8080\n",
            "Epoch 32/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.4948 - acc: 0.7781 - val_loss: 0.5414 - val_acc: 0.7680\n",
            "Epoch 33/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.4976 - acc: 0.7767 - val_loss: 0.5509 - val_acc: 0.7680\n",
            "Epoch 34/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5300 - acc: 0.7632 - val_loss: 0.4678 - val_acc: 0.7960\n",
            "Epoch 35/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 0.5300 - acc: 0.7584 - val_loss: 0.4946 - val_acc: 0.7520\n",
            "Epoch 36/100\n",
            "24500/24500 [==============================] - 9s 381us/step - loss: 0.5555 - acc: 0.7432 - val_loss: 0.5189 - val_acc: 0.7420\n",
            "Epoch 37/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5355 - acc: 0.7539 - val_loss: 0.5124 - val_acc: 0.7800\n",
            "Epoch 38/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5350 - acc: 0.7492 - val_loss: 0.4413 - val_acc: 0.8120\n",
            "Epoch 39/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5291 - acc: 0.7488 - val_loss: 0.4614 - val_acc: 0.8040\n",
            "Epoch 40/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 0.5433 - acc: 0.7447 - val_loss: 0.5200 - val_acc: 0.7860\n",
            "Epoch 41/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5600 - acc: 0.7371 - val_loss: 0.4944 - val_acc: 0.7800\n",
            "Epoch 42/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5685 - acc: 0.7340 - val_loss: 0.5098 - val_acc: 0.7640\n",
            "Epoch 43/100\n",
            "24500/24500 [==============================] - 9s 380us/step - loss: 0.5652 - acc: 0.7338 - val_loss: 0.6884 - val_acc: 0.7060\n",
            "Epoch 44/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5668 - acc: 0.7318 - val_loss: 0.4975 - val_acc: 0.7820\n",
            "Epoch 45/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5779 - acc: 0.7220 - val_loss: 0.5266 - val_acc: 0.7480\n",
            "Epoch 46/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 7.8225 - acc: 0.5066 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 47/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 48/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 49/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 50/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 51/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 52/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 53/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 54/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 55/100\n",
            "24500/24500 [==============================] - 9s 374us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 56/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 8.0689 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 57/100\n",
            "24500/24500 [==============================] - 9s 375us/step - loss: 7.8456 - acc: 0.5034 - val_loss: 0.5449 - val_acc: 0.7300\n",
            "Epoch 58/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.6208 - acc: 0.6925 - val_loss: 0.5221 - val_acc: 0.7600\n",
            "Epoch 59/100\n",
            "24500/24500 [==============================] - 9s 375us/step - loss: 0.5855 - acc: 0.7223 - val_loss: 0.5813 - val_acc: 0.7360\n",
            "Epoch 60/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 0.5902 - acc: 0.7166 - val_loss: 0.5056 - val_acc: 0.7680\n",
            "Epoch 61/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 0.6008 - acc: 0.7140 - val_loss: 0.4660 - val_acc: 0.7820\n",
            "Epoch 62/100\n",
            "24500/24500 [==============================] - 9s 375us/step - loss: 0.5985 - acc: 0.7119 - val_loss: 0.5237 - val_acc: 0.7600\n",
            "Epoch 63/100\n",
            "24500/24500 [==============================] - 9s 380us/step - loss: 0.5804 - acc: 0.7186 - val_loss: 1.6112 - val_acc: 0.4960\n",
            "Epoch 64/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5741 - acc: 0.7207 - val_loss: 0.6873 - val_acc: 0.6560\n",
            "Epoch 65/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 0.5805 - acc: 0.7139 - val_loss: 0.5420 - val_acc: 0.7540\n",
            "Epoch 66/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5624 - acc: 0.7284 - val_loss: 0.4703 - val_acc: 0.7800\n",
            "Epoch 67/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5711 - acc: 0.7239 - val_loss: 0.4650 - val_acc: 0.7840\n",
            "Epoch 68/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 0.5825 - acc: 0.7178 - val_loss: 0.4758 - val_acc: 0.8000\n",
            "Epoch 69/100\n",
            "24500/24500 [==============================] - 9s 380us/step - loss: 0.5805 - acc: 0.7176 - val_loss: 0.4667 - val_acc: 0.8120\n",
            "Epoch 70/100\n",
            "24500/24500 [==============================] - 9s 380us/step - loss: 0.5748 - acc: 0.7247 - val_loss: 0.4278 - val_acc: 0.8120\n",
            "Epoch 71/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5795 - acc: 0.7204 - val_loss: 0.8446 - val_acc: 0.6320\n",
            "Epoch 72/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 0.5775 - acc: 0.7176 - val_loss: 0.4513 - val_acc: 0.7980\n",
            "Epoch 73/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 0.5748 - acc: 0.7295 - val_loss: 0.5291 - val_acc: 0.7500\n",
            "Epoch 74/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5743 - acc: 0.7211 - val_loss: 0.4894 - val_acc: 0.7880\n",
            "Epoch 75/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 0.5683 - acc: 0.7299 - val_loss: 0.5589 - val_acc: 0.7320\n",
            "Epoch 76/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 0.5743 - acc: 0.7236 - val_loss: 0.5048 - val_acc: 0.7680\n",
            "Epoch 77/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 0.5750 - acc: 0.7169 - val_loss: 0.7574 - val_acc: 0.5660\n",
            "Epoch 78/100\n",
            "24500/24500 [==============================] - 9s 381us/step - loss: 0.5893 - acc: 0.7114 - val_loss: 0.5352 - val_acc: 0.7500\n",
            "Epoch 79/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 0.5866 - acc: 0.7134 - val_loss: 0.5421 - val_acc: 0.7480\n",
            "Epoch 80/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5819 - acc: 0.7137 - val_loss: 0.5470 - val_acc: 0.7680\n",
            "Epoch 81/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5903 - acc: 0.7073 - val_loss: 0.5103 - val_acc: 0.7920\n",
            "Epoch 82/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5799 - acc: 0.7130 - val_loss: 0.5201 - val_acc: 0.7360\n",
            "Epoch 83/100\n",
            "24500/24500 [==============================] - 9s 380us/step - loss: 0.5912 - acc: 0.7158 - val_loss: 0.4414 - val_acc: 0.8100\n",
            "Epoch 84/100\n",
            "24500/24500 [==============================] - 9s 380us/step - loss: 0.5804 - acc: 0.7161 - val_loss: 1.6056 - val_acc: 0.5680\n",
            "Epoch 85/100\n",
            "24500/24500 [==============================] - 9s 381us/step - loss: 0.5913 - acc: 0.7131 - val_loss: 0.6377 - val_acc: 0.7500\n",
            "Epoch 86/100\n",
            "24500/24500 [==============================] - 9s 380us/step - loss: 0.6127 - acc: 0.7096 - val_loss: 0.4864 - val_acc: 0.7800\n",
            "Epoch 87/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5858 - acc: 0.7140 - val_loss: 0.5200 - val_acc: 0.7620\n",
            "Epoch 88/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 0.5860 - acc: 0.7158 - val_loss: 0.4559 - val_acc: 0.8160\n",
            "Epoch 89/100\n",
            "24500/24500 [==============================] - 9s 381us/step - loss: 0.5766 - acc: 0.7187 - val_loss: 0.5791 - val_acc: 0.7520\n",
            "Epoch 90/100\n",
            "24500/24500 [==============================] - 9s 379us/step - loss: 0.5860 - acc: 0.7172 - val_loss: 0.4903 - val_acc: 0.7880\n",
            "Epoch 91/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5710 - acc: 0.7210 - val_loss: 0.4775 - val_acc: 0.7740\n",
            "Epoch 92/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5784 - acc: 0.7214 - val_loss: 0.4990 - val_acc: 0.7780\n",
            "Epoch 93/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5835 - acc: 0.7143 - val_loss: 0.5136 - val_acc: 0.7880\n",
            "Epoch 94/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 0.5815 - acc: 0.7117 - val_loss: 0.5149 - val_acc: 0.7580\n",
            "Epoch 95/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 0.5814 - acc: 0.7122 - val_loss: 0.5414 - val_acc: 0.7820\n",
            "Epoch 96/100\n",
            "24500/24500 [==============================] - 9s 378us/step - loss: 0.5780 - acc: 0.7145 - val_loss: 0.5763 - val_acc: 0.6880\n",
            "Epoch 97/100\n",
            "24500/24500 [==============================] - 9s 376us/step - loss: 0.5856 - acc: 0.7182 - val_loss: 0.4536 - val_acc: 0.7900\n",
            "Epoch 98/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5701 - acc: 0.7193 - val_loss: 0.4482 - val_acc: 0.8140\n",
            "Epoch 99/100\n",
            "24500/24500 [==============================] - 9s 377us/step - loss: 0.5729 - acc: 0.7210 - val_loss: 0.5549 - val_acc: 0.7340\n",
            "Epoch 100/100\n",
            "24500/24500 [==============================] - 9s 380us/step - loss: 0.5609 - acc: 0.7258 - val_loss: 0.4885 - val_acc: 0.7980\n",
            " F1 Score on Train :  0.7715756783262504\n",
            " F1 Score on Test :  0.7942973523421588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v9KObMM7qre2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "e4b36700-d70c-4a0f-baf7-0e270299f88c"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model13 = Sequential()\n",
        "\n",
        "model13.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model13.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model13.add(Conv2D(32, (3, 3),  activation = 'relu'))\n",
        "model13.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model13.add(Conv2D(64, (3, 3),  activation = 'relu'))\n",
        "model13.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model13.add(Flatten())\n",
        "model13.add(Dense(64, activation='relu'))\n",
        "\n",
        "model13.add(BatchNormalization())\n",
        "\n",
        "model13.add(layers.Dropout(0.5))\n",
        "model13.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model13.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model13.fit(X_train,y_train, epochs=20, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "y_predicted_train_catDog = model13.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model13.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/20\n",
            "24500/24500 [==============================] - 13s 547us/step - loss: 0.6272 - acc: 0.6587 - val_loss: 0.7157 - val_acc: 0.6320\n",
            "Epoch 2/20\n",
            "24500/24500 [==============================] - 12s 495us/step - loss: 0.4887 - acc: 0.7695 - val_loss: 0.4030 - val_acc: 0.8120\n",
            "Epoch 3/20\n",
            "24500/24500 [==============================] - 12s 495us/step - loss: 0.4367 - acc: 0.8013 - val_loss: 0.5950 - val_acc: 0.7180\n",
            "Epoch 4/20\n",
            "24500/24500 [==============================] - 12s 493us/step - loss: 0.3884 - acc: 0.8294 - val_loss: 0.6592 - val_acc: 0.7160\n",
            "Epoch 5/20\n",
            "24500/24500 [==============================] - 12s 493us/step - loss: 0.3567 - acc: 0.8449 - val_loss: 0.2971 - val_acc: 0.8860\n",
            "Epoch 6/20\n",
            "24500/24500 [==============================] - 12s 494us/step - loss: 0.3234 - acc: 0.8604 - val_loss: 0.3940 - val_acc: 0.8200\n",
            "Epoch 7/20\n",
            "24500/24500 [==============================] - 12s 493us/step - loss: 0.2995 - acc: 0.8731 - val_loss: 0.2973 - val_acc: 0.8840\n",
            "Epoch 8/20\n",
            "24500/24500 [==============================] - 12s 494us/step - loss: 0.2762 - acc: 0.8835 - val_loss: 0.4294 - val_acc: 0.8200\n",
            "Epoch 9/20\n",
            "24500/24500 [==============================] - 12s 492us/step - loss: 0.2578 - acc: 0.8923 - val_loss: 0.3608 - val_acc: 0.8460\n",
            "Epoch 10/20\n",
            "24500/24500 [==============================] - 12s 494us/step - loss: 0.2346 - acc: 0.9024 - val_loss: 0.2914 - val_acc: 0.8880\n",
            "Epoch 11/20\n",
            "24500/24500 [==============================] - 12s 494us/step - loss: 0.2195 - acc: 0.9112 - val_loss: 0.3812 - val_acc: 0.8620\n",
            "Epoch 12/20\n",
            "24500/24500 [==============================] - 12s 494us/step - loss: 0.2023 - acc: 0.9183 - val_loss: 0.5330 - val_acc: 0.8260\n",
            "Epoch 13/20\n",
            "24500/24500 [==============================] - 12s 493us/step - loss: 0.1905 - acc: 0.9229 - val_loss: 0.3230 - val_acc: 0.8980\n",
            "Epoch 14/20\n",
            "24500/24500 [==============================] - 12s 493us/step - loss: 0.1836 - acc: 0.9258 - val_loss: 0.4343 - val_acc: 0.8420\n",
            "Epoch 15/20\n",
            "24500/24500 [==============================] - 12s 494us/step - loss: 0.1648 - acc: 0.9349 - val_loss: 0.4251 - val_acc: 0.8620\n",
            "Epoch 16/20\n",
            "24500/24500 [==============================] - 12s 494us/step - loss: 0.1538 - acc: 0.9397 - val_loss: 0.9249 - val_acc: 0.7360\n",
            "Epoch 17/20\n",
            "24500/24500 [==============================] - 12s 493us/step - loss: 0.1456 - acc: 0.9424 - val_loss: 0.3992 - val_acc: 0.8680\n",
            "Epoch 18/20\n",
            "24500/24500 [==============================] - 12s 494us/step - loss: 0.1351 - acc: 0.9481 - val_loss: 0.4063 - val_acc: 0.8700\n",
            "Epoch 19/20\n",
            "24500/24500 [==============================] - 12s 494us/step - loss: 0.1280 - acc: 0.9499 - val_loss: 0.4309 - val_acc: 0.8720\n",
            "Epoch 20/20\n",
            "24500/24500 [==============================] - 12s 492us/step - loss: 0.1248 - acc: 0.9516 - val_loss: 0.4922 - val_acc: 0.8520\n",
            " F1 Score on Train :  0.9242139327415052\n",
            " F1 Score on Test :  0.8262910798122066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JIViI4-F-yOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "28c80d14-8fdb-4d09-d83c-3d8bcbdb70a1"
      },
      "cell_type": "code",
      "source": [
        "model13.summary()\n",
        "model13.save('13initialized-model.keras')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_35 (Conv2D)           (None, 62, 62, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 64)                147520    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 175,905\n",
            "Trainable params: 175,777\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R9jH9XjsAO99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1857
        },
        "outputId": "287b2cb3-dc62-4cc8-ee0f-058ee95a5bd7"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from sklearn.metrics import f1_score\n",
        "from keras import layers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense,Flatten\n",
        "\n",
        "# Model\n",
        "model10 = Sequential()\n",
        "\n",
        "model10.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1), activation = 'relu'))\n",
        "model10.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model10.add(Conv2D(64, (3, 3),  activation = 'relu'))\n",
        "model10.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model10.add(Conv2D(64, (3, 3),  activation = 'relu'))\n",
        "model10.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "model10.add(Flatten())\n",
        "model10.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model10.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model10.fit(X_train,y_train, epochs=50, batch_size=32, validation_data = (X_test, y_test) )\n",
        "\n",
        "y_predicted_train_catDog = model10.predict_classes(X_train) \n",
        "y_predicted_test_catDog = model10.predict_classes(X_test) \n",
        "result_f1_train=f1_score(y_train, y_predicted_train_catDog)\n",
        "result_f1_test=f1_score(y_test, y_predicted_test_catDog)\n",
        "print(\" F1 Score on Train : \",result_f1_train)\n",
        "print(\" F1 Score on Test : \",result_f1_test)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "24500/24500 [==============================] - 14s 579us/step - loss: 8.0619 - acc: 0.4995 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 2/50\n",
            "24500/24500 [==============================] - 10s 398us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 3/50\n",
            "24500/24500 [==============================] - 10s 399us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 4/50\n",
            "24500/24500 [==============================] - 10s 398us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 5/50\n",
            "24500/24500 [==============================] - 10s 403us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 6/50\n",
            "24500/24500 [==============================] - 10s 403us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 7/50\n",
            "24500/24500 [==============================] - 10s 400us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 8/50\n",
            "24500/24500 [==============================] - 10s 399us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 9/50\n",
            "24500/24500 [==============================] - 10s 400us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 10/50\n",
            "24500/24500 [==============================] - 10s 401us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 11/50\n",
            "24500/24500 [==============================] - 10s 401us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 12/50\n",
            "24500/24500 [==============================] - 10s 403us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 13/50\n",
            "24500/24500 [==============================] - 10s 402us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 14/50\n",
            "24500/24500 [==============================] - 10s 400us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 15/50\n",
            "24500/24500 [==============================] - 10s 400us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 16/50\n",
            "24500/24500 [==============================] - 10s 402us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 17/50\n",
            "24500/24500 [==============================] - 10s 399us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 18/50\n",
            "24500/24500 [==============================] - 10s 398us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 19/50\n",
            "24500/24500 [==============================] - 10s 400us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 20/50\n",
            "24500/24500 [==============================] - 10s 399us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 21/50\n",
            "24500/24500 [==============================] - 10s 401us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 22/50\n",
            "24500/24500 [==============================] - 10s 402us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 23/50\n",
            "24500/24500 [==============================] - 10s 399us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 24/50\n",
            "24500/24500 [==============================] - 10s 398us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 25/50\n",
            "24500/24500 [==============================] - 10s 401us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 26/50\n",
            "24500/24500 [==============================] - 10s 400us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 27/50\n",
            "24500/24500 [==============================] - 10s 403us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 28/50\n",
            "24500/24500 [==============================] - 10s 402us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 29/50\n",
            "24500/24500 [==============================] - 10s 400us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 30/50\n",
            "24500/24500 [==============================] - 10s 398us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 31/50\n",
            "24500/24500 [==============================] - 10s 399us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 32/50\n",
            "24500/24500 [==============================] - 10s 399us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 33/50\n",
            "24500/24500 [==============================] - 10s 398us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 34/50\n",
            "24500/24500 [==============================] - 10s 400us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 35/50\n",
            "24500/24500 [==============================] - 10s 397us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 36/50\n",
            "24500/24500 [==============================] - 10s 396us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 37/50\n",
            "24500/24500 [==============================] - 10s 400us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 38/50\n",
            "24500/24500 [==============================] - 10s 396us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 39/50\n",
            "24500/24500 [==============================] - 10s 395us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 40/50\n",
            "24500/24500 [==============================] - 10s 401us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 41/50\n",
            "24500/24500 [==============================] - 10s 400us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 42/50\n",
            "24500/24500 [==============================] - 10s 398us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 43/50\n",
            "24500/24500 [==============================] - 10s 398us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 44/50\n",
            "24500/24500 [==============================] - 10s 399us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 45/50\n",
            "24500/24500 [==============================] - 10s 404us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 46/50\n",
            "24500/24500 [==============================] - 10s 401us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 47/50\n",
            "24500/24500 [==============================] - 10s 401us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 48/50\n",
            "24500/24500 [==============================] - 10s 400us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 49/50\n",
            "24500/24500 [==============================] - 10s 399us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            "Epoch 50/50\n",
            "24500/24500 [==============================] - 10s 405us/step - loss: 8.0683 - acc: 0.4994 - val_loss: 7.6077 - val_acc: 0.5280\n",
            " F1 Score on Train :  0.0\n",
            " F1 Score on Test :  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VogwC73nrk6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "8420aba2-f74d-4c5a-a846-0507db029c53"
      },
      "cell_type": "code",
      "source": [
        "model10.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 62, 62, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 29, 29, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 12, 12, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 2305      \n",
            "=================================================================\n",
            "Total params: 58,049\n",
            "Trainable params: 58,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5apLyEz3t-d3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "0bcf0061-c298-4429-f1f3-fe623cf6bab9"
      },
      "cell_type": "code",
      "source": [
        "model10.layers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.convolutional.Conv2D at 0x7f1ae0cf41d0>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f1ae0cf46a0>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f1ae0cf4198>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f1ae0ceeb00>,\n",
              " <keras.layers.convolutional.Conv2D at 0x7f1ae0cf4da0>,\n",
              " <keras.layers.pooling.MaxPooling2D at 0x7f1ae0db1e48>,\n",
              " <keras.layers.core.Flatten at 0x7f1ae0ceecf8>,\n",
              " <keras.layers.core.Dense at 0x7f1ae226ef98>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "S-joQoQWuJth",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "295a1475-5afd-4edc-d33a-cdc9a0886cb5"
      },
      "cell_type": "code",
      "source": [
        "model10.inputs"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'conv2d_4_input:0' shape=(?, 64, 64, 1) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "Qp5PLTa1uy9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7032b7a6-ab94-44e2-f29a-40ce289ea595"
      },
      "cell_type": "code",
      "source": [
        "model10.outputs"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'dense_2/Sigmoid:0' shape=(?, 1) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "ZKcAj9WtxANi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model10.save('newmodel.keras')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9DzIKpAQxaCv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}